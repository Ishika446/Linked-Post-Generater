{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "RNlGT5-DcvVb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b86bfc48-7dd3-4bfb-ab8b-4c0cc00e7e88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 3, Sample 506, Loss: 2.3294\n",
            "Epoch 3, Sample 507, Loss: 2.3969\n",
            "Epoch 3, Sample 508, Loss: 2.8360\n",
            "Epoch 3, Sample 509, Loss: 1.5164\n",
            "Epoch 3, Sample 510, Loss: 2.9322\n",
            "Epoch 3, Sample 511, Loss: 2.0379\n",
            "Epoch 3, Sample 512, Loss: 2.6418\n",
            "Epoch 3, Sample 513, Loss: 1.6700\n",
            "Epoch 3, Sample 514, Loss: 2.3931\n",
            "Epoch 3, Sample 515, Loss: 2.0046\n",
            "Epoch 3, Sample 516, Loss: 2.2953\n",
            "Epoch 3, Sample 517, Loss: 2.5759\n",
            "Epoch 3, Sample 518, Loss: 1.7665\n",
            "Epoch 3, Sample 519, Loss: 2.1731\n",
            "Epoch 3, Sample 520, Loss: 1.9864\n",
            "Epoch 3, Sample 521, Loss: 1.8578\n",
            "Epoch 3, Sample 522, Loss: 2.6043\n",
            "Epoch 3, Sample 523, Loss: 2.0585\n",
            "Epoch 3, Sample 524, Loss: 2.9048\n",
            "Epoch 3, Sample 525, Loss: 2.7408\n",
            "Epoch 3, Sample 526, Loss: 1.9959\n",
            "Epoch 3, Sample 527, Loss: 1.7332\n",
            "Epoch 3, Sample 528, Loss: 2.1729\n",
            "Epoch 3, Sample 529, Loss: 2.7981\n",
            "Epoch 3, Sample 530, Loss: 3.4425\n",
            "Epoch 3, Sample 531, Loss: 2.7242\n",
            "Epoch 3, Sample 532, Loss: 2.5243\n",
            "Epoch 3, Sample 533, Loss: 1.6937\n",
            "Epoch 3, Sample 534, Loss: 2.1980\n",
            "Epoch 3, Sample 535, Loss: 2.0674\n",
            "Epoch 3, Sample 536, Loss: 2.5482\n",
            "Epoch 3, Sample 537, Loss: 3.6450\n",
            "Epoch 3, Sample 538, Loss: 2.2706\n",
            "Epoch 3, Sample 539, Loss: 1.9917\n",
            "Epoch 3, Sample 540, Loss: 2.8109\n",
            "Epoch 3, Sample 541, Loss: 2.1661\n",
            "Epoch 3, Sample 542, Loss: 2.3905\n",
            "Epoch 3, Sample 543, Loss: 2.6323\n",
            "Epoch 3, Sample 544, Loss: 1.8336\n",
            "Epoch 3, Sample 545, Loss: 3.0116\n",
            "Epoch 3, Sample 546, Loss: 3.1373\n",
            "Epoch 3, Sample 547, Loss: 1.8031\n",
            "Epoch 3, Sample 548, Loss: 1.7245\n",
            "Epoch 3, Sample 549, Loss: 3.1976\n",
            "Epoch 3, Sample 550, Loss: 2.4170\n",
            "Epoch 3, Sample 551, Loss: 2.0535\n",
            "Epoch 3, Sample 552, Loss: 2.2960\n",
            "Epoch 3, Sample 553, Loss: 2.7701\n",
            "Epoch 3, Sample 554, Loss: 2.6830\n",
            "Epoch 3, Sample 555, Loss: 2.1071\n",
            "Epoch 3, Sample 556, Loss: 2.5326\n",
            "Epoch 3, Sample 557, Loss: 2.8408\n",
            "Epoch 3, Sample 558, Loss: 3.3967\n",
            "Epoch 3, Sample 559, Loss: 2.2288\n",
            "Epoch 3, Sample 560, Loss: 2.8237\n",
            "Epoch 3, Sample 561, Loss: 3.3080\n",
            "Epoch 3, Sample 562, Loss: 2.7068\n",
            "Epoch 3, Sample 563, Loss: 2.0306\n",
            "Epoch 3, Sample 564, Loss: 2.4779\n",
            "Epoch 3, Sample 565, Loss: 2.9208\n",
            "Epoch 3, Sample 566, Loss: 2.3065\n",
            "Epoch 3, Sample 567, Loss: 2.0264\n",
            "Epoch 3, Sample 568, Loss: 2.6212\n",
            "Epoch 3, Sample 569, Loss: 3.0909\n",
            "Epoch 3, Sample 570, Loss: 2.5022\n",
            "Epoch 3, Sample 571, Loss: 2.8314\n",
            "Epoch 3, Sample 572, Loss: 2.4556\n",
            "Epoch 3, Sample 573, Loss: 2.1278\n",
            "Epoch 3, Sample 574, Loss: 2.2543\n",
            "Epoch 3, Sample 575, Loss: 3.3137\n",
            "Epoch 3, Sample 576, Loss: 2.3909\n",
            "Epoch 3, Sample 577, Loss: 2.1198\n",
            "Epoch 3, Sample 578, Loss: 2.4752\n",
            "Epoch 3, Sample 579, Loss: 2.5942\n",
            "Epoch 3, Sample 580, Loss: 3.6229\n",
            "Epoch 3, Sample 581, Loss: 1.9621\n",
            "Epoch 3, Sample 582, Loss: 2.9362\n",
            "Epoch 3, Sample 583, Loss: 3.4641\n",
            "Epoch 3, Sample 584, Loss: 2.0964\n",
            "Epoch 3, Sample 585, Loss: 2.7182\n",
            "Epoch 3, Sample 586, Loss: 3.3189\n",
            "Epoch 3, Sample 587, Loss: 2.5064\n",
            "Epoch 3, Sample 588, Loss: 3.1609\n",
            "Epoch 3, Sample 589, Loss: 2.3170\n",
            "Epoch 3, Sample 590, Loss: 3.1002\n",
            "Epoch 3, Sample 591, Loss: 2.2107\n",
            "Epoch 3, Sample 592, Loss: 3.5441\n",
            "Epoch 3, Sample 593, Loss: 1.4589\n",
            "Epoch 3, Sample 594, Loss: 2.9316\n",
            "Epoch 3, Sample 595, Loss: 1.7754\n",
            "Epoch 3, Sample 596, Loss: 2.4650\n",
            "Epoch 3, Sample 597, Loss: 3.0138\n",
            "Epoch 3, Sample 598, Loss: 2.3902\n",
            "Epoch 3, Sample 599, Loss: 2.1745\n",
            "Epoch 3, Sample 600, Loss: 3.0203\n",
            "Epoch 3, Sample 601, Loss: 2.3599\n",
            "Epoch 3, Sample 602, Loss: 3.2200\n",
            "Epoch 3, Sample 603, Loss: 1.9193\n",
            "Epoch 3, Sample 604, Loss: 3.3227\n",
            "Epoch 3, Sample 605, Loss: 2.5050\n",
            "Epoch 3, Sample 606, Loss: 2.1057\n",
            "Epoch 3, Sample 607, Loss: 3.4425\n",
            "Epoch 3, Sample 608, Loss: 2.9250\n",
            "Epoch 3, Sample 609, Loss: 2.3834\n",
            "Epoch 3, Sample 610, Loss: 2.3747\n",
            "Epoch 3, Sample 611, Loss: 3.0163\n",
            "Epoch 3, Sample 612, Loss: 3.2603\n",
            "Epoch 3, Sample 613, Loss: 3.7788\n",
            "Epoch 3, Sample 614, Loss: 2.9129\n",
            "Epoch 3, Sample 615, Loss: 1.7804\n",
            "Epoch 3, Sample 616, Loss: 2.5295\n",
            "Epoch 3, Sample 617, Loss: 3.4427\n",
            "Epoch 3, Sample 618, Loss: 2.0664\n",
            "Epoch 3, Sample 619, Loss: 1.8846\n",
            "Epoch 3, Sample 620, Loss: 2.4565\n",
            "Epoch 3, Sample 621, Loss: 2.0004\n",
            "Epoch 3, Sample 622, Loss: 2.0006\n",
            "Epoch 3, Sample 623, Loss: 3.0571\n",
            "Epoch 3, Sample 624, Loss: 1.7674\n",
            "Epoch 3, Sample 625, Loss: 2.4974\n",
            "Epoch 3, Sample 626, Loss: 2.2701\n",
            "Epoch 3, Sample 627, Loss: 2.7012\n",
            "Epoch 3, Sample 628, Loss: 2.6549\n",
            "Epoch 3, Sample 629, Loss: 3.0585\n",
            "Epoch 3, Sample 630, Loss: 3.0947\n",
            "Epoch 3, Sample 631, Loss: 1.5390\n",
            "Epoch 3, Sample 632, Loss: 2.3078\n",
            "Epoch 3, Sample 633, Loss: 1.7287\n",
            "Epoch 3, Sample 634, Loss: 1.6899\n",
            "Epoch 3, Sample 635, Loss: 1.9670\n",
            "Epoch 3, Sample 636, Loss: 2.8898\n",
            "Epoch 3, Sample 637, Loss: 2.2142\n",
            "Epoch 3, Sample 638, Loss: 1.7344\n",
            "Epoch 3, Sample 639, Loss: 2.5757\n",
            "Epoch 3, Sample 640, Loss: 2.5826\n",
            "Epoch 3, Sample 641, Loss: 2.1128\n",
            "Epoch 3, Sample 642, Loss: 1.8644\n",
            "Epoch 3, Sample 643, Loss: 2.5018\n",
            "Epoch 3, Sample 644, Loss: 1.9851\n",
            "Epoch 3, Sample 645, Loss: 2.2932\n",
            "Epoch 3, Sample 646, Loss: 2.9050\n",
            "Epoch 3, Sample 647, Loss: 2.5584\n",
            "Epoch 3, Sample 648, Loss: 2.8876\n",
            "Epoch 3, Sample 649, Loss: 2.6201\n",
            "Epoch 3, Sample 650, Loss: 2.1161\n",
            "Epoch 3, Sample 651, Loss: 2.7351\n",
            "Epoch 3, Sample 652, Loss: 1.7562\n",
            "Epoch 3, Sample 653, Loss: 2.1494\n",
            "Epoch 3, Sample 654, Loss: 2.3344\n",
            "Epoch 3, Sample 655, Loss: 2.5092\n",
            "Epoch 3, Sample 656, Loss: 3.0665\n",
            "Epoch 3, Sample 657, Loss: 2.4905\n",
            "Epoch 3, Sample 658, Loss: 2.4014\n",
            "Epoch 3, Sample 659, Loss: 1.9387\n",
            "Epoch 3, Sample 660, Loss: 2.4368\n",
            "Epoch 3, Sample 661, Loss: 2.0213\n",
            "Epoch 3, Sample 662, Loss: 2.4867\n",
            "Epoch 3, Sample 663, Loss: 2.0874\n",
            "Epoch 3, Sample 664, Loss: 2.0084\n",
            "Epoch 3, Sample 665, Loss: 2.3499\n",
            "Epoch 3, Sample 666, Loss: 2.3158\n",
            "Epoch 3, Sample 667, Loss: 3.8079\n",
            "Epoch 3, Sample 668, Loss: 2.6849\n",
            "Epoch 3, Sample 669, Loss: 1.9808\n",
            "Epoch 3, Sample 670, Loss: 2.2104\n",
            "Epoch 3, Sample 671, Loss: 1.7581\n",
            "Epoch 3, Sample 672, Loss: 2.0246\n",
            "Epoch 3, Sample 673, Loss: 2.4662\n",
            "Epoch 3, Sample 674, Loss: 2.4706\n",
            "Epoch 3, Sample 675, Loss: 2.2378\n",
            "Epoch 3, Sample 676, Loss: 2.1364\n",
            "Epoch 3, Sample 677, Loss: 2.5779\n",
            "Epoch 3, Sample 678, Loss: 2.0626\n",
            "Epoch 3, Sample 679, Loss: 2.0660\n",
            "Epoch 3, Sample 680, Loss: 2.8380\n",
            "Epoch 3, Sample 681, Loss: 1.7895\n",
            "Epoch 3, Sample 682, Loss: 1.9330\n",
            "Epoch 3, Sample 683, Loss: 2.3695\n",
            "Epoch 3, Sample 684, Loss: 2.5604\n",
            "Epoch 3, Sample 685, Loss: 1.7951\n",
            "Epoch 3, Sample 686, Loss: 1.8513\n",
            "Epoch 3, Sample 687, Loss: 2.5656\n",
            "Epoch 3, Sample 688, Loss: 2.3388\n",
            "Epoch 3, Sample 689, Loss: 2.0764\n",
            "Epoch 3, Sample 690, Loss: 2.3324\n",
            "Epoch 3, Sample 691, Loss: 2.5922\n",
            "Epoch 3, Sample 692, Loss: 2.4140\n",
            "Epoch 3, Sample 693, Loss: 1.5585\n",
            "Epoch 3, Sample 694, Loss: 2.9482\n",
            "Epoch 3, Sample 695, Loss: 2.3769\n",
            "Epoch 3, Sample 696, Loss: 2.3135\n",
            "Epoch 3, Sample 697, Loss: 2.1072\n",
            "Epoch 3, Sample 698, Loss: 2.1583\n",
            "Epoch 3, Sample 699, Loss: 3.5239\n",
            "Epoch 3, Sample 700, Loss: 2.6487\n",
            "Epoch 3, Sample 701, Loss: 2.1012\n",
            "Epoch 3, Sample 702, Loss: 1.9955\n",
            "Epoch 3, Sample 703, Loss: 2.5382\n",
            "Epoch 3, Sample 704, Loss: 2.6248\n",
            "Epoch 3, Sample 705, Loss: 2.6235\n",
            "Epoch 3, Sample 706, Loss: 3.3631\n",
            "Epoch 3, Sample 707, Loss: 2.7661\n",
            "Epoch 3, Sample 708, Loss: 2.9011\n",
            "Epoch 3, Sample 709, Loss: 2.4766\n",
            "Epoch 3, Sample 710, Loss: 2.7189\n",
            "Epoch 3, Sample 711, Loss: 1.6104\n",
            "Epoch 3, Sample 712, Loss: 2.4461\n",
            "Epoch 3, Sample 713, Loss: 3.3073\n",
            "Epoch 3, Sample 714, Loss: 2.5884\n",
            "Epoch 3, Sample 715, Loss: 2.0705\n",
            "Epoch 3, Sample 716, Loss: 2.5048\n",
            "Epoch 3, Sample 717, Loss: 2.5168\n",
            "Epoch 3, Sample 718, Loss: 2.7667\n",
            "Epoch 3, Sample 719, Loss: 2.7695\n",
            "Epoch 3, Sample 720, Loss: 2.7302\n",
            "Epoch 3, Sample 721, Loss: 2.4971\n",
            "Epoch 3, Sample 722, Loss: 2.1409\n",
            "Epoch 3, Sample 723, Loss: 3.1560\n",
            "Epoch 3, Sample 724, Loss: 2.9552\n",
            "Epoch 3, Sample 725, Loss: 2.2293\n",
            "Epoch 3, Sample 726, Loss: 2.4132\n",
            "Epoch 3, Sample 727, Loss: 2.9158\n",
            "Epoch 3, Sample 728, Loss: 2.9464\n",
            "Epoch 3, Sample 729, Loss: 3.5531\n",
            "Epoch 3, Sample 730, Loss: 2.5556\n",
            "Epoch 3, Sample 731, Loss: 2.5367\n",
            "Epoch 3, Sample 732, Loss: 3.1544\n",
            "Epoch 3, Sample 733, Loss: 1.5659\n",
            "Epoch 3, Sample 734, Loss: 3.0183\n",
            "Epoch 3, Sample 735, Loss: 2.9029\n",
            "Epoch 3, Sample 736, Loss: 2.5535\n",
            "Epoch 3, Sample 737, Loss: 1.7719\n",
            "Epoch 3, Sample 738, Loss: 2.2884\n",
            "Epoch 3, Sample 739, Loss: 2.4593\n",
            "Epoch 3, Sample 740, Loss: 2.2822\n",
            "Epoch 3, Sample 741, Loss: 2.1812\n",
            "Epoch 3, Sample 742, Loss: 2.1648\n",
            "Epoch 3, Sample 743, Loss: 2.9904\n",
            "Epoch 3, Sample 744, Loss: 2.9625\n",
            "Epoch 3, Sample 745, Loss: 3.0686\n",
            "Epoch 3, Sample 746, Loss: 2.5388\n",
            "Epoch 3, Sample 747, Loss: 3.3528\n",
            "Epoch 3, Sample 748, Loss: 2.8214\n",
            "Epoch 3, Sample 749, Loss: 2.1053\n",
            "Epoch 3, Sample 750, Loss: 2.9821\n",
            "Epoch 3, Sample 751, Loss: 1.9709\n",
            "Epoch 3, Sample 752, Loss: 2.0162\n",
            "Epoch 3, Sample 753, Loss: 2.8929\n",
            "Epoch 3, Sample 754, Loss: 2.8880\n",
            "Epoch 3, Sample 755, Loss: 2.8609\n",
            "Epoch 3, Sample 756, Loss: 2.7745\n",
            "Epoch 3, Sample 757, Loss: 3.3740\n",
            "Epoch 3, Sample 758, Loss: 2.8005\n",
            "Epoch 3, Sample 759, Loss: 2.7981\n",
            "Epoch 3, Sample 760, Loss: 2.7006\n",
            "Epoch 3, Sample 761, Loss: 2.4194\n",
            "Epoch 3, Sample 762, Loss: 3.3846\n",
            "Epoch 3, Sample 763, Loss: 2.3842\n",
            "Epoch 3, Sample 764, Loss: 2.7221\n",
            "Epoch 3, Sample 765, Loss: 2.7347\n",
            "Epoch 3, Sample 766, Loss: 2.9394\n",
            "Epoch 3, Sample 767, Loss: 2.5204\n",
            "Epoch 3, Sample 768, Loss: 2.8256\n",
            "Epoch 3, Sample 769, Loss: 2.4883\n",
            "Epoch 3, Sample 770, Loss: 3.3773\n",
            "Epoch 3, Sample 771, Loss: 2.4122\n",
            "Epoch 3, Sample 772, Loss: 2.9467\n",
            "Epoch 3, Sample 773, Loss: 1.8701\n",
            "Epoch 3, Sample 774, Loss: 2.5324\n",
            "Epoch 3, Sample 775, Loss: 2.4087\n",
            "Epoch 3, Sample 776, Loss: 2.1891\n",
            "Epoch 3, Sample 777, Loss: 2.4557\n",
            "Epoch 3, Sample 778, Loss: 2.5989\n",
            "Epoch 3, Sample 779, Loss: 2.1337\n",
            "Epoch 3, Sample 780, Loss: 2.6760\n",
            "Epoch 3, Sample 781, Loss: 2.3424\n",
            "Epoch 3, Sample 782, Loss: 2.6280\n",
            "Epoch 3, Sample 783, Loss: 3.3539\n",
            "Epoch 3, Sample 784, Loss: 1.3095\n",
            "Epoch 3, Sample 785, Loss: 2.3218\n",
            "Epoch 3, Sample 786, Loss: 2.4262\n",
            "Epoch 3, Sample 787, Loss: 2.1497\n",
            "Epoch 3, Sample 788, Loss: 2.5679\n",
            "Epoch 3, Sample 789, Loss: 2.7759\n",
            "Epoch 3, Sample 790, Loss: 2.1575\n",
            "Epoch 3, Sample 791, Loss: 3.1571\n",
            "Epoch 3, Sample 792, Loss: 2.5529\n",
            "Epoch 3, Sample 793, Loss: 1.8214\n",
            "Epoch 3, Sample 794, Loss: 2.7684\n",
            "Epoch 3, Sample 795, Loss: 3.0924\n",
            "Epoch 3, Sample 796, Loss: 2.5810\n",
            "Epoch 3, Sample 797, Loss: 3.3590\n",
            "Epoch 3, Sample 798, Loss: 3.3418\n",
            "Epoch 3, Sample 799, Loss: 4.1739\n",
            "Epoch 3, Sample 800, Loss: 3.1925\n",
            "Epoch 3, Sample 801, Loss: 2.9246\n",
            "Epoch 3, Sample 802, Loss: 2.0063\n",
            "Epoch 3, Sample 803, Loss: 2.3124\n",
            "Epoch 3, Sample 804, Loss: 2.0595\n",
            "Epoch 3, Sample 805, Loss: 3.1047\n",
            "Epoch 3, Sample 806, Loss: 2.7832\n",
            "Epoch 3, Sample 807, Loss: 1.9536\n",
            "Epoch 3, Sample 808, Loss: 3.6312\n",
            "Epoch 3, Sample 809, Loss: 2.4106\n",
            "Epoch 3, Sample 810, Loss: 2.9151\n",
            "Epoch 3, Sample 811, Loss: 2.5324\n",
            "Epoch 3, Sample 812, Loss: 1.9875\n",
            "Epoch 3, Sample 813, Loss: 2.8788\n",
            "Epoch 3, Sample 814, Loss: 2.6489\n",
            "Epoch 3, Sample 815, Loss: 3.0445\n",
            "Epoch 3, Sample 816, Loss: 2.4898\n",
            "Epoch 3, Sample 817, Loss: 3.0944\n",
            "Epoch 3, Sample 818, Loss: 2.6413\n",
            "Epoch 3, Sample 819, Loss: 2.3139\n",
            "Epoch 3, Sample 820, Loss: 2.3440\n",
            "Epoch 3, Sample 821, Loss: 3.2753\n",
            "Epoch 3, Sample 822, Loss: 2.5486\n",
            "Epoch 3, Sample 823, Loss: 1.3078\n",
            "Epoch 3, Sample 824, Loss: 3.2890\n",
            "Epoch 3, Sample 825, Loss: 2.2170\n",
            "Epoch 3, Sample 826, Loss: 2.7466\n",
            "Epoch 3, Sample 827, Loss: 2.4374\n",
            "Epoch 3, Sample 828, Loss: 3.1774\n",
            "Epoch 3, Sample 829, Loss: 1.9316\n",
            "Epoch 3, Sample 830, Loss: 3.0991\n",
            "Epoch 3, Sample 831, Loss: 3.0288\n",
            "Epoch 3, Sample 832, Loss: 1.9281\n",
            "Epoch 3, Sample 833, Loss: 3.2867\n",
            "Epoch 3, Sample 834, Loss: 3.1541\n",
            "Epoch 3, Sample 835, Loss: 2.5768\n",
            "Epoch 3, Sample 836, Loss: 2.9280\n",
            "Epoch 3, Sample 837, Loss: 2.6433\n",
            "Epoch 3, Sample 838, Loss: 2.9821\n",
            "Epoch 3, Sample 839, Loss: 2.9403\n",
            "Epoch 3, Sample 840, Loss: 2.9176\n",
            "Epoch 3, Sample 841, Loss: 2.0763\n",
            "Epoch 3, Sample 842, Loss: 2.9723\n",
            "Epoch 3, Sample 843, Loss: 2.3547\n",
            "Epoch 3, Sample 844, Loss: 2.2194\n",
            "Epoch 3, Sample 845, Loss: 2.5818\n",
            "Epoch 3, Sample 846, Loss: 2.7469\n",
            "Epoch 3, Sample 847, Loss: 2.5225\n",
            "Epoch 3, Sample 848, Loss: 3.2785\n",
            "Epoch 3, Sample 849, Loss: 3.3696\n",
            "Epoch 3, Sample 850, Loss: 2.8302\n",
            "Epoch 3, Sample 851, Loss: 1.9988\n",
            "Epoch 3, Sample 852, Loss: 2.3323\n",
            "Epoch 3, Sample 853, Loss: 2.5563\n",
            "Epoch 3, Sample 854, Loss: 3.2971\n",
            "Epoch 3, Sample 855, Loss: 2.5801\n",
            "Epoch 3, Sample 856, Loss: 2.0588\n",
            "Epoch 3, Sample 857, Loss: 3.4427\n",
            "Epoch 3, Sample 858, Loss: 1.9525\n",
            "Epoch 3, Sample 859, Loss: 2.6542\n",
            "Epoch 3, Sample 860, Loss: 2.3000\n",
            "Epoch 3, Sample 861, Loss: 2.4815\n",
            "Epoch 3, Sample 862, Loss: 2.6671\n",
            "Epoch 3, Sample 863, Loss: 2.6172\n",
            "Epoch 3, Sample 864, Loss: 3.2181\n",
            "Epoch 3, Sample 865, Loss: 2.6299\n",
            "Epoch 3, Sample 866, Loss: 2.4056\n",
            "Epoch 3, Sample 867, Loss: 2.6965\n",
            "Epoch 3, Sample 868, Loss: 3.3228\n",
            "Epoch 3, Sample 869, Loss: 2.7199\n",
            "Epoch 3, Sample 870, Loss: 2.5088\n",
            "Epoch 3, Sample 871, Loss: 3.0978\n",
            "Epoch 3, Sample 872, Loss: 2.7665\n",
            "Epoch 3, Sample 873, Loss: 1.7043\n",
            "Epoch 3, Sample 874, Loss: 1.9196\n",
            "Epoch 3, Sample 875, Loss: 2.8915\n",
            "Epoch 3, Sample 876, Loss: 2.3956\n",
            "Epoch 3, Sample 877, Loss: 1.9677\n",
            "Epoch 3, Sample 878, Loss: 3.3308\n",
            "Epoch 3, Sample 879, Loss: 2.7458\n",
            "Epoch 3, Sample 880, Loss: 2.2655\n",
            "Epoch 3, Sample 881, Loss: 2.2981\n",
            "Epoch 3, Sample 882, Loss: 2.4914\n",
            "Epoch 3, Sample 883, Loss: 2.7980\n",
            "Epoch 3, Sample 884, Loss: 2.4311\n",
            "Epoch 3, Sample 885, Loss: 2.2265\n",
            "Epoch 3, Sample 886, Loss: 2.4757\n",
            "Epoch 3, Sample 887, Loss: 3.6829\n",
            "Epoch 3, Sample 888, Loss: 2.7951\n",
            "Epoch 3, Sample 889, Loss: 2.4401\n",
            "Epoch 3, Sample 890, Loss: 2.9696\n",
            "Epoch 3, Sample 891, Loss: 2.5319\n",
            "Epoch 3, Sample 892, Loss: 3.2244\n",
            "Epoch 3, Sample 893, Loss: 3.0359\n",
            "Epoch 3, Sample 894, Loss: 2.8035\n",
            "Epoch 3, Sample 895, Loss: 1.9192\n",
            "Epoch 3, Sample 896, Loss: 2.7066\n",
            "Epoch 3, Sample 897, Loss: 2.5552\n",
            "Epoch 3, Sample 898, Loss: 2.1071\n",
            "Epoch 3, Sample 899, Loss: 2.4442\n",
            "Epoch 3, Sample 900, Loss: 2.3842\n",
            "Epoch 3, Sample 901, Loss: 2.7448\n",
            "Epoch 3, Sample 902, Loss: 2.9928\n",
            "Epoch 3, Sample 903, Loss: 2.7906\n",
            "Epoch 3, Sample 904, Loss: 2.0940\n",
            "Epoch 3, Sample 905, Loss: 1.9257\n",
            "Epoch 3, Sample 906, Loss: 2.3074\n",
            "Epoch 3, Sample 907, Loss: 2.5586\n",
            "Epoch 3, Sample 908, Loss: 2.6137\n",
            "Epoch 3, Sample 909, Loss: 1.9902\n",
            "Epoch 3, Sample 910, Loss: 3.4607\n",
            "Epoch 3, Sample 911, Loss: 3.0389\n",
            "Epoch 3, Sample 912, Loss: 2.0226\n",
            "Epoch 3, Sample 913, Loss: 2.5171\n",
            "Epoch 3, Sample 914, Loss: 3.1388\n",
            "Epoch 3, Sample 915, Loss: 3.5616\n",
            "Epoch 3, Sample 916, Loss: 2.7584\n",
            "Epoch 3, Sample 917, Loss: 2.6994\n",
            "Epoch 3, Sample 918, Loss: 2.3884\n",
            "Epoch 3, Sample 919, Loss: 2.7836\n",
            "Epoch 3, Sample 920, Loss: 3.0664\n",
            "Epoch 3, Sample 921, Loss: 2.5273\n",
            "Epoch 3, Sample 922, Loss: 2.7045\n",
            "Epoch 3, Sample 923, Loss: 2.3485\n",
            "Epoch 3, Sample 924, Loss: 2.3659\n",
            "Epoch 3, Sample 925, Loss: 2.7320\n",
            "Epoch 3, Sample 926, Loss: 2.9288\n",
            "Epoch 3, Sample 927, Loss: 2.5962\n",
            "Epoch 3, Sample 928, Loss: 2.4185\n",
            "Epoch 3, Sample 929, Loss: 2.3378\n",
            "Epoch 3, Sample 930, Loss: 2.9090\n",
            "Epoch 3, Sample 931, Loss: 2.8158\n",
            "Epoch 3, Sample 932, Loss: 1.8892\n",
            "Epoch 3, Sample 933, Loss: 2.2597\n",
            "Epoch 3, Sample 934, Loss: 2.2244\n",
            "Epoch 3, Sample 935, Loss: 2.6582\n",
            "Epoch 3, Sample 936, Loss: 2.5270\n",
            "Epoch 3, Sample 937, Loss: 2.4171\n",
            "Epoch 3, Sample 938, Loss: 2.2810\n",
            "Epoch 3, Sample 939, Loss: 2.6375\n",
            "Epoch 3, Sample 940, Loss: 2.3908\n",
            "Epoch 3, Sample 941, Loss: 2.2845\n",
            "Epoch 3, Sample 942, Loss: 2.1066\n",
            "Epoch 3, Sample 943, Loss: 2.0086\n",
            "Epoch 3, Sample 944, Loss: 2.6525\n",
            "Epoch 3, Sample 945, Loss: 2.3464\n",
            "Epoch 3, Sample 946, Loss: 2.0868\n",
            "Epoch 3, Sample 947, Loss: 1.9634\n",
            "Epoch 3, Sample 948, Loss: 3.7796\n",
            "Epoch 3, Sample 949, Loss: 3.1814\n",
            "Epoch 3, Sample 950, Loss: 2.5228\n",
            "Epoch 3, Sample 951, Loss: 2.3024\n",
            "Epoch 3, Sample 952, Loss: 3.0652\n",
            "Epoch 3, Sample 953, Loss: 3.2068\n",
            "Epoch 3, Sample 954, Loss: 2.8415\n",
            "Epoch 3, Sample 955, Loss: 2.2425\n",
            "Epoch 3, Sample 956, Loss: 3.1346\n",
            "Epoch 3, Sample 957, Loss: 2.4441\n",
            "Epoch 3, Sample 958, Loss: 2.5167\n",
            "Epoch 3, Sample 959, Loss: 2.8239\n",
            "Epoch 3, Sample 960, Loss: 2.4712\n",
            "Epoch 3, Sample 961, Loss: 2.9585\n",
            "Epoch 3, Sample 962, Loss: 2.6937\n",
            "Epoch 3, Sample 963, Loss: 2.5047\n",
            "Epoch 3, Sample 964, Loss: 2.0797\n",
            "Epoch 3, Sample 965, Loss: 1.8033\n",
            "Epoch 3, Sample 966, Loss: 2.8537\n",
            "Epoch 3, Sample 967, Loss: 2.2302\n",
            "Epoch 3, Sample 968, Loss: 2.6023\n",
            "Epoch 3, Sample 969, Loss: 2.4016\n",
            "Epoch 3, Sample 970, Loss: 2.9430\n",
            "Epoch 3, Sample 971, Loss: 2.6063\n",
            "Epoch 3, Sample 972, Loss: 2.6451\n",
            "Epoch 3, Sample 973, Loss: 3.0617\n",
            "Epoch 3, Sample 974, Loss: 2.5534\n",
            "Epoch 3, Sample 975, Loss: 2.4821\n",
            "Epoch 3, Sample 976, Loss: 1.7665\n",
            "Epoch 3, Sample 977, Loss: 2.7355\n",
            "Epoch 3, Sample 978, Loss: 1.8686\n",
            "Epoch 3, Sample 979, Loss: 2.9639\n",
            "Epoch 3, Sample 980, Loss: 2.8487\n",
            "Epoch 3, Sample 981, Loss: 2.4395\n",
            "Epoch 3, Sample 982, Loss: 2.3024\n",
            "Epoch 3, Sample 983, Loss: 3.0983\n",
            "Epoch 3, Sample 984, Loss: 2.3160\n",
            "Epoch 3, Sample 985, Loss: 2.3177\n",
            "Epoch 3, Sample 986, Loss: 2.3582\n",
            "Epoch 3, Sample 987, Loss: 2.9650\n",
            "Epoch 3, Sample 988, Loss: 2.6326\n",
            "Epoch 3, Sample 989, Loss: 3.0773\n",
            "Epoch 3, Sample 990, Loss: 2.5497\n",
            "Epoch 3, Sample 991, Loss: 2.6664\n",
            "Epoch 3, Sample 992, Loss: 2.7791\n",
            "Epoch 3, Sample 993, Loss: 2.0558\n",
            "Epoch 3, Sample 994, Loss: 3.4919\n",
            "Epoch 3, Sample 995, Loss: 2.2441\n",
            "Epoch 3, Sample 996, Loss: 2.8676\n",
            "Epoch 3, Sample 997, Loss: 2.6377\n",
            "Epoch 3, Sample 998, Loss: 3.1054\n",
            "Epoch 3, Sample 999, Loss: 2.4632\n",
            "Epoch 3, Sample 1000, Loss: 2.1796\n",
            "Epoch 3, Sample 1001, Loss: 2.9973\n",
            "Epoch 3, Sample 1002, Loss: 3.4495\n",
            "Epoch 3, Sample 1003, Loss: 2.8505\n",
            "Epoch 3, Sample 1004, Loss: 2.9756\n",
            "Epoch 3, Sample 1005, Loss: 2.3639\n",
            "Epoch 3, Sample 1006, Loss: 3.1909\n",
            "Epoch 3, Sample 1007, Loss: 2.7725\n",
            "Epoch 3, Sample 1008, Loss: 2.7617\n",
            "Epoch 3, Sample 1009, Loss: 2.6608\n",
            "Epoch 3, Sample 1010, Loss: 2.1794\n",
            "Epoch 3, Sample 1011, Loss: 2.5016\n",
            "Epoch 3, Sample 1012, Loss: 2.9191\n",
            "Epoch 3, Sample 1013, Loss: 1.9040\n",
            "Epoch 3, Sample 1014, Loss: 2.8624\n",
            "Epoch 3, Sample 1015, Loss: 3.3535\n",
            "Epoch 3, Sample 1016, Loss: 2.9423\n",
            "Epoch 3, Sample 1017, Loss: 3.2758\n",
            "Epoch 3, Sample 1018, Loss: 3.1090\n",
            "Epoch 3, Sample 1019, Loss: 2.8680\n",
            "Epoch 3, Sample 1020, Loss: 2.3626\n",
            "Epoch 3, Sample 1021, Loss: 2.3807\n",
            "Epoch 3, Sample 1022, Loss: 2.3347\n",
            "Epoch 3, Sample 1023, Loss: 2.2558\n",
            "Epoch 3, Sample 1024, Loss: 2.4699\n",
            "Epoch 3, Sample 1025, Loss: 2.8004\n",
            "Epoch 3, Sample 1026, Loss: 2.1378\n",
            "Epoch 3, Sample 1027, Loss: 2.8179\n",
            "Epoch 3, Sample 1028, Loss: 2.5138\n",
            "Epoch 3, Sample 1029, Loss: 1.9684\n",
            "Epoch 3, Sample 1030, Loss: 1.6058\n",
            "Epoch 3, Sample 1031, Loss: 2.7564\n",
            "Epoch 3, Sample 1032, Loss: 2.6366\n",
            "Epoch 3, Sample 1033, Loss: 2.2847\n",
            "Epoch 3, Sample 1034, Loss: 2.7099\n",
            "Epoch 3, Sample 1035, Loss: 2.1443\n",
            "Epoch 3, Sample 1036, Loss: 2.2510\n",
            "Epoch 3, Sample 1037, Loss: 2.5541\n",
            "Epoch 3, Sample 1038, Loss: 1.9719\n",
            "Epoch 3, Sample 1039, Loss: 2.3531\n",
            "Epoch 3, Sample 1040, Loss: 2.4537\n",
            "Epoch 3, Sample 1041, Loss: 2.0856\n",
            "Epoch 3, Sample 1042, Loss: 1.9418\n",
            "Epoch 3, Sample 1043, Loss: 1.6873\n",
            "Epoch 3, Sample 1044, Loss: 1.8198\n",
            "Epoch 3, Sample 1045, Loss: 2.1713\n",
            "Epoch 3, Sample 1046, Loss: 2.2090\n",
            "Epoch 3, Sample 1047, Loss: 2.7790\n",
            "Epoch 3, Sample 1048, Loss: 2.1269\n",
            "Epoch 3, Sample 1049, Loss: 2.2213\n",
            "Epoch 3, Sample 1050, Loss: 1.4274\n",
            "Epoch 3, Sample 1051, Loss: 1.9715\n",
            "Epoch 3, Sample 1052, Loss: 2.3596\n",
            "Epoch 3, Sample 1053, Loss: 2.4468\n",
            "Epoch 3, Sample 1054, Loss: 2.2181\n",
            "Epoch 3, Sample 1055, Loss: 2.6125\n",
            "Epoch 3, Sample 1056, Loss: 3.0570\n",
            "Epoch 3, Sample 1057, Loss: 3.3790\n",
            "Epoch 3, Sample 1058, Loss: 2.9951\n",
            "Epoch 3, Sample 1059, Loss: 2.7492\n",
            "Epoch 3, Sample 1060, Loss: 2.2198\n",
            "Epoch 3, Sample 1061, Loss: 2.6861\n",
            "Epoch 3, Sample 1062, Loss: 2.6307\n",
            "Epoch 3, Sample 1063, Loss: 2.3046\n",
            "Epoch 3, Sample 1064, Loss: 2.3380\n",
            "Epoch 3, Sample 1065, Loss: 1.9372\n",
            "Epoch 3, Sample 1066, Loss: 1.6233\n",
            "Epoch 3, Sample 1067, Loss: 1.9795\n",
            "Epoch 3, Sample 1068, Loss: 2.0350\n",
            "Epoch 3, Sample 1069, Loss: 1.4065\n",
            "Epoch 3, Sample 1070, Loss: 2.4160\n",
            "Epoch 3, Sample 1071, Loss: 2.0451\n",
            "Epoch 3, Sample 1072, Loss: 3.0421\n",
            "Epoch 3, Sample 1073, Loss: 1.8363\n",
            "Epoch 3, Sample 1074, Loss: 2.7528\n",
            "Epoch 3, Sample 1075, Loss: 1.9414\n",
            "Epoch 3, Sample 1076, Loss: 3.3917\n",
            "Epoch 3, Sample 1077, Loss: 3.0588\n",
            "Epoch 3, Sample 1078, Loss: 1.8637\n",
            "Epoch 3, Sample 1079, Loss: 2.8285\n",
            "Epoch 3, Sample 1080, Loss: 2.2403\n",
            "Epoch 3, Sample 1081, Loss: 2.2937\n",
            "Epoch 3, Sample 1082, Loss: 3.8967\n",
            "Epoch 3, Sample 1083, Loss: 2.3227\n",
            "Epoch 3, Sample 1084, Loss: 1.4362\n",
            "Epoch 3, Sample 1085, Loss: 1.9121\n",
            "Epoch 3, Sample 1086, Loss: 2.8511\n",
            "Epoch 3, Sample 1087, Loss: 3.5896\n",
            "Epoch 3, Sample 1088, Loss: 2.7288\n",
            "Epoch 3, Sample 1089, Loss: 1.7027\n",
            "Epoch 3, Sample 1090, Loss: 2.0887\n",
            "Epoch 3, Sample 1091, Loss: 2.2455\n",
            "Epoch 3, Sample 1092, Loss: 2.3454\n",
            "Epoch 3, Sample 1093, Loss: 2.1926\n",
            "Epoch 3, Sample 1094, Loss: 2.3902\n",
            "Epoch 3, Sample 1095, Loss: 2.1472\n",
            "Epoch 3, Sample 1096, Loss: 3.3113\n",
            "Epoch 3, Sample 1097, Loss: 2.6519\n",
            "Epoch 3, Sample 1098, Loss: 2.2669\n",
            "Epoch 3, Sample 1099, Loss: 2.1614\n",
            "Epoch 3, Sample 1100, Loss: 2.7287\n",
            "Epoch 3, Sample 1101, Loss: 1.6066\n",
            "Epoch 3, Sample 1102, Loss: 1.9443\n",
            "Epoch 3, Sample 1103, Loss: 1.9890\n",
            "Epoch 3, Sample 1104, Loss: 2.5304\n",
            "Epoch 3, Sample 1105, Loss: 2.0489\n",
            "Epoch 3, Sample 1106, Loss: 2.2121\n",
            "Epoch 3, Sample 1107, Loss: 2.8652\n",
            "Epoch 3, Sample 1108, Loss: 2.9160\n",
            "Epoch 3, Sample 1109, Loss: 1.7341\n",
            "Epoch 3, Sample 1110, Loss: 1.9243\n",
            "Epoch 3, Sample 1111, Loss: 2.4929\n",
            "Epoch 3, Sample 1112, Loss: 1.3418\n",
            "Epoch 3, Sample 1113, Loss: 1.8102\n",
            "Epoch 3, Sample 1114, Loss: 1.8441\n",
            "Epoch 3, Sample 1115, Loss: 3.6712\n",
            "Epoch 3, Sample 1116, Loss: 3.8005\n",
            "Epoch 3, Sample 1117, Loss: 2.3651\n",
            "Epoch 3, Sample 1118, Loss: 1.8578\n",
            "Epoch 3, Sample 1119, Loss: 2.1569\n",
            "Epoch 3, Sample 1120, Loss: 2.6649\n",
            "Epoch 3, Sample 1121, Loss: 2.2062\n",
            "Epoch 3, Sample 1122, Loss: 2.5496\n",
            "Epoch 3, Sample 1123, Loss: 2.0478\n",
            "Epoch 3, Sample 1124, Loss: 1.6144\n",
            "Epoch 3, Sample 1125, Loss: 2.5521\n",
            "Epoch 3, Sample 1126, Loss: 1.9274\n",
            "Epoch 3, Sample 1127, Loss: 2.2342\n",
            "Epoch 3, Sample 1128, Loss: 1.7573\n",
            "Epoch 3, Sample 1129, Loss: 3.1522\n",
            "Epoch 3, Sample 1130, Loss: 2.4556\n",
            "Epoch 3, Sample 1131, Loss: 2.4747\n",
            "Epoch 3, Sample 1132, Loss: 3.6183\n",
            "Epoch 3, Sample 1133, Loss: 2.3458\n",
            "Epoch 3, Sample 1134, Loss: 3.1918\n",
            "Epoch 3, Sample 1135, Loss: 3.0585\n",
            "Epoch 3, Sample 1136, Loss: 3.2062\n",
            "Epoch 3, Sample 1137, Loss: 3.1194\n",
            "Epoch 3, Sample 1138, Loss: 2.7899\n",
            "Epoch 3, Sample 1139, Loss: 2.7141\n",
            "Epoch 3, Sample 1140, Loss: 2.0949\n",
            "Epoch 3, Sample 1141, Loss: 2.7320\n",
            "Epoch 3, Sample 1142, Loss: 2.8660\n",
            "Epoch 3, Sample 1143, Loss: 2.6401\n",
            "Epoch 3, Sample 1144, Loss: 1.6848\n",
            "Epoch 3, Sample 1145, Loss: 1.9054\n",
            "Epoch 3, Sample 1146, Loss: 2.4772\n",
            "Epoch 3, Sample 1147, Loss: 3.3810\n",
            "Epoch 3, Sample 1148, Loss: 2.4919\n",
            "Epoch 3, Sample 1149, Loss: 2.4863\n",
            "Epoch 3, Sample 1150, Loss: 2.2080\n",
            "Epoch 3, Sample 1151, Loss: 2.1215\n",
            "Epoch 3, Sample 1152, Loss: 1.9410\n",
            "Epoch 3, Sample 1153, Loss: 2.4091\n",
            "Epoch 3, Sample 1154, Loss: 2.4244\n",
            "Epoch 3, Sample 1155, Loss: 2.3232\n",
            "Epoch 3, Sample 1156, Loss: 2.5367\n",
            "Epoch 3, Sample 1157, Loss: 1.7477\n",
            "Epoch 3, Sample 1158, Loss: 2.3200\n",
            "Epoch 3, Sample 1159, Loss: 2.1389\n",
            "Epoch 3, Sample 1160, Loss: 2.8174\n",
            "Epoch 3, Sample 1161, Loss: 1.8956\n",
            "Epoch 3, Sample 1162, Loss: 2.8694\n",
            "Epoch 3, Sample 1163, Loss: 2.9586\n",
            "Epoch 3, Sample 1164, Loss: 2.9557\n",
            "Epoch 3, Sample 1165, Loss: 2.3712\n",
            "Epoch 3, Sample 1166, Loss: 2.1946\n",
            "Epoch 3, Sample 1167, Loss: 2.1446\n",
            "Epoch 3, Sample 1168, Loss: 2.8726\n",
            "Epoch 3, Sample 1169, Loss: 2.3093\n",
            "Epoch 3, Sample 1170, Loss: 2.5596\n",
            "Epoch 3, Sample 1171, Loss: 2.8079\n",
            "Epoch 3, Sample 1172, Loss: 1.8935\n",
            "Epoch 3, Sample 1173, Loss: 1.4511\n",
            "Epoch 3, Sample 1174, Loss: 2.9318\n",
            "Epoch 3, Sample 1175, Loss: 2.6221\n",
            "Epoch 3, Sample 1176, Loss: 2.7560\n",
            "Epoch 3, Sample 1177, Loss: 2.7492\n",
            "Epoch 3, Sample 1178, Loss: 1.8632\n",
            "Epoch 3, Sample 1179, Loss: 2.4198\n",
            "Epoch 3, Sample 1180, Loss: 2.7357\n",
            "Epoch 3, Sample 1181, Loss: 2.6738\n",
            "Epoch 3, Sample 1182, Loss: 2.1434\n",
            "Epoch 3, Sample 1183, Loss: 2.1196\n",
            "Epoch 3, Sample 1184, Loss: 2.1865\n",
            "Epoch 3, Sample 1185, Loss: 2.6290\n",
            "Epoch 3, Sample 1186, Loss: 2.1287\n",
            "Epoch 3, Sample 1187, Loss: 1.7990\n",
            "Epoch 3, Sample 1188, Loss: 2.7582\n",
            "Epoch 3, Sample 1189, Loss: 1.9611\n",
            "Epoch 3, Sample 1190, Loss: 2.0237\n",
            "Epoch 3, Sample 1191, Loss: 2.3064\n",
            "Epoch 3, Sample 1192, Loss: 2.3090\n",
            "Epoch 3, Sample 1193, Loss: 1.7746\n",
            "Epoch 3, Sample 1194, Loss: 2.7797\n",
            "Epoch 3, Sample 1195, Loss: 2.4928\n",
            "Epoch 3, Sample 1196, Loss: 2.1027\n",
            "Epoch 3, Sample 1197, Loss: 2.1585\n",
            "Epoch 3, Sample 1198, Loss: 2.6928\n",
            "Epoch 3, Sample 1199, Loss: 2.1458\n",
            "Epoch 3, Sample 1200, Loss: 2.3836\n",
            "Epoch 3, Sample 1201, Loss: 2.5270\n",
            "Epoch 3, Sample 1202, Loss: 2.2387\n",
            "Epoch 3, Sample 1203, Loss: 2.4660\n",
            "Epoch 3, Sample 1204, Loss: 2.2571\n",
            "Epoch 3, Sample 1205, Loss: 2.5102\n",
            "Epoch 3, Sample 1206, Loss: 2.7325\n",
            "Epoch 3, Sample 1207, Loss: 2.7518\n",
            "Epoch 3, Sample 1208, Loss: 2.7628\n",
            "Epoch 3, Sample 1209, Loss: 1.5378\n",
            "Epoch 3, Sample 1210, Loss: 2.0052\n",
            "Epoch 3, Sample 1211, Loss: 2.8749\n",
            "Epoch 3, Sample 1212, Loss: 1.9458\n",
            "Epoch 3, Sample 1213, Loss: 2.1020\n",
            "Epoch 3, Sample 1214, Loss: 2.1038\n",
            "Epoch 3, Sample 1215, Loss: 2.3363\n",
            "Epoch 3, Sample 1216, Loss: 2.0889\n",
            "Epoch 3, Sample 1217, Loss: 2.7836\n",
            "Epoch 3, Sample 1218, Loss: 2.3387\n",
            "Epoch 3, Sample 1219, Loss: 2.4904\n",
            "Epoch 3, Sample 1220, Loss: 2.6662\n",
            "Epoch 3, Sample 1221, Loss: 2.4499\n",
            "Epoch 3, Sample 1222, Loss: 3.2330\n",
            "Epoch 3, Sample 1223, Loss: 2.1763\n",
            "Epoch 3, Sample 1224, Loss: 2.1697\n",
            "Epoch 3, Sample 1225, Loss: 2.5348\n",
            "Epoch 3, Sample 1226, Loss: 3.3198\n",
            "Epoch 3, Sample 1227, Loss: 3.4431\n",
            "Epoch 3, Sample 1228, Loss: 2.2464\n",
            "Epoch 3, Sample 1229, Loss: 2.3677\n",
            "Epoch 3, Sample 1230, Loss: 3.3437\n",
            "Epoch 3, Sample 1231, Loss: 2.7411\n",
            "Epoch 3, Sample 1232, Loss: 2.8806\n",
            "Epoch 3, Sample 1233, Loss: 3.5625\n",
            "Epoch 3, Sample 1234, Loss: 2.4388\n",
            "Epoch 3, Sample 1235, Loss: 2.5475\n",
            "Epoch 3, Sample 1236, Loss: 2.5543\n",
            "Epoch 3, Sample 1237, Loss: 2.8014\n",
            "Epoch 3, Sample 1238, Loss: 2.6573\n",
            "Epoch 3, Sample 1239, Loss: 2.9253\n",
            "Epoch 3, Sample 1240, Loss: 3.3784\n",
            "Epoch 3, Sample 1241, Loss: 2.6564\n",
            "Epoch 3, Sample 1242, Loss: 3.8183\n",
            "Epoch 3, Sample 1243, Loss: 3.1366\n",
            "Epoch 3, Sample 1244, Loss: 3.2985\n",
            "Epoch 3, Sample 1245, Loss: 3.6346\n",
            "Epoch 3, Sample 1246, Loss: 2.7017\n",
            "Epoch 3, Sample 1247, Loss: 4.1237\n",
            "Epoch 3, Sample 1248, Loss: 3.8257\n",
            "Epoch 3, Sample 1249, Loss: 3.3652\n",
            "Epoch 3, Sample 1250, Loss: 2.9488\n",
            "Epoch 3, Sample 1251, Loss: 3.5677\n",
            "Epoch 3, Sample 1252, Loss: 3.8009\n",
            "Epoch 3, Sample 1253, Loss: 2.7838\n",
            "Epoch 3, Sample 1254, Loss: 2.8148\n",
            "Epoch 3, Sample 1255, Loss: 2.9280\n",
            "Epoch 3, Sample 1256, Loss: 2.6976\n",
            "Epoch 3, Sample 1257, Loss: 2.9975\n",
            "Epoch 3, Sample 1258, Loss: 1.7916\n",
            "Epoch 3, Sample 1259, Loss: 2.8832\n",
            "Epoch 3, Sample 1260, Loss: 3.4143\n",
            "Epoch 3, Sample 1261, Loss: 3.0804\n",
            "Epoch 3, Sample 1262, Loss: 3.0063\n",
            "Epoch 3, Sample 1263, Loss: 2.6808\n",
            "Epoch 3, Sample 1264, Loss: 2.4038\n",
            "Epoch 3, Sample 1265, Loss: 3.1105\n",
            "Epoch 3, Sample 1266, Loss: 3.1542\n",
            "Epoch 3, Sample 1267, Loss: 3.0860\n",
            "Epoch 3, Sample 1268, Loss: 2.8940\n",
            "Epoch 3, Sample 1269, Loss: 2.0266\n",
            "Epoch 3, Sample 1270, Loss: 3.0159\n",
            "Epoch 3, Sample 1271, Loss: 2.6852\n",
            "Epoch 3, Sample 1272, Loss: 3.2996\n",
            "Epoch 3, Sample 1273, Loss: 3.6952\n",
            "Epoch 3, Sample 1274, Loss: 3.8632\n",
            "Epoch 3, Sample 1275, Loss: 2.8322\n",
            "Epoch 3, Sample 1276, Loss: 3.0128\n",
            "Epoch 3, Sample 1277, Loss: 2.8382\n",
            "Epoch 3, Sample 1278, Loss: 2.9501\n",
            "Epoch 3, Sample 1279, Loss: 2.5789\n",
            "Epoch 3, Sample 1280, Loss: 2.8502\n",
            "Epoch 3, Sample 1281, Loss: 2.6819\n",
            "Epoch 3, Sample 1282, Loss: 2.7091\n",
            "Epoch 3, Sample 1283, Loss: 3.3826\n",
            "Epoch 3, Sample 1284, Loss: 3.1393\n",
            "Epoch 3, Sample 1285, Loss: 3.9553\n",
            "Epoch 3, Sample 1286, Loss: 2.7038\n",
            "Epoch 3, Sample 1287, Loss: 2.7276\n",
            "Epoch 3, Sample 1288, Loss: 2.7337\n",
            "Epoch 3, Sample 1289, Loss: 3.0942\n",
            "Epoch 3, Sample 1290, Loss: 3.0173\n",
            "Epoch 3, Sample 1291, Loss: 3.2129\n",
            "Epoch 3, Sample 1292, Loss: 2.8274\n",
            "Epoch 3, Sample 1293, Loss: 4.1201\n",
            "Epoch 3, Sample 1294, Loss: 3.6346\n",
            "Epoch 3, Sample 1295, Loss: 3.2169\n",
            "Epoch 3, Sample 1296, Loss: 3.2136\n",
            "Epoch 3, Sample 1297, Loss: 2.7661\n",
            "Epoch 3, Sample 1298, Loss: 3.2245\n",
            "Epoch 3, Sample 1299, Loss: 3.4194\n",
            "Epoch 3, Sample 1300, Loss: 3.6421\n",
            "Epoch 3, Sample 1301, Loss: 3.4922\n",
            "Epoch 3, Sample 1302, Loss: 2.9386\n",
            "Epoch 3, Sample 1303, Loss: 3.4854\n",
            "Epoch 3, Sample 1304, Loss: 2.7139\n",
            "Epoch 3, Sample 1305, Loss: 3.3359\n",
            "Epoch 3, Sample 1306, Loss: 2.5881\n",
            "Epoch 3, Sample 1307, Loss: 2.1972\n",
            "Epoch 3, Sample 1308, Loss: 2.6481\n",
            "Epoch 3, Sample 1309, Loss: 2.8478\n",
            "Epoch 3, Sample 1310, Loss: 2.1758\n",
            "Epoch 3, Sample 1311, Loss: 3.5043\n",
            "Epoch 3, Sample 1312, Loss: 3.3581\n",
            "Epoch 3, Sample 1313, Loss: 3.1207\n",
            "Epoch 3, Sample 1314, Loss: 3.0964\n",
            "Epoch 3, Sample 1315, Loss: 2.5411\n",
            "Epoch 3, Sample 1316, Loss: 2.5456\n",
            "Epoch 3, Sample 1317, Loss: 3.3708\n",
            "Epoch 3, Sample 1318, Loss: 3.0735\n",
            "Epoch 3, Sample 1319, Loss: 2.8775\n",
            "Epoch 3, Sample 1320, Loss: 2.9079\n",
            "Epoch 3, Sample 1321, Loss: 3.0099\n",
            "Epoch 3, Sample 1322, Loss: 3.0829\n",
            "Epoch 3, Sample 1323, Loss: 2.7152\n",
            "Epoch 3, Sample 1324, Loss: 3.0788\n",
            "Epoch 3, Sample 1325, Loss: 2.8513\n",
            "Epoch 3, Sample 1326, Loss: 3.0524\n",
            "Epoch 3, Sample 1327, Loss: 2.5553\n",
            "Epoch 3, Sample 1328, Loss: 2.9053\n",
            "Epoch 3, Sample 1329, Loss: 2.6783\n",
            "Epoch 3, Sample 1330, Loss: 2.7192\n",
            "Epoch 3, Sample 1331, Loss: 2.7395\n",
            "Epoch 3, Sample 1332, Loss: 2.3069\n",
            "Epoch 3, Sample 1333, Loss: 3.5605\n",
            "Epoch 3, Sample 1334, Loss: 3.3829\n",
            "Epoch 3, Sample 1335, Loss: 3.3867\n",
            "Epoch 3, Sample 1336, Loss: 2.2133\n",
            "Epoch 3, Sample 1337, Loss: 3.4483\n",
            "Epoch 3, Sample 1338, Loss: 2.7381\n",
            "Epoch 3, Sample 1339, Loss: 2.8223\n",
            "Epoch 3, Sample 1340, Loss: 3.0812\n",
            "Epoch 3, Sample 1341, Loss: 2.7596\n",
            "Epoch 3, Sample 1342, Loss: 3.2401\n",
            "Epoch 3, Sample 1343, Loss: 3.7976\n",
            "Epoch 3, Sample 1344, Loss: 3.6077\n",
            "Epoch 3, Sample 1345, Loss: 3.5487\n",
            "Epoch 3, Sample 1346, Loss: 2.7552\n",
            "Epoch 3, Sample 1347, Loss: 3.5712\n",
            "Epoch 3, Sample 1348, Loss: 2.3575\n",
            "Epoch 3, Sample 1349, Loss: 2.8991\n",
            "Epoch 3, Sample 1350, Loss: 2.9889\n",
            "Epoch 3, Sample 1351, Loss: 2.9648\n",
            "Epoch 3, Sample 1352, Loss: 2.8459\n",
            "Epoch 3, Sample 1353, Loss: 2.9781\n",
            "Epoch 3, Sample 1354, Loss: 3.0509\n",
            "Epoch 3, Sample 1355, Loss: 3.4764\n",
            "Epoch 3, Sample 1356, Loss: 2.7501\n",
            "Epoch 3, Sample 1357, Loss: 3.7455\n",
            "Epoch 3, Sample 1358, Loss: 3.6280\n",
            "Epoch 3, Sample 1359, Loss: 2.3695\n",
            "Epoch 3, Sample 1360, Loss: 2.3789\n",
            "Epoch 3, Sample 1361, Loss: 2.9269\n",
            "Epoch 3, Sample 1362, Loss: 3.0800\n",
            "Epoch 3, Sample 1363, Loss: 2.8663\n",
            "Epoch 3, Sample 1364, Loss: 2.9634\n",
            "Epoch 3, Sample 1365, Loss: 3.3100\n",
            "Epoch 3, Sample 1366, Loss: 2.5075\n",
            "Epoch 3, Sample 1367, Loss: 3.3873\n",
            "Epoch 3, Sample 1368, Loss: 3.0091\n",
            "Epoch 3, Sample 1369, Loss: 2.9686\n",
            "Epoch 3, Sample 1370, Loss: 2.3697\n",
            "Epoch 3, Sample 1371, Loss: 2.8391\n",
            "Epoch 3, Sample 1372, Loss: 2.9592\n",
            "Epoch 3, Sample 1373, Loss: 3.6364\n",
            "Epoch 3, Sample 1374, Loss: 3.0650\n",
            "Epoch 3, Sample 1375, Loss: 3.6892\n",
            "Epoch 3, Sample 1376, Loss: 3.4680\n",
            "Epoch 3, Sample 1377, Loss: 3.0615\n",
            "Epoch 3, Sample 1378, Loss: 3.8261\n",
            "Epoch 3, Sample 1379, Loss: 3.4876\n",
            "Epoch 3, Sample 1380, Loss: 2.3351\n",
            "Epoch 3, Sample 1381, Loss: 3.3043\n",
            "Epoch 3, Sample 1382, Loss: 3.6269\n",
            "Epoch 3, Sample 1383, Loss: 2.9061\n",
            "Epoch 3, Sample 1384, Loss: 3.1068\n",
            "Epoch 3, Sample 1385, Loss: 3.3635\n",
            "Epoch 3, Sample 1386, Loss: 3.1513\n",
            "Epoch 3, Sample 1387, Loss: 3.3188\n",
            "Epoch 3, Sample 1388, Loss: 2.8235\n",
            "Epoch 3, Sample 1389, Loss: 3.8500\n",
            "Epoch 3, Sample 1390, Loss: 3.3013\n",
            "Epoch 3, Sample 1391, Loss: 4.0660\n",
            "Epoch 3, Sample 1392, Loss: 2.8715\n",
            "Epoch 3, Sample 1393, Loss: 3.1745\n",
            "Epoch 3, Sample 1394, Loss: 2.9698\n",
            "Epoch 3, Sample 1395, Loss: 3.1187\n",
            "Epoch 3, Sample 1396, Loss: 2.8863\n",
            "Epoch 3, Sample 1397, Loss: 2.9297\n",
            "Epoch 3, Sample 1398, Loss: 2.9718\n",
            "Epoch 3, Sample 1399, Loss: 3.0171\n",
            "Epoch 3, Sample 1400, Loss: 2.7023\n",
            "Epoch 3, Sample 1401, Loss: 3.5574\n",
            "Epoch 3, Sample 1402, Loss: 3.1560\n",
            "Epoch 3, Sample 1403, Loss: 3.0060\n",
            "Epoch 3, Sample 1404, Loss: 3.1027\n",
            "Epoch 3, Sample 1405, Loss: 3.1339\n",
            "Epoch 3, Sample 1406, Loss: 3.5540\n",
            "Epoch 3, Sample 1407, Loss: 2.7245\n",
            "Epoch 3, Sample 1408, Loss: 2.6607\n",
            "Epoch 3, Sample 1409, Loss: 2.8871\n",
            "Epoch 3, Sample 1410, Loss: 3.4387\n",
            "Epoch 3, Sample 1411, Loss: 3.0392\n",
            "Epoch 3, Sample 1412, Loss: 3.3370\n",
            "Epoch 3, Sample 1413, Loss: 3.5083\n",
            "Epoch 3, Sample 1414, Loss: 2.6640\n",
            "Epoch 3, Sample 1415, Loss: 3.1324\n",
            "Epoch 3, Sample 1416, Loss: 2.5137\n",
            "Epoch 3, Sample 1417, Loss: 3.3357\n",
            "Epoch 3, Sample 1418, Loss: 3.3385\n",
            "Epoch 3, Sample 1419, Loss: 2.8778\n",
            "Epoch 3, Sample 1420, Loss: 3.6494\n",
            "Epoch 3, Sample 1421, Loss: 3.3470\n",
            "Epoch 3, Sample 1422, Loss: 3.5075\n",
            "Epoch 3, Sample 1423, Loss: 3.2084\n",
            "Epoch 3, Sample 1424, Loss: 3.2120\n",
            "Epoch 3, Sample 1425, Loss: 3.0897\n",
            "Epoch 3, Sample 1426, Loss: 3.2535\n",
            "Epoch 3, Sample 1427, Loss: 2.5301\n",
            "Epoch 3, Sample 1428, Loss: 3.3397\n",
            "Epoch 3, Sample 1429, Loss: 2.8983\n",
            "Epoch 3, Sample 1430, Loss: 2.9374\n",
            "Epoch 3, Sample 1431, Loss: 2.4944\n",
            "Epoch 3, Sample 1432, Loss: 3.8186\n",
            "Epoch 3, Sample 1433, Loss: 2.7433\n",
            "Epoch 3, Sample 1434, Loss: 3.0104\n",
            "Epoch 3, Sample 1435, Loss: 2.8358\n",
            "Epoch 3, Sample 1436, Loss: 2.3070\n",
            "Epoch 3, Sample 1437, Loss: 1.4967\n",
            "Epoch 3, Sample 1438, Loss: 2.4991\n",
            "Epoch 3, Sample 1439, Loss: 2.7477\n",
            "Epoch 3, Sample 1440, Loss: 2.7906\n",
            "Epoch 3, Sample 1441, Loss: 2.9179\n",
            "Epoch 3, Sample 1442, Loss: 2.7642\n",
            "Epoch 3, Sample 1443, Loss: 2.3775\n",
            "Epoch 3, Sample 1444, Loss: 2.0491\n",
            "Epoch 3, Sample 1445, Loss: 2.9975\n",
            "Epoch 3, Sample 1446, Loss: 3.5726\n",
            "Epoch 3, Sample 1447, Loss: 2.7686\n",
            "Epoch 3, Sample 1448, Loss: 2.7267\n",
            "Epoch 3, Sample 1449, Loss: 2.9082\n",
            "Epoch 3, Sample 1450, Loss: 2.7056\n",
            "Epoch 3, Sample 1451, Loss: 2.0767\n",
            "Epoch 3, Sample 1452, Loss: 2.8416\n",
            "Epoch 3, Sample 1453, Loss: 2.7820\n",
            "Epoch 3, Sample 1454, Loss: 2.2515\n",
            "Epoch 3, Sample 1455, Loss: 2.0865\n",
            "Epoch 3, Sample 1456, Loss: 2.6433\n",
            "Epoch 3, Sample 1457, Loss: 2.4900\n",
            "Epoch 3, Sample 1458, Loss: 2.4388\n",
            "Epoch 3, Sample 1459, Loss: 2.4532\n",
            "Epoch 3, Sample 1460, Loss: 2.2950\n",
            "Epoch 3, Sample 1461, Loss: 2.6302\n",
            "Epoch 3, Sample 1462, Loss: 2.6061\n",
            "Epoch 3, Sample 1463, Loss: 2.5953\n",
            "Epoch 3, Sample 1464, Loss: 2.7040\n",
            "Epoch 3, Sample 1465, Loss: 2.5699\n",
            "Epoch 3, Sample 1466, Loss: 3.1381\n",
            "Epoch 3, Sample 1467, Loss: 2.6292\n",
            "Epoch 3, Sample 1468, Loss: 3.1432\n",
            "Epoch 3, Sample 1469, Loss: 2.8157\n",
            "Epoch 3, Sample 1470, Loss: 3.2665\n",
            "Epoch 3, Sample 1471, Loss: 2.5592\n",
            "Epoch 3, Sample 1472, Loss: 2.0561\n",
            "Epoch 3, Sample 1473, Loss: 2.5583\n",
            "Epoch 3, Sample 1474, Loss: 2.6044\n",
            "Epoch 3, Sample 1475, Loss: 2.8153\n",
            "Epoch 3, Sample 1476, Loss: 3.7278\n",
            "Epoch 3, Sample 1477, Loss: 2.2928\n",
            "Epoch 3, Sample 1478, Loss: 2.2879\n",
            "Epoch 3, Sample 1479, Loss: 2.8137\n",
            "Epoch 3, Sample 1480, Loss: 2.7557\n",
            "Epoch 3, Sample 1481, Loss: 2.4786\n",
            "Epoch 3, Sample 1482, Loss: 2.9684\n",
            "Epoch 3, Sample 1483, Loss: 2.8152\n",
            "Epoch 3, Sample 1484, Loss: 2.4585\n",
            "Epoch 3, Sample 1485, Loss: 3.8237\n",
            "Epoch 3, Sample 1486, Loss: 2.0848\n",
            "Epoch 3, Sample 1487, Loss: 2.0510\n",
            "Epoch 3, Sample 1488, Loss: 3.1471\n",
            "Epoch 3, Sample 1489, Loss: 4.0852\n",
            "Epoch 3, Sample 1490, Loss: 2.7558\n",
            "Epoch 3, Sample 1491, Loss: 2.4934\n",
            "Epoch 3, Sample 1492, Loss: 2.7844\n",
            "Epoch 3, Sample 1493, Loss: 2.7120\n",
            "Epoch 3, Sample 1494, Loss: 2.5298\n",
            "Epoch 3, Sample 1495, Loss: 3.4102\n",
            "Epoch 3, Sample 1496, Loss: 2.3244\n",
            "Epoch 3, Sample 1497, Loss: 2.6868\n",
            "Epoch 3, Sample 1498, Loss: 2.5307\n",
            "Epoch 3, Sample 1499, Loss: 2.8341\n",
            "Epoch 3, Sample 1500, Loss: 3.0117\n",
            "Epoch 3, Sample 1501, Loss: 3.9857\n",
            "Epoch 3, Sample 1502, Loss: 2.3236\n",
            "Epoch 3, Sample 1503, Loss: 2.8431\n",
            "Epoch 3, Sample 1504, Loss: 2.3998\n",
            "Epoch 3, Sample 1505, Loss: 2.4468\n",
            "Epoch 3, Sample 1506, Loss: 2.9305\n",
            "Epoch 3, Sample 1507, Loss: 3.4376\n",
            "Epoch 3, Sample 1508, Loss: 3.4290\n",
            "Epoch 3, Sample 1509, Loss: 2.1072\n",
            "Epoch 3, Sample 1510, Loss: 2.6359\n",
            "Epoch 3, Sample 1511, Loss: 2.5726\n",
            "Epoch 3, Sample 1512, Loss: 2.7715\n",
            "Epoch 3, Sample 1513, Loss: 3.2549\n",
            "Epoch 3, Sample 1514, Loss: 3.0664\n",
            "Epoch 3, Sample 1515, Loss: 3.5193\n",
            "Epoch 3, Sample 1516, Loss: 2.1397\n",
            "Epoch 3, Sample 1517, Loss: 3.3408\n",
            "Epoch 3, Sample 1518, Loss: 2.9095\n",
            "Epoch 3, Sample 1519, Loss: 3.3482\n",
            "Epoch 3, Sample 1520, Loss: 2.2586\n",
            "Epoch 3, Sample 1521, Loss: 3.1209\n",
            "Epoch 3, Sample 1522, Loss: 2.2317\n",
            "Epoch 3, Sample 1523, Loss: 2.8655\n",
            "Epoch 3, Sample 1524, Loss: 2.1121\n",
            "Epoch 3, Sample 1525, Loss: 3.3114\n",
            "Epoch 3, Sample 1526, Loss: 2.8362\n",
            "Epoch 3, Sample 1527, Loss: 3.0979\n",
            "Epoch 3, Sample 1528, Loss: 3.0447\n",
            "Epoch 3, Sample 1529, Loss: 2.8960\n",
            "Epoch 3, Sample 1530, Loss: 2.0311\n",
            "Epoch 3, Sample 1531, Loss: 3.2699\n",
            "Epoch 3, Sample 1532, Loss: 3.3346\n",
            "Epoch 3, Sample 1533, Loss: 2.5154\n",
            "Epoch 3, Sample 1534, Loss: 3.5729\n",
            "Epoch 3, Sample 1535, Loss: 4.0405\n",
            "Epoch 3, Sample 1536, Loss: 3.4984\n",
            "Epoch 3, Sample 1537, Loss: 1.8066\n",
            "Epoch 3, Sample 1538, Loss: 3.4428\n",
            "Epoch 3, Sample 1539, Loss: 2.1925\n",
            "Epoch 3, Sample 1540, Loss: 1.8173\n",
            "Epoch 3, Sample 1541, Loss: 2.8221\n",
            "Epoch 3, Sample 1542, Loss: 2.8456\n",
            "Epoch 3, Sample 1543, Loss: 2.8935\n",
            "Epoch 3, Sample 1544, Loss: 3.3654\n",
            "Epoch 3, Sample 1545, Loss: 2.0699\n",
            "Epoch 3, Sample 1546, Loss: 2.9122\n",
            "Epoch 3, Sample 1547, Loss: 2.4248\n",
            "Epoch 3, Sample 1548, Loss: 2.8148\n",
            "Epoch 3, Sample 1549, Loss: 2.0389\n",
            "Epoch 3, Sample 1550, Loss: 3.3336\n",
            "Epoch 3, Sample 1551, Loss: 2.5057\n",
            "Epoch 3, Sample 1552, Loss: 3.0444\n",
            "Epoch 3, Sample 1553, Loss: 2.1610\n",
            "Epoch 3, Sample 1554, Loss: 3.2137\n",
            "Epoch 3, Sample 1555, Loss: 3.6600\n",
            "Epoch 3, Sample 1556, Loss: 1.7396\n",
            "Epoch 3, Sample 1557, Loss: 3.2937\n",
            "Epoch 3, Sample 1558, Loss: 2.7250\n",
            "Epoch 3, Sample 1559, Loss: 2.2490\n",
            "Epoch 3, Sample 1560, Loss: 2.8260\n",
            "Epoch 3, Sample 1561, Loss: 2.7626\n",
            "Epoch 3, Sample 1562, Loss: 2.9503\n",
            "Epoch 3, Sample 1563, Loss: 2.9729\n",
            "Epoch 3, Sample 1564, Loss: 2.2725\n",
            "Epoch 3, Sample 1565, Loss: 3.0080\n",
            "Epoch 3, Sample 1566, Loss: 3.9349\n",
            "Epoch 3, Sample 1567, Loss: 2.7817\n",
            "Epoch 3, Sample 1568, Loss: 2.8836\n",
            "Epoch 3, Sample 1569, Loss: 3.2115\n",
            "Epoch 3, Sample 1570, Loss: 3.9690\n",
            "Epoch 3, Sample 1571, Loss: 3.1125\n",
            "Epoch 3, Sample 1572, Loss: 3.8903\n",
            "Epoch 3, Sample 1573, Loss: 3.0461\n",
            "Epoch 3, Sample 1574, Loss: 3.3776\n",
            "Epoch 3, Sample 1575, Loss: 2.5884\n",
            "Epoch 3, Sample 1576, Loss: 2.9097\n",
            "Epoch 3, Sample 1577, Loss: 2.6865\n",
            "Epoch 3, Sample 1578, Loss: 3.1183\n",
            "Epoch 3, Sample 1579, Loss: 2.5292\n",
            "Epoch 3, Sample 1580, Loss: 2.2677\n",
            "Epoch 3, Sample 1581, Loss: 2.5852\n",
            "Epoch 3, Sample 1582, Loss: 2.8424\n",
            "Epoch 3, Sample 1583, Loss: 2.6053\n",
            "Epoch 3, Sample 1584, Loss: 1.9521\n",
            "Epoch 3, Sample 1585, Loss: 2.5066\n",
            "Epoch 3, Sample 1586, Loss: 2.1588\n",
            "Epoch 3, Sample 1587, Loss: 2.3625\n",
            "Epoch 3, Sample 1588, Loss: 2.9952\n",
            "Epoch 3, Sample 1589, Loss: 2.3895\n",
            "Epoch 3, Sample 1590, Loss: 2.5639\n",
            "Epoch 3, Sample 1591, Loss: 2.7492\n",
            "Epoch 3, Sample 1592, Loss: 2.4525\n",
            "Epoch 3, Sample 1593, Loss: 1.9553\n",
            "Epoch 3, Sample 1594, Loss: 2.3732\n",
            "Epoch 3, Sample 1595, Loss: 2.8540\n",
            "Epoch 3, Sample 1596, Loss: 2.7444\n",
            "Epoch 3, Sample 1597, Loss: 2.5846\n",
            "Epoch 3, Sample 1598, Loss: 3.2080\n",
            "Epoch 3, Sample 1599, Loss: 2.0569\n",
            "Epoch 3, Sample 1600, Loss: 2.8848\n",
            "Epoch 3, Sample 1601, Loss: 2.3759\n",
            "Epoch 3, Sample 1602, Loss: 2.7641\n",
            "Epoch 3, Sample 1603, Loss: 2.7993\n",
            "Epoch 3, Sample 1604, Loss: 3.2840\n",
            "Epoch 3, Sample 1605, Loss: 2.7670\n",
            "Epoch 3, Sample 1606, Loss: 2.8035\n",
            "Epoch 3, Sample 1607, Loss: 2.2224\n",
            "Epoch 3, Sample 1608, Loss: 2.5396\n",
            "Epoch 3, Sample 1609, Loss: 2.8958\n",
            "Epoch 3, Sample 1610, Loss: 3.6947\n",
            "Epoch 3, Sample 1611, Loss: 2.7329\n",
            "Epoch 3, Sample 1612, Loss: 3.2834\n",
            "Epoch 3, Sample 1613, Loss: 2.6014\n",
            "Epoch 3, Sample 1614, Loss: 2.6109\n",
            "Epoch 3, Sample 1615, Loss: 2.7941\n",
            "Epoch 3, Sample 1616, Loss: 3.3317\n",
            "Epoch 3, Sample 1617, Loss: 2.5970\n",
            "Epoch 3, Sample 1618, Loss: 3.5928\n",
            "Epoch 3, Sample 1619, Loss: 2.7364\n",
            "Epoch 3, Sample 1620, Loss: 3.0965\n",
            "Epoch 3, Sample 1621, Loss: 3.0833\n",
            "Epoch 3, Sample 1622, Loss: 2.6766\n",
            "Epoch 3, Sample 1623, Loss: 2.5372\n",
            "Epoch 3, Sample 1624, Loss: 2.3086\n",
            "Epoch 3, Sample 1625, Loss: 2.1349\n",
            "Epoch 3, Sample 1626, Loss: 3.6027\n",
            "Epoch 3, Sample 1627, Loss: 2.2217\n",
            "Epoch 3, Sample 1628, Loss: 2.3370\n",
            "Epoch 3, Sample 1629, Loss: 2.6279\n",
            "Epoch 3, Sample 1630, Loss: 2.6454\n",
            "Epoch 3, Sample 1631, Loss: 2.8227\n",
            "Epoch 3, Sample 1632, Loss: 2.1231\n",
            "Epoch 3, Sample 1633, Loss: 2.8723\n",
            "Epoch 3, Sample 1634, Loss: 2.1686\n",
            "Epoch 3, Sample 1635, Loss: 2.4532\n",
            "Epoch 3, Sample 1636, Loss: 2.3911\n",
            "Epoch 3, Sample 1637, Loss: 1.6917\n",
            "Epoch 3, Sample 1638, Loss: 1.8204\n",
            "Epoch 3, Sample 1639, Loss: 2.8330\n",
            "Epoch 3, Sample 1640, Loss: 1.9005\n",
            "Epoch 3, Sample 1641, Loss: 2.7659\n",
            "Epoch 3, Sample 1642, Loss: 2.0735\n",
            "Epoch 3, Sample 1643, Loss: 2.1517\n",
            "Epoch 3, Sample 1644, Loss: 2.4928\n",
            "Epoch 3, Sample 1645, Loss: 2.7491\n",
            "Epoch 3, Sample 1646, Loss: 2.7704\n",
            "Epoch 3, Sample 1647, Loss: 1.8891\n",
            "Epoch 3, Sample 1648, Loss: 3.0030\n",
            "Epoch 3, Sample 1649, Loss: 2.5219\n",
            "Epoch 3, Sample 1650, Loss: 2.4915\n",
            "Epoch 3, Sample 1651, Loss: 2.5177\n",
            "Epoch 3, Sample 1652, Loss: 2.0836\n",
            "Epoch 3, Sample 1653, Loss: 1.5716\n",
            "Epoch 3, Sample 1654, Loss: 2.6089\n",
            "Epoch 3, Sample 1655, Loss: 1.8569\n",
            "Epoch 3, Sample 1656, Loss: 2.1780\n",
            "Epoch 3, Sample 1657, Loss: 2.6776\n",
            "Epoch 3, Sample 1658, Loss: 2.4049\n",
            "Epoch 3, Sample 1659, Loss: 1.5076\n",
            "Epoch 3, Sample 1660, Loss: 3.0020\n",
            "Epoch 3, Sample 1661, Loss: 2.8717\n",
            "Epoch 3, Sample 1662, Loss: 2.3325\n",
            "Epoch 3, Sample 1663, Loss: 2.4728\n",
            "Epoch 3, Sample 1664, Loss: 3.3687\n",
            "Epoch 3, Sample 1665, Loss: 2.5045\n",
            "Epoch 3, Sample 1666, Loss: 3.0623\n",
            "Epoch 3, Sample 1667, Loss: 2.7693\n",
            "Epoch 3, Sample 1668, Loss: 2.8750\n",
            "Epoch 3, Sample 1669, Loss: 2.7820\n",
            "Epoch 3, Sample 1670, Loss: 2.1371\n",
            "Epoch 3, Sample 1671, Loss: 2.8784\n",
            "Epoch 3, Sample 1672, Loss: 2.4238\n",
            "Epoch 3, Sample 1673, Loss: 3.1005\n",
            "Epoch 3, Sample 1674, Loss: 3.0592\n",
            "Epoch 3, Sample 1675, Loss: 3.8610\n",
            "Epoch 3, Sample 1676, Loss: 2.2831\n",
            "Epoch 3, Sample 1677, Loss: 2.9116\n",
            "Epoch 3, Sample 1678, Loss: 3.3109\n",
            "Epoch 3, Sample 1679, Loss: 2.4458\n",
            "Epoch 3, Sample 1680, Loss: 3.7138\n",
            "Epoch 3, Sample 1681, Loss: 2.2459\n",
            "Epoch 3, Sample 1682, Loss: 1.9832\n",
            "Epoch 3, Sample 1683, Loss: 3.1054\n",
            "Epoch 3, Sample 1684, Loss: 2.9357\n",
            "Epoch 3, Sample 1685, Loss: 3.1525\n",
            "Epoch 3, Sample 1686, Loss: 3.1150\n",
            "Epoch 3, Sample 1687, Loss: 2.3197\n",
            "Epoch 3, Sample 1688, Loss: 2.7515\n",
            "Epoch 3, Sample 1689, Loss: 2.3273\n",
            "Epoch 3, Sample 1690, Loss: 2.2407\n",
            "Epoch 3, Sample 1691, Loss: 3.2493\n",
            "Epoch 3, Sample 1692, Loss: 3.4589\n",
            "Epoch 3, Sample 1693, Loss: 3.6257\n",
            "Epoch 3, Sample 1694, Loss: 2.4811\n",
            "Epoch 3, Sample 1695, Loss: 2.9267\n",
            "Epoch 3, Sample 1696, Loss: 2.0998\n",
            "Epoch 3, Sample 1697, Loss: 2.2054\n",
            "Epoch 3, Sample 1698, Loss: 1.5203\n",
            "Epoch 3, Sample 1699, Loss: 2.8008\n",
            "Epoch 3, Sample 1700, Loss: 2.5634\n",
            "Epoch 3, Sample 1701, Loss: 1.9616\n",
            "Epoch 3, Sample 1702, Loss: 2.5185\n",
            "Epoch 3, Sample 1703, Loss: 2.3551\n",
            "Epoch 3, Sample 1704, Loss: 2.8899\n",
            "Epoch 3, Sample 1705, Loss: 2.6142\n",
            "Epoch 3, Sample 1706, Loss: 2.2012\n",
            "Epoch 3, Sample 1707, Loss: 2.4794\n",
            "Epoch 3, Sample 1708, Loss: 2.3616\n",
            "Epoch 3, Sample 1709, Loss: 2.3617\n",
            "Epoch 3, Sample 1710, Loss: 2.7387\n",
            "Epoch 3, Sample 1711, Loss: 3.6032\n",
            "Epoch 3, Sample 1712, Loss: 2.1432\n",
            "Epoch 3, Sample 1713, Loss: 2.8192\n",
            "Epoch 3, Sample 1714, Loss: 2.3657\n",
            "Epoch 3, Sample 1715, Loss: 2.8329\n",
            "Epoch 3, Sample 1716, Loss: 1.8530\n",
            "Epoch 3, Sample 1717, Loss: 2.6444\n",
            "Epoch 3, Sample 1718, Loss: 2.8742\n",
            "Epoch 3, Sample 1719, Loss: 2.1177\n",
            "Epoch 3, Sample 1720, Loss: 2.2602\n",
            "Epoch 3, Sample 1721, Loss: 2.4362\n",
            "Epoch 3, Sample 1722, Loss: 2.9072\n",
            "Epoch 3, Sample 1723, Loss: 2.5457\n",
            "Epoch 3, Sample 1724, Loss: 3.1646\n",
            "Epoch 3, Sample 1725, Loss: 1.6786\n",
            "Epoch 3, Sample 1726, Loss: 2.6249\n",
            "Epoch 3, Sample 1727, Loss: 2.9795\n",
            "Epoch 3, Sample 1728, Loss: 2.7866\n",
            "Epoch 3, Sample 1729, Loss: 1.8058\n",
            "Epoch 3, Sample 1730, Loss: 2.2885\n",
            "Epoch 3, Sample 1731, Loss: 3.1656\n",
            "Epoch 3, Sample 1732, Loss: 3.0294\n",
            "Epoch 3, Sample 1733, Loss: 2.1576\n",
            "Epoch 3, Sample 1734, Loss: 1.7992\n",
            "Epoch 3, Sample 1735, Loss: 2.0574\n",
            "Epoch 3, Sample 1736, Loss: 2.2600\n",
            "Epoch 3, Sample 1737, Loss: 2.5009\n",
            "Epoch 3, Sample 1738, Loss: 2.6269\n",
            "Epoch 3, Sample 1739, Loss: 2.3609\n",
            "Epoch 3, Sample 1740, Loss: 2.8616\n",
            "Epoch 3, Sample 1741, Loss: 2.5346\n",
            "Epoch 3, Sample 1742, Loss: 2.4607\n",
            "Epoch 3, Sample 1743, Loss: 2.1071\n",
            "Epoch 3, Sample 1744, Loss: 2.5553\n",
            "Epoch 3, Sample 1745, Loss: 2.5394\n",
            "Epoch 3, Sample 1746, Loss: 2.8791\n",
            "Epoch 3, Sample 1747, Loss: 2.9382\n",
            "Epoch 3, Sample 1748, Loss: 2.4648\n",
            "Epoch 3, Sample 1749, Loss: 2.6955\n",
            "Epoch 3, Sample 1750, Loss: 2.5993\n",
            "Epoch 3, Sample 1751, Loss: 2.5874\n",
            "Epoch 3, Sample 1752, Loss: 2.5614\n",
            "Epoch 3, Sample 1753, Loss: 1.6978\n",
            "Epoch 3, Sample 1754, Loss: 3.0924\n",
            "Epoch 3, Sample 1755, Loss: 2.5966\n",
            "Epoch 3, Sample 1756, Loss: 2.2928\n",
            "Epoch 3, Sample 1757, Loss: 2.7500\n",
            "Epoch 3, Sample 1758, Loss: 2.3849\n",
            "Epoch 3, Sample 1759, Loss: 2.7731\n",
            "Epoch 3, Sample 1760, Loss: 2.1993\n",
            "Epoch 3, Sample 1761, Loss: 2.5850\n",
            "Epoch 3, Sample 1762, Loss: 1.9773\n",
            "Epoch 3, Sample 1763, Loss: 1.9151\n",
            "Epoch 3, Sample 1764, Loss: 2.4727\n",
            "Epoch 3, Sample 1765, Loss: 2.7143\n",
            "Epoch 3, Sample 1766, Loss: 2.3963\n",
            "Epoch 3, Sample 1767, Loss: 1.8892\n",
            "Epoch 3, Sample 1768, Loss: 2.0878\n",
            "Epoch 3, Sample 1769, Loss: 3.1812\n",
            "Epoch 3, Sample 1770, Loss: 2.9292\n",
            "Epoch 3, Sample 1771, Loss: 2.9746\n",
            "Epoch 3, Sample 1772, Loss: 3.3740\n",
            "Epoch 3, Sample 1773, Loss: 2.3237\n",
            "Epoch 3, Sample 1774, Loss: 2.9816\n",
            "Epoch 3, Sample 1775, Loss: 2.3144\n",
            "Epoch 3, Sample 1776, Loss: 2.0415\n",
            "Epoch 3, Sample 1777, Loss: 2.2509\n",
            "Epoch 3, Sample 1778, Loss: 1.9573\n",
            "Epoch 3, Sample 1779, Loss: 2.4580\n",
            "Epoch 3, Sample 1780, Loss: 1.2060\n",
            "Epoch 3, Sample 1781, Loss: 1.8238\n",
            "Epoch 3, Sample 1782, Loss: 2.6020\n",
            "Epoch 3, Sample 1783, Loss: 2.3749\n",
            "Epoch 3, Sample 1784, Loss: 2.7269\n",
            "Epoch 3, Sample 1785, Loss: 2.2539\n",
            "Epoch 3, Sample 1786, Loss: 2.6883\n",
            "Epoch 3, Sample 1787, Loss: 2.0366\n",
            "Epoch 3, Sample 1788, Loss: 2.9647\n",
            "Epoch 3, Sample 1789, Loss: 2.2856\n",
            "Epoch 3, Sample 1790, Loss: 2.5292\n",
            "Epoch 3, Sample 1791, Loss: 2.4000\n",
            "Epoch 3, Sample 1792, Loss: 2.3393\n",
            "Epoch 3, Sample 1793, Loss: 2.9817\n",
            "Epoch 3, Sample 1794, Loss: 3.2460\n",
            "Epoch 3, Sample 1795, Loss: 2.2063\n",
            "Epoch 3, Sample 1796, Loss: 2.4851\n",
            "Epoch 3, Sample 1797, Loss: 3.4084\n",
            "Epoch 3, Sample 1798, Loss: 2.7290\n",
            "Epoch 3, Sample 1799, Loss: 2.2829\n",
            "Epoch 3, Sample 1800, Loss: 2.8629\n",
            "Epoch 3, Sample 1801, Loss: 2.4758\n",
            "Epoch 3, Sample 1802, Loss: 2.9121\n",
            "Epoch 3, Sample 1803, Loss: 2.1503\n",
            "Epoch 3, Sample 1804, Loss: 2.4042\n",
            "Epoch 3, Sample 1805, Loss: 2.5968\n",
            "Epoch 3, Sample 1806, Loss: 1.9524\n",
            "Epoch 3, Sample 1807, Loss: 1.9343\n",
            "Epoch 3, Sample 1808, Loss: 2.5733\n",
            "Epoch 3, Sample 1809, Loss: 3.8317\n",
            "Epoch 3, Sample 1810, Loss: 2.5863\n",
            "Epoch 3, Sample 1811, Loss: 2.5048\n",
            "Epoch 3, Sample 1812, Loss: 2.2419\n",
            "Epoch 3, Sample 1813, Loss: 3.5114\n",
            "Epoch 3, Sample 1814, Loss: 2.2606\n",
            "Epoch 3, Sample 1815, Loss: 2.0605\n",
            "Epoch 3, Sample 1816, Loss: 2.3102\n",
            "Epoch 3, Sample 1817, Loss: 2.6337\n",
            "Epoch 3, Sample 1818, Loss: 2.8324\n",
            "Epoch 3, Sample 1819, Loss: 2.9957\n",
            "Epoch 3, Sample 1820, Loss: 2.7605\n",
            "Epoch 3, Sample 1821, Loss: 2.2550\n",
            "Epoch 3, Sample 1822, Loss: 2.9498\n",
            "Epoch 3, Sample 1823, Loss: 2.1721\n",
            "Epoch 3, Sample 1824, Loss: 2.2926\n",
            "Epoch 3, Sample 1825, Loss: 2.5726\n",
            "Epoch 3, Sample 1826, Loss: 3.1844\n",
            "Epoch 3, Sample 1827, Loss: 3.0437\n",
            "Epoch 3, Sample 1828, Loss: 2.9957\n",
            "Epoch 3, Sample 1829, Loss: 2.0608\n",
            "Epoch 3, Sample 1830, Loss: 2.4697\n",
            "Epoch 3, Sample 1831, Loss: 2.6623\n",
            "Epoch 3, Sample 1832, Loss: 2.2284\n",
            "Epoch 3, Sample 1833, Loss: 2.3699\n",
            "Epoch 3, Sample 1834, Loss: 2.2729\n",
            "Epoch 3, Sample 1835, Loss: 2.5563\n",
            "Epoch 4, Sample 1, Loss: 3.4449\n",
            "Epoch 4, Sample 2, Loss: 3.0893\n",
            "Epoch 4, Sample 3, Loss: 2.9668\n",
            "Epoch 4, Sample 4, Loss: 2.8742\n",
            "Epoch 4, Sample 5, Loss: 3.2151\n",
            "Epoch 4, Sample 6, Loss: 3.2143\n",
            "Epoch 4, Sample 7, Loss: 2.7177\n",
            "Epoch 4, Sample 8, Loss: 2.5824\n",
            "Epoch 4, Sample 9, Loss: 3.1782\n",
            "Epoch 4, Sample 10, Loss: 2.9265\n",
            "Epoch 4, Sample 11, Loss: 2.9221\n",
            "Epoch 4, Sample 12, Loss: 2.3781\n",
            "Epoch 4, Sample 13, Loss: 2.3882\n",
            "Epoch 4, Sample 14, Loss: 1.8608\n",
            "Epoch 4, Sample 15, Loss: 2.2031\n",
            "Epoch 4, Sample 16, Loss: 2.4321\n",
            "Epoch 4, Sample 17, Loss: 2.3537\n",
            "Epoch 4, Sample 18, Loss: 2.9150\n",
            "Epoch 4, Sample 19, Loss: 2.9155\n",
            "Epoch 4, Sample 20, Loss: 2.1376\n",
            "Epoch 4, Sample 21, Loss: 2.6397\n",
            "Epoch 4, Sample 22, Loss: 2.8054\n",
            "Epoch 4, Sample 23, Loss: 1.4691\n",
            "Epoch 4, Sample 24, Loss: 3.2528\n",
            "Epoch 4, Sample 25, Loss: 2.4900\n",
            "Epoch 4, Sample 26, Loss: 2.5921\n",
            "Epoch 4, Sample 27, Loss: 1.7486\n",
            "Epoch 4, Sample 28, Loss: 3.2739\n",
            "Epoch 4, Sample 29, Loss: 2.5376\n",
            "Epoch 4, Sample 30, Loss: 2.2465\n",
            "Epoch 4, Sample 31, Loss: 1.5583\n",
            "Epoch 4, Sample 32, Loss: 1.8662\n",
            "Epoch 4, Sample 33, Loss: 1.6028\n",
            "Epoch 4, Sample 34, Loss: 2.1209\n",
            "Epoch 4, Sample 35, Loss: 1.8202\n",
            "Epoch 4, Sample 36, Loss: 1.5645\n",
            "Epoch 4, Sample 37, Loss: 1.9339\n",
            "Epoch 4, Sample 38, Loss: 1.5978\n",
            "Epoch 4, Sample 39, Loss: 1.9046\n",
            "Epoch 4, Sample 40, Loss: 2.3157\n",
            "Epoch 4, Sample 41, Loss: 1.4632\n",
            "Epoch 4, Sample 42, Loss: 2.0871\n",
            "Epoch 4, Sample 43, Loss: 2.4112\n",
            "Epoch 4, Sample 44, Loss: 1.8596\n",
            "Epoch 4, Sample 45, Loss: 2.2178\n",
            "Epoch 4, Sample 46, Loss: 1.7108\n",
            "Epoch 4, Sample 47, Loss: 1.9704\n",
            "Epoch 4, Sample 48, Loss: 1.7092\n",
            "Epoch 4, Sample 49, Loss: 1.6910\n",
            "Epoch 4, Sample 50, Loss: 2.0998\n",
            "Epoch 4, Sample 51, Loss: 1.3975\n",
            "Epoch 4, Sample 52, Loss: 2.1501\n",
            "Epoch 4, Sample 53, Loss: 1.9888\n",
            "Epoch 4, Sample 54, Loss: 2.1477\n",
            "Epoch 4, Sample 55, Loss: 2.1674\n",
            "Epoch 4, Sample 56, Loss: 2.1859\n",
            "Epoch 4, Sample 57, Loss: 1.5328\n",
            "Epoch 4, Sample 58, Loss: 1.9980\n",
            "Epoch 4, Sample 59, Loss: 2.2469\n",
            "Epoch 4, Sample 60, Loss: 1.9531\n",
            "Epoch 4, Sample 61, Loss: 1.6402\n",
            "Epoch 4, Sample 62, Loss: 1.6367\n",
            "Epoch 4, Sample 63, Loss: 1.8707\n",
            "Epoch 4, Sample 64, Loss: 2.4517\n",
            "Epoch 4, Sample 65, Loss: 2.0528\n",
            "Epoch 4, Sample 66, Loss: 1.7787\n",
            "Epoch 4, Sample 67, Loss: 1.6338\n",
            "Epoch 4, Sample 68, Loss: 1.9063\n",
            "Epoch 4, Sample 69, Loss: 1.8012\n",
            "Epoch 4, Sample 70, Loss: 1.8744\n",
            "Epoch 4, Sample 71, Loss: 1.5325\n",
            "Epoch 4, Sample 72, Loss: 1.6347\n",
            "Epoch 4, Sample 73, Loss: 1.8251\n",
            "Epoch 4, Sample 74, Loss: 2.0513\n",
            "Epoch 4, Sample 75, Loss: 2.3585\n",
            "Epoch 4, Sample 76, Loss: 2.1207\n",
            "Epoch 4, Sample 77, Loss: 1.2084\n",
            "Epoch 4, Sample 78, Loss: 1.6045\n",
            "Epoch 4, Sample 79, Loss: 1.8000\n",
            "Epoch 4, Sample 80, Loss: 2.1782\n",
            "Epoch 4, Sample 81, Loss: 1.7284\n",
            "Epoch 4, Sample 82, Loss: 1.4956\n",
            "Epoch 4, Sample 83, Loss: 2.0475\n",
            "Epoch 4, Sample 84, Loss: 1.7427\n",
            "Epoch 4, Sample 85, Loss: 2.2840\n",
            "Epoch 4, Sample 86, Loss: 1.6000\n",
            "Epoch 4, Sample 87, Loss: 1.9880\n",
            "Epoch 4, Sample 88, Loss: 1.6244\n",
            "Epoch 4, Sample 89, Loss: 2.5498\n",
            "Epoch 4, Sample 90, Loss: 1.3867\n",
            "Epoch 4, Sample 91, Loss: 2.3172\n",
            "Epoch 4, Sample 92, Loss: 2.0877\n",
            "Epoch 4, Sample 93, Loss: 2.2277\n",
            "Epoch 4, Sample 94, Loss: 2.2331\n",
            "Epoch 4, Sample 95, Loss: 2.0371\n",
            "Epoch 4, Sample 96, Loss: 2.1903\n",
            "Epoch 4, Sample 97, Loss: 2.2965\n",
            "Epoch 4, Sample 98, Loss: 2.6763\n",
            "Epoch 4, Sample 99, Loss: 2.3153\n",
            "Epoch 4, Sample 100, Loss: 3.0587\n",
            "Epoch 4, Sample 101, Loss: 2.7249\n",
            "Epoch 4, Sample 102, Loss: 2.5330\n",
            "Epoch 4, Sample 103, Loss: 2.5008\n",
            "Epoch 4, Sample 104, Loss: 2.1958\n",
            "Epoch 4, Sample 105, Loss: 2.6676\n",
            "Epoch 4, Sample 106, Loss: 1.9788\n",
            "Epoch 4, Sample 107, Loss: 2.5423\n",
            "Epoch 4, Sample 108, Loss: 2.6621\n",
            "Epoch 4, Sample 109, Loss: 1.6961\n",
            "Epoch 4, Sample 110, Loss: 2.9191\n",
            "Epoch 4, Sample 111, Loss: 1.6980\n",
            "Epoch 4, Sample 112, Loss: 2.4648\n",
            "Epoch 4, Sample 113, Loss: 1.7696\n",
            "Epoch 4, Sample 114, Loss: 2.2984\n",
            "Epoch 4, Sample 115, Loss: 2.4027\n",
            "Epoch 4, Sample 116, Loss: 1.6660\n",
            "Epoch 4, Sample 117, Loss: 2.9040\n",
            "Epoch 4, Sample 118, Loss: 2.3627\n",
            "Epoch 4, Sample 119, Loss: 2.5412\n",
            "Epoch 4, Sample 120, Loss: 2.7703\n",
            "Epoch 4, Sample 121, Loss: 2.4169\n",
            "Epoch 4, Sample 122, Loss: 1.8815\n",
            "Epoch 4, Sample 123, Loss: 2.6394\n",
            "Epoch 4, Sample 124, Loss: 2.0694\n",
            "Epoch 4, Sample 125, Loss: 1.9419\n",
            "Epoch 4, Sample 126, Loss: 2.6036\n",
            "Epoch 4, Sample 127, Loss: 3.0801\n",
            "Epoch 4, Sample 128, Loss: 2.1594\n",
            "Epoch 4, Sample 129, Loss: 2.3392\n",
            "Epoch 4, Sample 130, Loss: 2.4967\n",
            "Epoch 4, Sample 131, Loss: 1.8672\n",
            "Epoch 4, Sample 132, Loss: 1.9287\n",
            "Epoch 4, Sample 133, Loss: 2.8939\n",
            "Epoch 4, Sample 134, Loss: 2.1150\n",
            "Epoch 4, Sample 135, Loss: 2.3060\n",
            "Epoch 4, Sample 136, Loss: 1.9394\n",
            "Epoch 4, Sample 137, Loss: 2.3903\n",
            "Epoch 4, Sample 138, Loss: 2.1083\n",
            "Epoch 4, Sample 139, Loss: 2.9772\n",
            "Epoch 4, Sample 140, Loss: 2.1577\n",
            "Epoch 4, Sample 141, Loss: 2.4801\n",
            "Epoch 4, Sample 142, Loss: 2.1821\n",
            "Epoch 4, Sample 143, Loss: 2.1754\n",
            "Epoch 4, Sample 144, Loss: 2.3878\n",
            "Epoch 4, Sample 145, Loss: 1.7016\n",
            "Epoch 4, Sample 146, Loss: 2.7221\n",
            "Epoch 4, Sample 147, Loss: 2.0274\n",
            "Epoch 4, Sample 148, Loss: 3.1337\n",
            "Epoch 4, Sample 149, Loss: 1.9811\n",
            "Epoch 4, Sample 150, Loss: 2.1888\n",
            "Epoch 4, Sample 151, Loss: 1.6607\n",
            "Epoch 4, Sample 152, Loss: 1.5722\n",
            "Epoch 4, Sample 153, Loss: 3.5863\n",
            "Epoch 4, Sample 154, Loss: 1.7781\n",
            "Epoch 4, Sample 155, Loss: 2.6610\n",
            "Epoch 4, Sample 156, Loss: 2.5351\n",
            "Epoch 4, Sample 157, Loss: 1.6644\n",
            "Epoch 4, Sample 158, Loss: 1.5172\n",
            "Epoch 4, Sample 159, Loss: 2.2356\n",
            "Epoch 4, Sample 160, Loss: 2.6135\n",
            "Epoch 4, Sample 161, Loss: 2.5574\n",
            "Epoch 4, Sample 162, Loss: 2.3686\n",
            "Epoch 4, Sample 163, Loss: 3.5313\n",
            "Epoch 4, Sample 164, Loss: 1.8110\n",
            "Epoch 4, Sample 165, Loss: 2.0026\n",
            "Epoch 4, Sample 166, Loss: 2.2512\n",
            "Epoch 4, Sample 167, Loss: 1.7615\n",
            "Epoch 4, Sample 168, Loss: 2.5026\n",
            "Epoch 4, Sample 169, Loss: 3.0038\n",
            "Epoch 4, Sample 170, Loss: 2.1364\n",
            "Epoch 4, Sample 171, Loss: 1.8174\n",
            "Epoch 4, Sample 172, Loss: 1.8418\n",
            "Epoch 4, Sample 173, Loss: 2.2164\n",
            "Epoch 4, Sample 174, Loss: 2.2483\n",
            "Epoch 4, Sample 175, Loss: 2.0890\n",
            "Epoch 4, Sample 176, Loss: 3.0998\n",
            "Epoch 4, Sample 177, Loss: 2.4571\n",
            "Epoch 4, Sample 178, Loss: 3.2924\n",
            "Epoch 4, Sample 179, Loss: 1.9721\n",
            "Epoch 4, Sample 180, Loss: 2.3697\n",
            "Epoch 4, Sample 181, Loss: 3.4265\n",
            "Epoch 4, Sample 182, Loss: 2.9474\n",
            "Epoch 4, Sample 183, Loss: 2.3715\n",
            "Epoch 4, Sample 184, Loss: 1.3912\n",
            "Epoch 4, Sample 185, Loss: 2.2520\n",
            "Epoch 4, Sample 186, Loss: 2.2952\n",
            "Epoch 4, Sample 187, Loss: 2.3211\n",
            "Epoch 4, Sample 188, Loss: 2.3814\n",
            "Epoch 4, Sample 189, Loss: 3.5638\n",
            "Epoch 4, Sample 190, Loss: 3.0176\n",
            "Epoch 4, Sample 191, Loss: 1.9729\n",
            "Epoch 4, Sample 192, Loss: 2.4149\n",
            "Epoch 4, Sample 193, Loss: 2.0489\n",
            "Epoch 4, Sample 194, Loss: 2.4375\n",
            "Epoch 4, Sample 195, Loss: 2.5780\n",
            "Epoch 4, Sample 196, Loss: 2.4643\n",
            "Epoch 4, Sample 197, Loss: 2.0200\n",
            "Epoch 4, Sample 198, Loss: 1.6991\n",
            "Epoch 4, Sample 199, Loss: 2.3379\n",
            "Epoch 4, Sample 200, Loss: 1.7012\n",
            "Epoch 4, Sample 201, Loss: 2.3278\n",
            "Epoch 4, Sample 202, Loss: 2.8459\n",
            "Epoch 4, Sample 203, Loss: 2.1335\n",
            "Epoch 4, Sample 204, Loss: 2.8273\n",
            "Epoch 4, Sample 205, Loss: 2.1064\n",
            "Epoch 4, Sample 206, Loss: 2.1255\n",
            "Epoch 4, Sample 207, Loss: 2.8970\n",
            "Epoch 4, Sample 208, Loss: 1.9253\n",
            "Epoch 4, Sample 209, Loss: 1.9906\n",
            "Epoch 4, Sample 210, Loss: 2.1623\n",
            "Epoch 4, Sample 211, Loss: 1.8377\n",
            "Epoch 4, Sample 212, Loss: 1.8177\n",
            "Epoch 4, Sample 213, Loss: 2.2749\n",
            "Epoch 4, Sample 214, Loss: 1.5734\n",
            "Epoch 4, Sample 215, Loss: 2.4692\n",
            "Epoch 4, Sample 216, Loss: 2.7658\n",
            "Epoch 4, Sample 217, Loss: 2.0253\n",
            "Epoch 4, Sample 218, Loss: 2.5049\n",
            "Epoch 4, Sample 219, Loss: 2.7552\n",
            "Epoch 4, Sample 220, Loss: 2.2860\n",
            "Epoch 4, Sample 221, Loss: 2.6071\n",
            "Epoch 4, Sample 222, Loss: 2.5831\n",
            "Epoch 4, Sample 223, Loss: 2.3727\n",
            "Epoch 4, Sample 224, Loss: 2.2216\n",
            "Epoch 4, Sample 225, Loss: 2.4007\n",
            "Epoch 4, Sample 226, Loss: 2.3691\n",
            "Epoch 4, Sample 227, Loss: 2.7906\n",
            "Epoch 4, Sample 228, Loss: 2.2367\n",
            "Epoch 4, Sample 229, Loss: 2.4674\n",
            "Epoch 4, Sample 230, Loss: 3.2332\n",
            "Epoch 4, Sample 231, Loss: 1.9966\n",
            "Epoch 4, Sample 232, Loss: 3.4840\n",
            "Epoch 4, Sample 233, Loss: 2.1594\n",
            "Epoch 4, Sample 234, Loss: 2.9211\n",
            "Epoch 4, Sample 235, Loss: 2.5397\n",
            "Epoch 4, Sample 236, Loss: 2.7757\n",
            "Epoch 4, Sample 237, Loss: 1.6010\n",
            "Epoch 4, Sample 238, Loss: 2.5320\n",
            "Epoch 4, Sample 239, Loss: 2.1532\n",
            "Epoch 4, Sample 240, Loss: 1.8139\n",
            "Epoch 4, Sample 241, Loss: 1.8787\n",
            "Epoch 4, Sample 242, Loss: 2.1396\n",
            "Epoch 4, Sample 243, Loss: 2.6454\n",
            "Epoch 4, Sample 244, Loss: 2.7811\n",
            "Epoch 4, Sample 245, Loss: 2.7122\n",
            "Epoch 4, Sample 246, Loss: 2.2180\n",
            "Epoch 4, Sample 247, Loss: 2.8403\n",
            "Epoch 4, Sample 248, Loss: 2.8938\n",
            "Epoch 4, Sample 249, Loss: 2.2670\n",
            "Epoch 4, Sample 250, Loss: 2.7838\n",
            "Epoch 4, Sample 251, Loss: 1.9011\n",
            "Epoch 4, Sample 252, Loss: 1.5296\n",
            "Epoch 4, Sample 253, Loss: 2.0576\n",
            "Epoch 4, Sample 254, Loss: 2.0250\n",
            "Epoch 4, Sample 255, Loss: 2.0992\n",
            "Epoch 4, Sample 256, Loss: 1.8815\n",
            "Epoch 4, Sample 257, Loss: 2.1665\n",
            "Epoch 4, Sample 258, Loss: 2.5729\n",
            "Epoch 4, Sample 259, Loss: 2.1797\n",
            "Epoch 4, Sample 260, Loss: 1.8554\n",
            "Epoch 4, Sample 261, Loss: 2.4456\n",
            "Epoch 4, Sample 262, Loss: 3.3036\n",
            "Epoch 4, Sample 263, Loss: 2.3654\n",
            "Epoch 4, Sample 264, Loss: 1.8724\n",
            "Epoch 4, Sample 265, Loss: 1.9797\n",
            "Epoch 4, Sample 266, Loss: 2.3129\n",
            "Epoch 4, Sample 267, Loss: 2.0823\n",
            "Epoch 4, Sample 268, Loss: 2.3693\n",
            "Epoch 4, Sample 269, Loss: 3.0984\n",
            "Epoch 4, Sample 270, Loss: 2.3894\n",
            "Epoch 4, Sample 271, Loss: 2.3770\n",
            "Epoch 4, Sample 272, Loss: 2.1709\n",
            "Epoch 4, Sample 273, Loss: 1.9628\n",
            "Epoch 4, Sample 274, Loss: 2.2032\n",
            "Epoch 4, Sample 275, Loss: 1.7646\n",
            "Epoch 4, Sample 276, Loss: 2.8889\n",
            "Epoch 4, Sample 277, Loss: 2.2826\n",
            "Epoch 4, Sample 278, Loss: 1.5589\n",
            "Epoch 4, Sample 279, Loss: 2.0808\n",
            "Epoch 4, Sample 280, Loss: 2.2602\n",
            "Epoch 4, Sample 281, Loss: 2.1233\n",
            "Epoch 4, Sample 282, Loss: 2.9500\n",
            "Epoch 4, Sample 283, Loss: 1.6806\n",
            "Epoch 4, Sample 284, Loss: 2.5854\n",
            "Epoch 4, Sample 285, Loss: 2.1554\n",
            "Epoch 4, Sample 286, Loss: 1.9687\n",
            "Epoch 4, Sample 287, Loss: 2.6124\n",
            "Epoch 4, Sample 288, Loss: 1.7604\n",
            "Epoch 4, Sample 289, Loss: 2.1807\n",
            "Epoch 4, Sample 290, Loss: 2.2734\n",
            "Epoch 4, Sample 291, Loss: 3.2873\n",
            "Epoch 4, Sample 292, Loss: 1.4220\n",
            "Epoch 4, Sample 293, Loss: 2.2098\n",
            "Epoch 4, Sample 294, Loss: 2.5423\n",
            "Epoch 4, Sample 295, Loss: 2.1989\n",
            "Epoch 4, Sample 296, Loss: 2.1743\n",
            "Epoch 4, Sample 297, Loss: 2.2206\n",
            "Epoch 4, Sample 298, Loss: 2.1341\n",
            "Epoch 4, Sample 299, Loss: 3.0112\n",
            "Epoch 4, Sample 300, Loss: 2.0397\n",
            "Epoch 4, Sample 301, Loss: 2.5587\n",
            "Epoch 4, Sample 302, Loss: 2.1007\n",
            "Epoch 4, Sample 303, Loss: 2.6457\n",
            "Epoch 4, Sample 304, Loss: 1.8033\n",
            "Epoch 4, Sample 305, Loss: 1.6679\n",
            "Epoch 4, Sample 306, Loss: 1.3529\n",
            "Epoch 4, Sample 307, Loss: 3.6226\n",
            "Epoch 4, Sample 308, Loss: 2.3198\n",
            "Epoch 4, Sample 309, Loss: 1.9266\n",
            "Epoch 4, Sample 310, Loss: 2.0537\n",
            "Epoch 4, Sample 311, Loss: 2.2731\n",
            "Epoch 4, Sample 312, Loss: 2.2179\n",
            "Epoch 4, Sample 313, Loss: 1.7050\n",
            "Epoch 4, Sample 314, Loss: 1.5535\n",
            "Epoch 4, Sample 315, Loss: 2.8983\n",
            "Epoch 4, Sample 316, Loss: 2.9503\n",
            "Epoch 4, Sample 317, Loss: 2.3155\n",
            "Epoch 4, Sample 318, Loss: 2.3122\n",
            "Epoch 4, Sample 319, Loss: 3.1532\n",
            "Epoch 4, Sample 320, Loss: 2.2628\n",
            "Epoch 4, Sample 321, Loss: 1.9449\n",
            "Epoch 4, Sample 322, Loss: 2.0592\n",
            "Epoch 4, Sample 323, Loss: 1.9444\n",
            "Epoch 4, Sample 324, Loss: 2.5925\n",
            "Epoch 4, Sample 325, Loss: 2.3216\n",
            "Epoch 4, Sample 326, Loss: 2.4103\n",
            "Epoch 4, Sample 327, Loss: 2.2140\n",
            "Epoch 4, Sample 328, Loss: 3.4481\n",
            "Epoch 4, Sample 329, Loss: 2.1606\n",
            "Epoch 4, Sample 330, Loss: 2.2400\n",
            "Epoch 4, Sample 331, Loss: 2.2103\n",
            "Epoch 4, Sample 332, Loss: 1.9082\n",
            "Epoch 4, Sample 333, Loss: 3.0591\n",
            "Epoch 4, Sample 334, Loss: 3.7986\n",
            "Epoch 4, Sample 335, Loss: 3.0353\n",
            "Epoch 4, Sample 336, Loss: 2.0224\n",
            "Epoch 4, Sample 337, Loss: 1.8591\n",
            "Epoch 4, Sample 338, Loss: 1.8917\n",
            "Epoch 4, Sample 339, Loss: 2.0906\n",
            "Epoch 4, Sample 340, Loss: 3.4615\n",
            "Epoch 4, Sample 341, Loss: 2.0592\n",
            "Epoch 4, Sample 342, Loss: 2.0968\n",
            "Epoch 4, Sample 343, Loss: 1.6910\n",
            "Epoch 4, Sample 344, Loss: 2.0093\n",
            "Epoch 4, Sample 345, Loss: 2.5486\n",
            "Epoch 4, Sample 346, Loss: 2.7554\n",
            "Epoch 4, Sample 347, Loss: 2.9302\n",
            "Epoch 4, Sample 348, Loss: 2.0628\n",
            "Epoch 4, Sample 349, Loss: 2.3438\n",
            "Epoch 4, Sample 350, Loss: 2.5475\n",
            "Epoch 4, Sample 351, Loss: 2.5725\n",
            "Epoch 4, Sample 352, Loss: 2.8545\n",
            "Epoch 4, Sample 353, Loss: 2.8886\n",
            "Epoch 4, Sample 354, Loss: 2.8840\n",
            "Epoch 4, Sample 355, Loss: 2.9451\n",
            "Epoch 4, Sample 356, Loss: 3.5165\n",
            "Epoch 4, Sample 357, Loss: 1.9376\n",
            "Epoch 4, Sample 358, Loss: 2.3697\n",
            "Epoch 4, Sample 359, Loss: 1.9967\n",
            "Epoch 4, Sample 360, Loss: 2.3912\n",
            "Epoch 4, Sample 361, Loss: 2.0665\n",
            "Epoch 4, Sample 362, Loss: 2.8130\n",
            "Epoch 4, Sample 363, Loss: 2.6811\n",
            "Epoch 4, Sample 364, Loss: 1.5947\n",
            "Epoch 4, Sample 365, Loss: 2.9054\n",
            "Epoch 4, Sample 366, Loss: 2.4290\n",
            "Epoch 4, Sample 367, Loss: 1.3706\n",
            "Epoch 4, Sample 368, Loss: 1.9441\n",
            "Epoch 4, Sample 369, Loss: 2.2449\n",
            "Epoch 4, Sample 370, Loss: 1.5517\n",
            "Epoch 4, Sample 371, Loss: 1.8663\n",
            "Epoch 4, Sample 372, Loss: 2.7472\n",
            "Epoch 4, Sample 373, Loss: 2.5148\n",
            "Epoch 4, Sample 374, Loss: 2.5624\n",
            "Epoch 4, Sample 375, Loss: 1.7911\n",
            "Epoch 4, Sample 376, Loss: 2.6743\n",
            "Epoch 4, Sample 377, Loss: 2.5289\n",
            "Epoch 4, Sample 378, Loss: 2.1153\n",
            "Epoch 4, Sample 379, Loss: 1.7361\n",
            "Epoch 4, Sample 380, Loss: 1.6802\n",
            "Epoch 4, Sample 381, Loss: 1.7837\n",
            "Epoch 4, Sample 382, Loss: 2.3652\n",
            "Epoch 4, Sample 383, Loss: 1.8078\n",
            "Epoch 4, Sample 384, Loss: 1.6135\n",
            "Epoch 4, Sample 385, Loss: 2.1542\n",
            "Epoch 4, Sample 386, Loss: 2.1441\n",
            "Epoch 4, Sample 387, Loss: 2.1933\n",
            "Epoch 4, Sample 388, Loss: 2.3702\n",
            "Epoch 4, Sample 389, Loss: 1.6559\n",
            "Epoch 4, Sample 390, Loss: 3.0779\n",
            "Epoch 4, Sample 391, Loss: 2.6606\n",
            "Epoch 4, Sample 392, Loss: 2.2504\n",
            "Epoch 4, Sample 393, Loss: 2.1701\n",
            "Epoch 4, Sample 394, Loss: 2.9292\n",
            "Epoch 4, Sample 395, Loss: 2.5898\n",
            "Epoch 4, Sample 396, Loss: 2.9161\n",
            "Epoch 4, Sample 397, Loss: 1.9623\n",
            "Epoch 4, Sample 398, Loss: 2.5445\n",
            "Epoch 4, Sample 399, Loss: 2.7678\n",
            "Epoch 4, Sample 400, Loss: 2.0567\n",
            "Epoch 4, Sample 401, Loss: 2.4472\n",
            "Epoch 4, Sample 402, Loss: 2.8495\n",
            "Epoch 4, Sample 403, Loss: 2.5434\n",
            "Epoch 4, Sample 404, Loss: 2.8357\n",
            "Epoch 4, Sample 405, Loss: 2.1830\n",
            "Epoch 4, Sample 406, Loss: 2.0051\n",
            "Epoch 4, Sample 407, Loss: 1.7810\n",
            "Epoch 4, Sample 408, Loss: 2.8784\n",
            "Epoch 4, Sample 409, Loss: 1.8092\n",
            "Epoch 4, Sample 410, Loss: 1.9661\n",
            "Epoch 4, Sample 411, Loss: 1.5431\n",
            "Epoch 4, Sample 412, Loss: 1.8851\n",
            "Epoch 4, Sample 413, Loss: 2.1751\n",
            "Epoch 4, Sample 414, Loss: 2.7678\n",
            "Epoch 4, Sample 415, Loss: 2.1680\n",
            "Epoch 4, Sample 416, Loss: 2.2112\n",
            "Epoch 4, Sample 417, Loss: 1.8672\n",
            "Epoch 4, Sample 418, Loss: 2.1058\n",
            "Epoch 4, Sample 419, Loss: 2.6298\n",
            "Epoch 4, Sample 420, Loss: 2.4043\n",
            "Epoch 4, Sample 421, Loss: 1.3697\n",
            "Epoch 4, Sample 422, Loss: 2.7014\n",
            "Epoch 4, Sample 423, Loss: 2.2197\n",
            "Epoch 4, Sample 424, Loss: 2.5289\n",
            "Epoch 4, Sample 425, Loss: 1.5603\n",
            "Epoch 4, Sample 426, Loss: 2.2155\n",
            "Epoch 4, Sample 427, Loss: 2.5504\n",
            "Epoch 4, Sample 428, Loss: 2.5073\n",
            "Epoch 4, Sample 429, Loss: 2.5034\n",
            "Epoch 4, Sample 430, Loss: 1.2210\n",
            "Epoch 4, Sample 431, Loss: 2.3811\n",
            "Epoch 4, Sample 432, Loss: 2.0755\n",
            "Epoch 4, Sample 433, Loss: 2.2766\n",
            "Epoch 4, Sample 434, Loss: 1.6510\n",
            "Epoch 4, Sample 435, Loss: 2.2694\n",
            "Epoch 4, Sample 436, Loss: 2.2037\n",
            "Epoch 4, Sample 437, Loss: 2.6267\n",
            "Epoch 4, Sample 438, Loss: 1.6779\n",
            "Epoch 4, Sample 439, Loss: 2.5019\n",
            "Epoch 4, Sample 440, Loss: 1.7623\n",
            "Epoch 4, Sample 441, Loss: 2.5377\n",
            "Epoch 4, Sample 442, Loss: 2.0414\n",
            "Epoch 4, Sample 443, Loss: 2.5574\n",
            "Epoch 4, Sample 444, Loss: 2.2550\n",
            "Epoch 4, Sample 445, Loss: 2.4900\n",
            "Epoch 4, Sample 446, Loss: 2.1793\n",
            "Epoch 4, Sample 447, Loss: 2.2530\n",
            "Epoch 4, Sample 448, Loss: 1.6297\n",
            "Epoch 4, Sample 449, Loss: 2.3611\n",
            "Epoch 4, Sample 450, Loss: 2.4181\n",
            "Epoch 4, Sample 451, Loss: 2.0751\n",
            "Epoch 4, Sample 452, Loss: 2.5769\n",
            "Epoch 4, Sample 453, Loss: 1.9929\n",
            "Epoch 4, Sample 454, Loss: 2.5867\n",
            "Epoch 4, Sample 455, Loss: 2.3248\n",
            "Epoch 4, Sample 456, Loss: 1.9982\n",
            "Epoch 4, Sample 457, Loss: 2.3723\n",
            "Epoch 4, Sample 458, Loss: 2.7837\n",
            "Epoch 4, Sample 459, Loss: 1.8616\n",
            "Epoch 4, Sample 460, Loss: 2.8655\n",
            "Epoch 4, Sample 461, Loss: 2.3870\n",
            "Epoch 4, Sample 462, Loss: 1.4733\n",
            "Epoch 4, Sample 463, Loss: 1.8458\n",
            "Epoch 4, Sample 464, Loss: 2.5126\n",
            "Epoch 4, Sample 465, Loss: 2.4023\n",
            "Epoch 4, Sample 466, Loss: 2.1320\n",
            "Epoch 4, Sample 467, Loss: 2.9011\n",
            "Epoch 4, Sample 468, Loss: 1.5904\n",
            "Epoch 4, Sample 469, Loss: 1.9546\n",
            "Epoch 4, Sample 470, Loss: 2.8797\n",
            "Epoch 4, Sample 471, Loss: 2.1924\n",
            "Epoch 4, Sample 472, Loss: 2.5074\n",
            "Epoch 4, Sample 473, Loss: 2.5397\n",
            "Epoch 4, Sample 474, Loss: 2.5526\n",
            "Epoch 4, Sample 475, Loss: 2.0259\n",
            "Epoch 4, Sample 476, Loss: 2.2168\n",
            "Epoch 4, Sample 477, Loss: 1.9842\n",
            "Epoch 4, Sample 478, Loss: 2.3006\n",
            "Epoch 4, Sample 479, Loss: 1.4764\n",
            "Epoch 4, Sample 480, Loss: 1.8282\n",
            "Epoch 4, Sample 481, Loss: 2.6838\n",
            "Epoch 4, Sample 482, Loss: 2.7986\n",
            "Epoch 4, Sample 483, Loss: 2.5287\n",
            "Epoch 4, Sample 484, Loss: 2.2736\n",
            "Epoch 4, Sample 485, Loss: 2.4063\n",
            "Epoch 4, Sample 486, Loss: 2.9200\n",
            "Epoch 4, Sample 487, Loss: 1.3923\n",
            "Epoch 4, Sample 488, Loss: 2.5788\n",
            "Epoch 4, Sample 489, Loss: 1.8403\n",
            "Epoch 4, Sample 490, Loss: 2.6706\n",
            "Epoch 4, Sample 491, Loss: 2.4274\n",
            "Epoch 4, Sample 492, Loss: 3.0499\n",
            "Epoch 4, Sample 493, Loss: 2.2484\n",
            "Epoch 4, Sample 494, Loss: 2.9318\n",
            "Epoch 4, Sample 495, Loss: 2.6739\n",
            "Epoch 4, Sample 496, Loss: 3.0137\n",
            "Epoch 4, Sample 497, Loss: 1.8123\n",
            "Epoch 4, Sample 498, Loss: 2.8959\n",
            "Epoch 4, Sample 499, Loss: 2.5999\n",
            "Epoch 4, Sample 500, Loss: 2.6556\n",
            "Epoch 4, Sample 501, Loss: 2.4457\n",
            "Epoch 4, Sample 502, Loss: 2.5532\n",
            "Epoch 4, Sample 503, Loss: 2.0333\n",
            "Epoch 4, Sample 504, Loss: 3.1950\n",
            "Epoch 4, Sample 505, Loss: 2.8568\n",
            "Epoch 4, Sample 506, Loss: 2.0668\n",
            "Epoch 4, Sample 507, Loss: 2.0533\n",
            "Epoch 4, Sample 508, Loss: 2.7618\n",
            "Epoch 4, Sample 509, Loss: 1.6144\n",
            "Epoch 4, Sample 510, Loss: 2.9291\n",
            "Epoch 4, Sample 511, Loss: 1.9856\n",
            "Epoch 4, Sample 512, Loss: 2.5673\n",
            "Epoch 4, Sample 513, Loss: 1.5070\n",
            "Epoch 4, Sample 514, Loss: 2.3014\n",
            "Epoch 4, Sample 515, Loss: 1.8199\n",
            "Epoch 4, Sample 516, Loss: 2.3950\n",
            "Epoch 4, Sample 517, Loss: 2.3640\n",
            "Epoch 4, Sample 518, Loss: 1.5937\n",
            "Epoch 4, Sample 519, Loss: 1.7740\n",
            "Epoch 4, Sample 520, Loss: 1.7592\n",
            "Epoch 4, Sample 521, Loss: 1.9032\n",
            "Epoch 4, Sample 522, Loss: 2.3331\n",
            "Epoch 4, Sample 523, Loss: 2.0818\n",
            "Epoch 4, Sample 524, Loss: 2.6552\n",
            "Epoch 4, Sample 525, Loss: 2.6650\n",
            "Epoch 4, Sample 526, Loss: 2.0322\n",
            "Epoch 4, Sample 527, Loss: 1.8474\n",
            "Epoch 4, Sample 528, Loss: 1.9596\n",
            "Epoch 4, Sample 529, Loss: 2.9220\n",
            "Epoch 4, Sample 530, Loss: 3.1479\n",
            "Epoch 4, Sample 531, Loss: 2.5983\n",
            "Epoch 4, Sample 532, Loss: 2.5485\n",
            "Epoch 4, Sample 533, Loss: 1.8819\n",
            "Epoch 4, Sample 534, Loss: 1.9244\n",
            "Epoch 4, Sample 535, Loss: 1.9228\n",
            "Epoch 4, Sample 536, Loss: 2.0014\n",
            "Epoch 4, Sample 537, Loss: 3.2824\n",
            "Epoch 4, Sample 538, Loss: 1.8664\n",
            "Epoch 4, Sample 539, Loss: 1.9158\n",
            "Epoch 4, Sample 540, Loss: 2.5837\n",
            "Epoch 4, Sample 541, Loss: 2.1257\n",
            "Epoch 4, Sample 542, Loss: 2.1358\n",
            "Epoch 4, Sample 543, Loss: 2.6884\n",
            "Epoch 4, Sample 544, Loss: 1.9269\n",
            "Epoch 4, Sample 545, Loss: 2.6458\n",
            "Epoch 4, Sample 546, Loss: 3.0960\n",
            "Epoch 4, Sample 547, Loss: 1.6190\n",
            "Epoch 4, Sample 548, Loss: 1.8129\n",
            "Epoch 4, Sample 549, Loss: 2.6043\n",
            "Epoch 4, Sample 550, Loss: 2.2018\n",
            "Epoch 4, Sample 551, Loss: 2.0179\n",
            "Epoch 4, Sample 552, Loss: 2.3632\n",
            "Epoch 4, Sample 553, Loss: 2.5393\n",
            "Epoch 4, Sample 554, Loss: 2.6204\n",
            "Epoch 4, Sample 555, Loss: 2.0593\n",
            "Epoch 4, Sample 556, Loss: 2.2804\n",
            "Epoch 4, Sample 557, Loss: 2.9211\n",
            "Epoch 4, Sample 558, Loss: 2.9820\n",
            "Epoch 4, Sample 559, Loss: 2.4638\n",
            "Epoch 4, Sample 560, Loss: 2.5995\n",
            "Epoch 4, Sample 561, Loss: 3.3932\n",
            "Epoch 4, Sample 562, Loss: 2.2901\n",
            "Epoch 4, Sample 563, Loss: 2.0964\n",
            "Epoch 4, Sample 564, Loss: 2.3708\n",
            "Epoch 4, Sample 565, Loss: 2.4260\n",
            "Epoch 4, Sample 566, Loss: 2.1139\n",
            "Epoch 4, Sample 567, Loss: 1.7164\n",
            "Epoch 4, Sample 568, Loss: 2.8105\n",
            "Epoch 4, Sample 569, Loss: 2.6836\n",
            "Epoch 4, Sample 570, Loss: 2.1139\n",
            "Epoch 4, Sample 571, Loss: 2.6672\n",
            "Epoch 4, Sample 572, Loss: 2.2300\n",
            "Epoch 4, Sample 573, Loss: 1.9712\n",
            "Epoch 4, Sample 574, Loss: 2.3531\n",
            "Epoch 4, Sample 575, Loss: 3.4112\n",
            "Epoch 4, Sample 576, Loss: 2.4132\n",
            "Epoch 4, Sample 577, Loss: 2.2567\n",
            "Epoch 4, Sample 578, Loss: 2.4135\n",
            "Epoch 4, Sample 579, Loss: 2.3665\n",
            "Epoch 4, Sample 580, Loss: 3.8591\n",
            "Epoch 4, Sample 581, Loss: 1.6653\n",
            "Epoch 4, Sample 582, Loss: 2.8994\n",
            "Epoch 4, Sample 583, Loss: 3.0631\n",
            "Epoch 4, Sample 584, Loss: 2.1861\n",
            "Epoch 4, Sample 585, Loss: 2.2688\n",
            "Epoch 4, Sample 586, Loss: 3.3234\n",
            "Epoch 4, Sample 587, Loss: 2.4298\n",
            "Epoch 4, Sample 588, Loss: 3.0890\n",
            "Epoch 4, Sample 589, Loss: 2.4626\n",
            "Epoch 4, Sample 590, Loss: 2.7243\n",
            "Epoch 4, Sample 591, Loss: 1.9956\n",
            "Epoch 4, Sample 592, Loss: 3.1346\n",
            "Epoch 4, Sample 593, Loss: 1.4337\n",
            "Epoch 4, Sample 594, Loss: 2.5130\n",
            "Epoch 4, Sample 595, Loss: 1.4976\n",
            "Epoch 4, Sample 596, Loss: 2.3629\n",
            "Epoch 4, Sample 597, Loss: 2.9981\n",
            "Epoch 4, Sample 598, Loss: 2.2208\n",
            "Epoch 4, Sample 599, Loss: 2.0917\n",
            "Epoch 4, Sample 600, Loss: 2.8049\n",
            "Epoch 4, Sample 601, Loss: 2.3245\n",
            "Epoch 4, Sample 602, Loss: 2.9598\n",
            "Epoch 4, Sample 603, Loss: 1.8597\n",
            "Epoch 4, Sample 604, Loss: 2.7209\n",
            "Epoch 4, Sample 605, Loss: 2.6629\n",
            "Epoch 4, Sample 606, Loss: 1.9401\n",
            "Epoch 4, Sample 607, Loss: 3.1550\n",
            "Epoch 4, Sample 608, Loss: 2.4942\n",
            "Epoch 4, Sample 609, Loss: 2.2514\n",
            "Epoch 4, Sample 610, Loss: 2.1550\n",
            "Epoch 4, Sample 611, Loss: 2.8679\n",
            "Epoch 4, Sample 612, Loss: 2.6113\n",
            "Epoch 4, Sample 613, Loss: 3.7201\n",
            "Epoch 4, Sample 614, Loss: 3.0172\n",
            "Epoch 4, Sample 615, Loss: 1.7958\n",
            "Epoch 4, Sample 616, Loss: 2.4848\n",
            "Epoch 4, Sample 617, Loss: 3.0363\n",
            "Epoch 4, Sample 618, Loss: 2.0743\n",
            "Epoch 4, Sample 619, Loss: 2.0384\n",
            "Epoch 4, Sample 620, Loss: 2.6531\n",
            "Epoch 4, Sample 621, Loss: 1.8689\n",
            "Epoch 4, Sample 622, Loss: 2.0288\n",
            "Epoch 4, Sample 623, Loss: 2.6229\n",
            "Epoch 4, Sample 624, Loss: 1.4816\n",
            "Epoch 4, Sample 625, Loss: 2.4490\n",
            "Epoch 4, Sample 626, Loss: 2.0232\n",
            "Epoch 4, Sample 627, Loss: 2.1981\n",
            "Epoch 4, Sample 628, Loss: 2.7454\n",
            "Epoch 4, Sample 629, Loss: 2.8336\n",
            "Epoch 4, Sample 630, Loss: 2.5766\n",
            "Epoch 4, Sample 631, Loss: 1.5016\n",
            "Epoch 4, Sample 632, Loss: 2.0416\n",
            "Epoch 4, Sample 633, Loss: 1.5285\n",
            "Epoch 4, Sample 634, Loss: 1.7168\n",
            "Epoch 4, Sample 635, Loss: 1.9742\n",
            "Epoch 4, Sample 636, Loss: 2.6317\n",
            "Epoch 4, Sample 637, Loss: 1.9462\n",
            "Epoch 4, Sample 638, Loss: 1.7538\n",
            "Epoch 4, Sample 639, Loss: 2.2416\n",
            "Epoch 4, Sample 640, Loss: 2.2838\n",
            "Epoch 4, Sample 641, Loss: 1.7434\n",
            "Epoch 4, Sample 642, Loss: 1.6168\n",
            "Epoch 4, Sample 643, Loss: 2.2647\n",
            "Epoch 4, Sample 644, Loss: 2.1158\n",
            "Epoch 4, Sample 645, Loss: 1.7041\n",
            "Epoch 4, Sample 646, Loss: 2.7140\n",
            "Epoch 4, Sample 647, Loss: 2.1370\n",
            "Epoch 4, Sample 648, Loss: 2.6480\n",
            "Epoch 4, Sample 649, Loss: 2.3625\n",
            "Epoch 4, Sample 650, Loss: 1.7778\n",
            "Epoch 4, Sample 651, Loss: 2.9481\n",
            "Epoch 4, Sample 652, Loss: 1.6053\n",
            "Epoch 4, Sample 653, Loss: 1.9397\n",
            "Epoch 4, Sample 654, Loss: 2.3377\n",
            "Epoch 4, Sample 655, Loss: 2.3548\n",
            "Epoch 4, Sample 656, Loss: 2.7031\n",
            "Epoch 4, Sample 657, Loss: 2.2745\n",
            "Epoch 4, Sample 658, Loss: 2.5361\n",
            "Epoch 4, Sample 659, Loss: 1.5732\n",
            "Epoch 4, Sample 660, Loss: 2.1266\n",
            "Epoch 4, Sample 661, Loss: 2.1612\n",
            "Epoch 4, Sample 662, Loss: 2.1110\n",
            "Epoch 4, Sample 663, Loss: 2.1579\n",
            "Epoch 4, Sample 664, Loss: 1.6104\n",
            "Epoch 4, Sample 665, Loss: 2.3544\n",
            "Epoch 4, Sample 666, Loss: 1.9123\n",
            "Epoch 4, Sample 667, Loss: 3.4217\n",
            "Epoch 4, Sample 668, Loss: 2.5224\n",
            "Epoch 4, Sample 669, Loss: 1.7841\n",
            "Epoch 4, Sample 670, Loss: 1.9711\n",
            "Epoch 4, Sample 671, Loss: 1.7338\n",
            "Epoch 4, Sample 672, Loss: 1.7546\n",
            "Epoch 4, Sample 673, Loss: 2.1826\n",
            "Epoch 4, Sample 674, Loss: 2.3961\n",
            "Epoch 4, Sample 675, Loss: 1.9639\n",
            "Epoch 4, Sample 676, Loss: 2.1605\n",
            "Epoch 4, Sample 677, Loss: 2.4321\n",
            "Epoch 4, Sample 678, Loss: 1.8946\n",
            "Epoch 4, Sample 679, Loss: 1.7223\n",
            "Epoch 4, Sample 680, Loss: 2.6426\n",
            "Epoch 4, Sample 681, Loss: 1.7694\n",
            "Epoch 4, Sample 682, Loss: 1.7449\n",
            "Epoch 4, Sample 683, Loss: 2.1091\n",
            "Epoch 4, Sample 684, Loss: 2.1760\n",
            "Epoch 4, Sample 685, Loss: 1.6837\n",
            "Epoch 4, Sample 686, Loss: 1.8570\n",
            "Epoch 4, Sample 687, Loss: 2.3027\n",
            "Epoch 4, Sample 688, Loss: 2.0628\n",
            "Epoch 4, Sample 689, Loss: 2.3134\n",
            "Epoch 4, Sample 690, Loss: 2.1093\n",
            "Epoch 4, Sample 691, Loss: 2.3209\n",
            "Epoch 4, Sample 692, Loss: 2.2885\n",
            "Epoch 4, Sample 693, Loss: 1.5097\n",
            "Epoch 4, Sample 694, Loss: 2.8659\n",
            "Epoch 4, Sample 695, Loss: 2.3029\n",
            "Epoch 4, Sample 696, Loss: 2.2934\n",
            "Epoch 4, Sample 697, Loss: 1.9187\n",
            "Epoch 4, Sample 698, Loss: 1.8437\n",
            "Epoch 4, Sample 699, Loss: 3.5529\n",
            "Epoch 4, Sample 700, Loss: 2.4177\n",
            "Epoch 4, Sample 701, Loss: 2.0488\n",
            "Epoch 4, Sample 702, Loss: 2.0515\n",
            "Epoch 4, Sample 703, Loss: 2.3008\n",
            "Epoch 4, Sample 704, Loss: 2.3368\n",
            "Epoch 4, Sample 705, Loss: 2.5387\n",
            "Epoch 4, Sample 706, Loss: 3.2564\n",
            "Epoch 4, Sample 707, Loss: 2.7632\n",
            "Epoch 4, Sample 708, Loss: 3.0797\n",
            "Epoch 4, Sample 709, Loss: 2.5727\n",
            "Epoch 4, Sample 710, Loss: 2.7214\n",
            "Epoch 4, Sample 711, Loss: 1.4367\n",
            "Epoch 4, Sample 712, Loss: 2.1225\n",
            "Epoch 4, Sample 713, Loss: 3.2377\n",
            "Epoch 4, Sample 714, Loss: 2.6732\n",
            "Epoch 4, Sample 715, Loss: 1.7451\n",
            "Epoch 4, Sample 716, Loss: 2.2307\n",
            "Epoch 4, Sample 717, Loss: 2.2064\n",
            "Epoch 4, Sample 718, Loss: 2.6100\n",
            "Epoch 4, Sample 719, Loss: 1.9962\n",
            "Epoch 4, Sample 720, Loss: 2.6824\n",
            "Epoch 4, Sample 721, Loss: 2.3741\n",
            "Epoch 4, Sample 722, Loss: 1.8186\n",
            "Epoch 4, Sample 723, Loss: 3.0163\n",
            "Epoch 4, Sample 724, Loss: 2.7599\n",
            "Epoch 4, Sample 725, Loss: 2.2376\n",
            "Epoch 4, Sample 726, Loss: 2.3858\n",
            "Epoch 4, Sample 727, Loss: 2.8543\n",
            "Epoch 4, Sample 728, Loss: 2.9803\n",
            "Epoch 4, Sample 729, Loss: 2.9764\n",
            "Epoch 4, Sample 730, Loss: 2.5242\n",
            "Epoch 4, Sample 731, Loss: 2.0714\n",
            "Epoch 4, Sample 732, Loss: 3.0113\n",
            "Epoch 4, Sample 733, Loss: 1.5449\n",
            "Epoch 4, Sample 734, Loss: 2.7241\n",
            "Epoch 4, Sample 735, Loss: 2.7829\n",
            "Epoch 4, Sample 736, Loss: 2.2299\n",
            "Epoch 4, Sample 737, Loss: 1.6798\n",
            "Epoch 4, Sample 738, Loss: 1.8377\n",
            "Epoch 4, Sample 739, Loss: 2.1767\n",
            "Epoch 4, Sample 740, Loss: 2.3018\n",
            "Epoch 4, Sample 741, Loss: 1.8530\n",
            "Epoch 4, Sample 742, Loss: 2.1782\n",
            "Epoch 4, Sample 743, Loss: 3.0206\n",
            "Epoch 4, Sample 744, Loss: 2.9988\n",
            "Epoch 4, Sample 745, Loss: 3.0557\n",
            "Epoch 4, Sample 746, Loss: 2.3590\n",
            "Epoch 4, Sample 747, Loss: 3.1940\n",
            "Epoch 4, Sample 748, Loss: 2.5892\n",
            "Epoch 4, Sample 749, Loss: 2.0303\n",
            "Epoch 4, Sample 750, Loss: 2.5827\n",
            "Epoch 4, Sample 751, Loss: 1.6126\n",
            "Epoch 4, Sample 752, Loss: 1.8998\n",
            "Epoch 4, Sample 753, Loss: 2.6739\n",
            "Epoch 4, Sample 754, Loss: 3.0459\n",
            "Epoch 4, Sample 755, Loss: 2.7831\n",
            "Epoch 4, Sample 756, Loss: 2.5798\n",
            "Epoch 4, Sample 757, Loss: 3.5801\n",
            "Epoch 4, Sample 758, Loss: 2.7717\n",
            "Epoch 4, Sample 759, Loss: 2.9900\n",
            "Epoch 4, Sample 760, Loss: 2.5950\n",
            "Epoch 4, Sample 761, Loss: 2.1795\n",
            "Epoch 4, Sample 762, Loss: 3.3320\n",
            "Epoch 4, Sample 763, Loss: 2.4961\n",
            "Epoch 4, Sample 764, Loss: 3.1346\n",
            "Epoch 4, Sample 765, Loss: 2.5507\n",
            "Epoch 4, Sample 766, Loss: 2.9000\n",
            "Epoch 4, Sample 767, Loss: 2.2326\n",
            "Epoch 4, Sample 768, Loss: 2.6043\n",
            "Epoch 4, Sample 769, Loss: 2.3912\n",
            "Epoch 4, Sample 770, Loss: 2.9063\n",
            "Epoch 4, Sample 771, Loss: 2.1139\n",
            "Epoch 4, Sample 772, Loss: 2.7461\n",
            "Epoch 4, Sample 773, Loss: 1.8909\n",
            "Epoch 4, Sample 774, Loss: 2.3555\n",
            "Epoch 4, Sample 775, Loss: 2.3468\n",
            "Epoch 4, Sample 776, Loss: 2.2307\n",
            "Epoch 4, Sample 777, Loss: 2.2303\n",
            "Epoch 4, Sample 778, Loss: 2.6580\n",
            "Epoch 4, Sample 779, Loss: 2.1500\n",
            "Epoch 4, Sample 780, Loss: 2.6310\n",
            "Epoch 4, Sample 781, Loss: 2.3103\n",
            "Epoch 4, Sample 782, Loss: 2.6111\n",
            "Epoch 4, Sample 783, Loss: 2.6664\n",
            "Epoch 4, Sample 784, Loss: 1.1819\n",
            "Epoch 4, Sample 785, Loss: 2.1867\n",
            "Epoch 4, Sample 786, Loss: 2.2506\n",
            "Epoch 4, Sample 787, Loss: 2.1607\n",
            "Epoch 4, Sample 788, Loss: 2.2844\n",
            "Epoch 4, Sample 789, Loss: 2.9042\n",
            "Epoch 4, Sample 790, Loss: 2.3141\n",
            "Epoch 4, Sample 791, Loss: 2.8340\n",
            "Epoch 4, Sample 792, Loss: 2.4361\n",
            "Epoch 4, Sample 793, Loss: 1.7610\n",
            "Epoch 4, Sample 794, Loss: 2.5992\n",
            "Epoch 4, Sample 795, Loss: 2.6047\n",
            "Epoch 4, Sample 796, Loss: 2.3863\n",
            "Epoch 4, Sample 797, Loss: 3.2760\n",
            "Epoch 4, Sample 798, Loss: 3.1773\n",
            "Epoch 4, Sample 799, Loss: 3.9135\n",
            "Epoch 4, Sample 800, Loss: 3.1254\n",
            "Epoch 4, Sample 801, Loss: 2.8502\n",
            "Epoch 4, Sample 802, Loss: 2.2047\n",
            "Epoch 4, Sample 803, Loss: 2.2889\n",
            "Epoch 4, Sample 804, Loss: 2.1761\n",
            "Epoch 4, Sample 805, Loss: 2.9194\n",
            "Epoch 4, Sample 806, Loss: 2.7131\n",
            "Epoch 4, Sample 807, Loss: 1.9349\n",
            "Epoch 4, Sample 808, Loss: 3.2536\n",
            "Epoch 4, Sample 809, Loss: 2.5915\n",
            "Epoch 4, Sample 810, Loss: 2.7231\n",
            "Epoch 4, Sample 811, Loss: 2.4672\n",
            "Epoch 4, Sample 812, Loss: 2.3092\n",
            "Epoch 4, Sample 813, Loss: 2.9810\n",
            "Epoch 4, Sample 814, Loss: 2.5365\n",
            "Epoch 4, Sample 815, Loss: 2.7402\n",
            "Epoch 4, Sample 816, Loss: 2.1705\n",
            "Epoch 4, Sample 817, Loss: 3.3275\n",
            "Epoch 4, Sample 818, Loss: 2.7089\n",
            "Epoch 4, Sample 819, Loss: 2.3455\n",
            "Epoch 4, Sample 820, Loss: 2.3697\n",
            "Epoch 4, Sample 821, Loss: 3.0396\n",
            "Epoch 4, Sample 822, Loss: 2.4639\n",
            "Epoch 4, Sample 823, Loss: 1.3721\n",
            "Epoch 4, Sample 824, Loss: 2.9511\n",
            "Epoch 4, Sample 825, Loss: 2.0300\n",
            "Epoch 4, Sample 826, Loss: 2.8067\n",
            "Epoch 4, Sample 827, Loss: 2.3646\n",
            "Epoch 4, Sample 828, Loss: 2.7637\n",
            "Epoch 4, Sample 829, Loss: 1.9725\n",
            "Epoch 4, Sample 830, Loss: 3.1505\n",
            "Epoch 4, Sample 831, Loss: 2.6968\n",
            "Epoch 4, Sample 832, Loss: 1.8623\n",
            "Epoch 4, Sample 833, Loss: 2.8208\n",
            "Epoch 4, Sample 834, Loss: 2.7001\n",
            "Epoch 4, Sample 835, Loss: 2.5789\n",
            "Epoch 4, Sample 836, Loss: 2.4980\n",
            "Epoch 4, Sample 837, Loss: 2.3521\n",
            "Epoch 4, Sample 838, Loss: 2.5519\n",
            "Epoch 4, Sample 839, Loss: 2.5923\n",
            "Epoch 4, Sample 840, Loss: 2.5942\n",
            "Epoch 4, Sample 841, Loss: 2.0409\n",
            "Epoch 4, Sample 842, Loss: 2.5522\n",
            "Epoch 4, Sample 843, Loss: 2.1962\n",
            "Epoch 4, Sample 844, Loss: 2.0689\n",
            "Epoch 4, Sample 845, Loss: 2.6092\n",
            "Epoch 4, Sample 846, Loss: 2.4019\n",
            "Epoch 4, Sample 847, Loss: 2.5734\n",
            "Epoch 4, Sample 848, Loss: 3.0039\n",
            "Epoch 4, Sample 849, Loss: 3.0909\n",
            "Epoch 4, Sample 850, Loss: 2.5003\n",
            "Epoch 4, Sample 851, Loss: 1.7761\n",
            "Epoch 4, Sample 852, Loss: 2.1939\n",
            "Epoch 4, Sample 853, Loss: 2.5468\n",
            "Epoch 4, Sample 854, Loss: 2.9507\n",
            "Epoch 4, Sample 855, Loss: 2.1783\n",
            "Epoch 4, Sample 856, Loss: 2.0588\n",
            "Epoch 4, Sample 857, Loss: 3.1894\n",
            "Epoch 4, Sample 858, Loss: 2.1181\n",
            "Epoch 4, Sample 859, Loss: 2.4886\n",
            "Epoch 4, Sample 860, Loss: 2.3271\n",
            "Epoch 4, Sample 861, Loss: 2.2649\n",
            "Epoch 4, Sample 862, Loss: 2.4791\n",
            "Epoch 4, Sample 863, Loss: 1.9742\n",
            "Epoch 4, Sample 864, Loss: 3.2404\n",
            "Epoch 4, Sample 865, Loss: 2.6408\n",
            "Epoch 4, Sample 866, Loss: 2.3274\n",
            "Epoch 4, Sample 867, Loss: 2.5238\n",
            "Epoch 4, Sample 868, Loss: 2.7086\n",
            "Epoch 4, Sample 869, Loss: 2.7912\n",
            "Epoch 4, Sample 870, Loss: 2.5209\n",
            "Epoch 4, Sample 871, Loss: 2.8614\n",
            "Epoch 4, Sample 872, Loss: 3.0368\n",
            "Epoch 4, Sample 873, Loss: 1.5819\n",
            "Epoch 4, Sample 874, Loss: 1.8104\n",
            "Epoch 4, Sample 875, Loss: 2.4442\n",
            "Epoch 4, Sample 876, Loss: 2.4947\n",
            "Epoch 4, Sample 877, Loss: 2.0272\n",
            "Epoch 4, Sample 878, Loss: 2.9758\n",
            "Epoch 4, Sample 879, Loss: 2.4010\n",
            "Epoch 4, Sample 880, Loss: 2.0475\n",
            "Epoch 4, Sample 881, Loss: 2.1128\n",
            "Epoch 4, Sample 882, Loss: 2.0949\n",
            "Epoch 4, Sample 883, Loss: 2.7725\n",
            "Epoch 4, Sample 884, Loss: 2.5973\n",
            "Epoch 4, Sample 885, Loss: 2.1291\n",
            "Epoch 4, Sample 886, Loss: 2.4348\n",
            "Epoch 4, Sample 887, Loss: 3.4911\n",
            "Epoch 4, Sample 888, Loss: 2.6140\n",
            "Epoch 4, Sample 889, Loss: 2.1939\n",
            "Epoch 4, Sample 890, Loss: 2.9094\n",
            "Epoch 4, Sample 891, Loss: 2.1583\n",
            "Epoch 4, Sample 892, Loss: 2.7672\n",
            "Epoch 4, Sample 893, Loss: 2.9320\n",
            "Epoch 4, Sample 894, Loss: 2.4033\n",
            "Epoch 4, Sample 895, Loss: 1.7648\n",
            "Epoch 4, Sample 896, Loss: 2.1429\n",
            "Epoch 4, Sample 897, Loss: 2.4325\n",
            "Epoch 4, Sample 898, Loss: 2.0726\n",
            "Epoch 4, Sample 899, Loss: 2.3930\n",
            "Epoch 4, Sample 900, Loss: 2.4309\n",
            "Epoch 4, Sample 901, Loss: 2.7493\n",
            "Epoch 4, Sample 902, Loss: 2.7797\n",
            "Epoch 4, Sample 903, Loss: 2.6003\n",
            "Epoch 4, Sample 904, Loss: 1.9418\n",
            "Epoch 4, Sample 905, Loss: 1.8857\n",
            "Epoch 4, Sample 906, Loss: 2.2712\n",
            "Epoch 4, Sample 907, Loss: 2.5250\n",
            "Epoch 4, Sample 908, Loss: 2.4554\n",
            "Epoch 4, Sample 909, Loss: 1.9532\n",
            "Epoch 4, Sample 910, Loss: 3.1592\n",
            "Epoch 4, Sample 911, Loss: 2.8837\n",
            "Epoch 4, Sample 912, Loss: 2.0331\n",
            "Epoch 4, Sample 913, Loss: 2.4148\n",
            "Epoch 4, Sample 914, Loss: 3.0127\n",
            "Epoch 4, Sample 915, Loss: 3.2818\n",
            "Epoch 4, Sample 916, Loss: 2.6189\n",
            "Epoch 4, Sample 917, Loss: 2.3155\n",
            "Epoch 4, Sample 918, Loss: 2.1612\n",
            "Epoch 4, Sample 919, Loss: 2.4830\n",
            "Epoch 4, Sample 920, Loss: 2.6285\n",
            "Epoch 4, Sample 921, Loss: 2.2851\n",
            "Epoch 4, Sample 922, Loss: 2.5877\n",
            "Epoch 4, Sample 923, Loss: 2.1074\n",
            "Epoch 4, Sample 924, Loss: 2.2652\n",
            "Epoch 4, Sample 925, Loss: 2.5957\n",
            "Epoch 4, Sample 926, Loss: 3.0667\n",
            "Epoch 4, Sample 927, Loss: 2.4279\n",
            "Epoch 4, Sample 928, Loss: 2.2300\n",
            "Epoch 4, Sample 929, Loss: 2.4384\n",
            "Epoch 4, Sample 930, Loss: 2.4183\n",
            "Epoch 4, Sample 931, Loss: 2.3226\n",
            "Epoch 4, Sample 932, Loss: 1.6107\n",
            "Epoch 4, Sample 933, Loss: 2.3695\n",
            "Epoch 4, Sample 934, Loss: 2.0017\n",
            "Epoch 4, Sample 935, Loss: 2.5969\n",
            "Epoch 4, Sample 936, Loss: 2.6614\n",
            "Epoch 4, Sample 937, Loss: 2.2779\n",
            "Epoch 4, Sample 938, Loss: 2.0957\n",
            "Epoch 4, Sample 939, Loss: 2.2860\n",
            "Epoch 4, Sample 940, Loss: 2.2193\n",
            "Epoch 4, Sample 941, Loss: 2.1782\n",
            "Epoch 4, Sample 942, Loss: 1.8351\n",
            "Epoch 4, Sample 943, Loss: 1.7651\n",
            "Epoch 4, Sample 944, Loss: 2.2993\n",
            "Epoch 4, Sample 945, Loss: 2.4535\n",
            "Epoch 4, Sample 946, Loss: 2.1450\n",
            "Epoch 4, Sample 947, Loss: 2.0376\n",
            "Epoch 4, Sample 948, Loss: 3.3199\n",
            "Epoch 4, Sample 949, Loss: 3.4145\n",
            "Epoch 4, Sample 950, Loss: 2.2302\n",
            "Epoch 4, Sample 951, Loss: 2.3256\n",
            "Epoch 4, Sample 952, Loss: 2.6288\n",
            "Epoch 4, Sample 953, Loss: 2.7803\n",
            "Epoch 4, Sample 954, Loss: 2.4974\n",
            "Epoch 4, Sample 955, Loss: 2.4206\n",
            "Epoch 4, Sample 956, Loss: 2.9188\n",
            "Epoch 4, Sample 957, Loss: 2.2858\n",
            "Epoch 4, Sample 958, Loss: 2.4357\n",
            "Epoch 4, Sample 959, Loss: 2.8267\n",
            "Epoch 4, Sample 960, Loss: 2.0892\n",
            "Epoch 4, Sample 961, Loss: 2.8288\n",
            "Epoch 4, Sample 962, Loss: 2.7101\n",
            "Epoch 4, Sample 963, Loss: 1.9708\n",
            "Epoch 4, Sample 964, Loss: 1.8550\n",
            "Epoch 4, Sample 965, Loss: 1.9093\n",
            "Epoch 4, Sample 966, Loss: 2.8418\n",
            "Epoch 4, Sample 967, Loss: 2.1131\n",
            "Epoch 4, Sample 968, Loss: 2.5492\n",
            "Epoch 4, Sample 969, Loss: 2.4410\n",
            "Epoch 4, Sample 970, Loss: 2.5498\n",
            "Epoch 4, Sample 971, Loss: 2.2584\n",
            "Epoch 4, Sample 972, Loss: 2.5466\n",
            "Epoch 4, Sample 973, Loss: 2.8689\n",
            "Epoch 4, Sample 974, Loss: 2.5637\n",
            "Epoch 4, Sample 975, Loss: 2.6145\n",
            "Epoch 4, Sample 976, Loss: 1.7015\n",
            "Epoch 4, Sample 977, Loss: 2.6109\n",
            "Epoch 4, Sample 978, Loss: 1.6637\n",
            "Epoch 4, Sample 979, Loss: 2.3629\n",
            "Epoch 4, Sample 980, Loss: 2.6634\n",
            "Epoch 4, Sample 981, Loss: 1.9359\n",
            "Epoch 4, Sample 982, Loss: 2.2530\n",
            "Epoch 4, Sample 983, Loss: 3.0215\n",
            "Epoch 4, Sample 984, Loss: 2.6288\n",
            "Epoch 4, Sample 985, Loss: 2.2693\n",
            "Epoch 4, Sample 986, Loss: 2.3378\n",
            "Epoch 4, Sample 987, Loss: 2.7143\n",
            "Epoch 4, Sample 988, Loss: 2.4548\n",
            "Epoch 4, Sample 989, Loss: 2.8673\n",
            "Epoch 4, Sample 990, Loss: 2.2456\n",
            "Epoch 4, Sample 991, Loss: 2.4396\n",
            "Epoch 4, Sample 992, Loss: 3.0451\n",
            "Epoch 4, Sample 993, Loss: 2.1058\n",
            "Epoch 4, Sample 994, Loss: 3.1427\n",
            "Epoch 4, Sample 995, Loss: 2.1501\n",
            "Epoch 4, Sample 996, Loss: 2.7533\n",
            "Epoch 4, Sample 997, Loss: 2.5393\n",
            "Epoch 4, Sample 998, Loss: 3.1215\n",
            "Epoch 4, Sample 999, Loss: 2.7121\n",
            "Epoch 4, Sample 1000, Loss: 2.2022\n",
            "Epoch 4, Sample 1001, Loss: 2.9723\n",
            "Epoch 4, Sample 1002, Loss: 3.1805\n",
            "Epoch 4, Sample 1003, Loss: 3.0014\n",
            "Epoch 4, Sample 1004, Loss: 2.9291\n",
            "Epoch 4, Sample 1005, Loss: 2.2961\n",
            "Epoch 4, Sample 1006, Loss: 2.9184\n",
            "Epoch 4, Sample 1007, Loss: 2.7685\n",
            "Epoch 4, Sample 1008, Loss: 2.5742\n",
            "Epoch 4, Sample 1009, Loss: 2.4291\n",
            "Epoch 4, Sample 1010, Loss: 1.9588\n",
            "Epoch 4, Sample 1011, Loss: 2.4039\n",
            "Epoch 4, Sample 1012, Loss: 2.3163\n",
            "Epoch 4, Sample 1013, Loss: 1.5363\n",
            "Epoch 4, Sample 1014, Loss: 2.4772\n",
            "Epoch 4, Sample 1015, Loss: 3.2298\n",
            "Epoch 4, Sample 1016, Loss: 2.1596\n",
            "Epoch 4, Sample 1017, Loss: 3.1105\n",
            "Epoch 4, Sample 1018, Loss: 2.7294\n",
            "Epoch 4, Sample 1019, Loss: 2.6582\n",
            "Epoch 4, Sample 1020, Loss: 2.2814\n",
            "Epoch 4, Sample 1021, Loss: 2.3672\n",
            "Epoch 4, Sample 1022, Loss: 2.1217\n",
            "Epoch 4, Sample 1023, Loss: 2.0690\n",
            "Epoch 4, Sample 1024, Loss: 2.1490\n",
            "Epoch 4, Sample 1025, Loss: 2.7179\n",
            "Epoch 4, Sample 1026, Loss: 2.0179\n",
            "Epoch 4, Sample 1027, Loss: 2.3545\n",
            "Epoch 4, Sample 1028, Loss: 2.4386\n",
            "Epoch 4, Sample 1029, Loss: 1.7378\n",
            "Epoch 4, Sample 1030, Loss: 1.4822\n",
            "Epoch 4, Sample 1031, Loss: 2.6520\n",
            "Epoch 4, Sample 1032, Loss: 2.4046\n",
            "Epoch 4, Sample 1033, Loss: 2.1737\n",
            "Epoch 4, Sample 1034, Loss: 2.6671\n",
            "Epoch 4, Sample 1035, Loss: 1.9576\n",
            "Epoch 4, Sample 1036, Loss: 1.8820\n",
            "Epoch 4, Sample 1037, Loss: 2.4332\n",
            "Epoch 4, Sample 1038, Loss: 1.6718\n",
            "Epoch 4, Sample 1039, Loss: 2.1644\n",
            "Epoch 4, Sample 1040, Loss: 2.3566\n",
            "Epoch 4, Sample 1041, Loss: 2.0405\n",
            "Epoch 4, Sample 1042, Loss: 1.6491\n",
            "Epoch 4, Sample 1043, Loss: 1.7526\n",
            "Epoch 4, Sample 1044, Loss: 1.5568\n",
            "Epoch 4, Sample 1045, Loss: 2.1218\n",
            "Epoch 4, Sample 1046, Loss: 1.9733\n",
            "Epoch 4, Sample 1047, Loss: 2.6459\n",
            "Epoch 4, Sample 1048, Loss: 2.0821\n",
            "Epoch 4, Sample 1049, Loss: 2.2934\n",
            "Epoch 4, Sample 1050, Loss: 1.3044\n",
            "Epoch 4, Sample 1051, Loss: 1.9751\n",
            "Epoch 4, Sample 1052, Loss: 2.1842\n",
            "Epoch 4, Sample 1053, Loss: 2.3511\n",
            "Epoch 4, Sample 1054, Loss: 2.4379\n",
            "Epoch 4, Sample 1055, Loss: 2.1241\n",
            "Epoch 4, Sample 1056, Loss: 3.0540\n",
            "Epoch 4, Sample 1057, Loss: 3.3278\n",
            "Epoch 4, Sample 1058, Loss: 2.8417\n",
            "Epoch 4, Sample 1059, Loss: 2.3736\n",
            "Epoch 4, Sample 1060, Loss: 1.8111\n",
            "Epoch 4, Sample 1061, Loss: 2.6589\n",
            "Epoch 4, Sample 1062, Loss: 2.5473\n",
            "Epoch 4, Sample 1063, Loss: 2.3996\n",
            "Epoch 4, Sample 1064, Loss: 2.3293\n",
            "Epoch 4, Sample 1065, Loss: 1.8430\n",
            "Epoch 4, Sample 1066, Loss: 1.7019\n",
            "Epoch 4, Sample 1067, Loss: 1.7950\n",
            "Epoch 4, Sample 1068, Loss: 1.7661\n",
            "Epoch 4, Sample 1069, Loss: 1.3419\n",
            "Epoch 4, Sample 1070, Loss: 2.3108\n",
            "Epoch 4, Sample 1071, Loss: 1.8728\n",
            "Epoch 4, Sample 1072, Loss: 2.9913\n",
            "Epoch 4, Sample 1073, Loss: 1.4310\n",
            "Epoch 4, Sample 1074, Loss: 2.5915\n",
            "Epoch 4, Sample 1075, Loss: 1.7761\n",
            "Epoch 4, Sample 1076, Loss: 3.3677\n",
            "Epoch 4, Sample 1077, Loss: 2.8485\n",
            "Epoch 4, Sample 1078, Loss: 1.6806\n",
            "Epoch 4, Sample 1079, Loss: 2.7213\n",
            "Epoch 4, Sample 1080, Loss: 2.2689\n",
            "Epoch 4, Sample 1081, Loss: 1.9772\n",
            "Epoch 4, Sample 1082, Loss: 3.6120\n",
            "Epoch 4, Sample 1083, Loss: 2.2986\n",
            "Epoch 4, Sample 1084, Loss: 1.4090\n",
            "Epoch 4, Sample 1085, Loss: 1.8951\n",
            "Epoch 4, Sample 1086, Loss: 2.3921\n",
            "Epoch 4, Sample 1087, Loss: 3.3707\n",
            "Epoch 4, Sample 1088, Loss: 2.3277\n",
            "Epoch 4, Sample 1089, Loss: 1.7121\n",
            "Epoch 4, Sample 1090, Loss: 1.9419\n",
            "Epoch 4, Sample 1091, Loss: 2.1959\n",
            "Epoch 4, Sample 1092, Loss: 2.6269\n",
            "Epoch 4, Sample 1093, Loss: 2.3079\n",
            "Epoch 4, Sample 1094, Loss: 2.0557\n",
            "Epoch 4, Sample 1095, Loss: 2.0703\n",
            "Epoch 4, Sample 1096, Loss: 3.4238\n",
            "Epoch 4, Sample 1097, Loss: 2.5018\n",
            "Epoch 4, Sample 1098, Loss: 1.9554\n",
            "Epoch 4, Sample 1099, Loss: 2.1437\n",
            "Epoch 4, Sample 1100, Loss: 2.4971\n",
            "Epoch 4, Sample 1101, Loss: 1.6286\n",
            "Epoch 4, Sample 1102, Loss: 2.4155\n",
            "Epoch 4, Sample 1103, Loss: 1.9440\n",
            "Epoch 4, Sample 1104, Loss: 2.4195\n",
            "Epoch 4, Sample 1105, Loss: 1.7800\n",
            "Epoch 4, Sample 1106, Loss: 2.0120\n",
            "Epoch 4, Sample 1107, Loss: 2.4311\n",
            "Epoch 4, Sample 1108, Loss: 2.7164\n",
            "Epoch 4, Sample 1109, Loss: 1.5407\n",
            "Epoch 4, Sample 1110, Loss: 1.8873\n",
            "Epoch 4, Sample 1111, Loss: 1.9726\n",
            "Epoch 4, Sample 1112, Loss: 1.3931\n",
            "Epoch 4, Sample 1113, Loss: 1.7122\n",
            "Epoch 4, Sample 1114, Loss: 1.6336\n",
            "Epoch 4, Sample 1115, Loss: 3.5485\n",
            "Epoch 4, Sample 1116, Loss: 3.5141\n",
            "Epoch 4, Sample 1117, Loss: 2.1509\n",
            "Epoch 4, Sample 1118, Loss: 1.7058\n",
            "Epoch 4, Sample 1119, Loss: 2.2511\n",
            "Epoch 4, Sample 1120, Loss: 2.4184\n",
            "Epoch 4, Sample 1121, Loss: 2.2193\n",
            "Epoch 4, Sample 1122, Loss: 2.7288\n",
            "Epoch 4, Sample 1123, Loss: 1.7888\n",
            "Epoch 4, Sample 1124, Loss: 1.5127\n",
            "Epoch 4, Sample 1125, Loss: 2.4050\n",
            "Epoch 4, Sample 1126, Loss: 1.8606\n",
            "Epoch 4, Sample 1127, Loss: 2.3851\n",
            "Epoch 4, Sample 1128, Loss: 1.3378\n",
            "Epoch 4, Sample 1129, Loss: 3.1588\n",
            "Epoch 4, Sample 1130, Loss: 2.4292\n",
            "Epoch 4, Sample 1131, Loss: 2.2324\n",
            "Epoch 4, Sample 1132, Loss: 3.3958\n",
            "Epoch 4, Sample 1133, Loss: 2.2138\n",
            "Epoch 4, Sample 1134, Loss: 2.8399\n",
            "Epoch 4, Sample 1135, Loss: 2.8948\n",
            "Epoch 4, Sample 1136, Loss: 3.2947\n",
            "Epoch 4, Sample 1137, Loss: 2.5031\n",
            "Epoch 4, Sample 1138, Loss: 2.7152\n",
            "Epoch 4, Sample 1139, Loss: 2.3263\n",
            "Epoch 4, Sample 1140, Loss: 2.2526\n",
            "Epoch 4, Sample 1141, Loss: 2.5346\n",
            "Epoch 4, Sample 1142, Loss: 2.6472\n",
            "Epoch 4, Sample 1143, Loss: 2.2091\n",
            "Epoch 4, Sample 1144, Loss: 1.8653\n",
            "Epoch 4, Sample 1145, Loss: 1.8460\n",
            "Epoch 4, Sample 1146, Loss: 2.1241\n",
            "Epoch 4, Sample 1147, Loss: 3.4552\n",
            "Epoch 4, Sample 1148, Loss: 2.4594\n",
            "Epoch 4, Sample 1149, Loss: 2.1197\n",
            "Epoch 4, Sample 1150, Loss: 2.1226\n",
            "Epoch 4, Sample 1151, Loss: 2.2029\n",
            "Epoch 4, Sample 1152, Loss: 1.8777\n",
            "Epoch 4, Sample 1153, Loss: 2.2055\n",
            "Epoch 4, Sample 1154, Loss: 2.3015\n",
            "Epoch 4, Sample 1155, Loss: 2.1030\n",
            "Epoch 4, Sample 1156, Loss: 2.3268\n",
            "Epoch 4, Sample 1157, Loss: 1.6559\n",
            "Epoch 4, Sample 1158, Loss: 2.4563\n",
            "Epoch 4, Sample 1159, Loss: 2.3624\n",
            "Epoch 4, Sample 1160, Loss: 2.5654\n",
            "Epoch 4, Sample 1161, Loss: 1.8366\n",
            "Epoch 4, Sample 1162, Loss: 2.6416\n",
            "Epoch 4, Sample 1163, Loss: 2.5651\n",
            "Epoch 4, Sample 1164, Loss: 2.6189\n",
            "Epoch 4, Sample 1165, Loss: 2.4401\n",
            "Epoch 4, Sample 1166, Loss: 2.3144\n",
            "Epoch 4, Sample 1167, Loss: 2.1405\n",
            "Epoch 4, Sample 1168, Loss: 3.0780\n",
            "Epoch 4, Sample 1169, Loss: 1.9246\n",
            "Epoch 4, Sample 1170, Loss: 2.1600\n",
            "Epoch 4, Sample 1171, Loss: 2.2484\n",
            "Epoch 4, Sample 1172, Loss: 1.8467\n",
            "Epoch 4, Sample 1173, Loss: 1.5172\n",
            "Epoch 4, Sample 1174, Loss: 2.6869\n",
            "Epoch 4, Sample 1175, Loss: 2.3121\n",
            "Epoch 4, Sample 1176, Loss: 2.4683\n",
            "Epoch 4, Sample 1177, Loss: 2.6132\n",
            "Epoch 4, Sample 1178, Loss: 1.8110\n",
            "Epoch 4, Sample 1179, Loss: 2.7275\n",
            "Epoch 4, Sample 1180, Loss: 2.5940\n",
            "Epoch 4, Sample 1181, Loss: 2.5046\n",
            "Epoch 4, Sample 1182, Loss: 2.3610\n",
            "Epoch 4, Sample 1183, Loss: 1.8252\n",
            "Epoch 4, Sample 1184, Loss: 2.1058\n",
            "Epoch 4, Sample 1185, Loss: 2.1825\n",
            "Epoch 4, Sample 1186, Loss: 1.9861\n",
            "Epoch 4, Sample 1187, Loss: 1.8056\n",
            "Epoch 4, Sample 1188, Loss: 2.4794\n",
            "Epoch 4, Sample 1189, Loss: 2.0367\n",
            "Epoch 4, Sample 1190, Loss: 2.2239\n",
            "Epoch 4, Sample 1191, Loss: 2.2253\n",
            "Epoch 4, Sample 1192, Loss: 2.3152\n",
            "Epoch 4, Sample 1193, Loss: 1.7364\n",
            "Epoch 4, Sample 1194, Loss: 2.8194\n",
            "Epoch 4, Sample 1195, Loss: 2.2612\n",
            "Epoch 4, Sample 1196, Loss: 2.1839\n",
            "Epoch 4, Sample 1197, Loss: 2.0917\n",
            "Epoch 4, Sample 1198, Loss: 2.4565\n",
            "Epoch 4, Sample 1199, Loss: 1.9727\n",
            "Epoch 4, Sample 1200, Loss: 2.3169\n",
            "Epoch 4, Sample 1201, Loss: 2.3694\n",
            "Epoch 4, Sample 1202, Loss: 2.1464\n",
            "Epoch 4, Sample 1203, Loss: 2.3496\n",
            "Epoch 4, Sample 1204, Loss: 2.2721\n",
            "Epoch 4, Sample 1205, Loss: 2.5079\n",
            "Epoch 4, Sample 1206, Loss: 2.5773\n",
            "Epoch 4, Sample 1207, Loss: 2.8894\n",
            "Epoch 4, Sample 1208, Loss: 2.8772\n",
            "Epoch 4, Sample 1209, Loss: 1.4349\n",
            "Epoch 4, Sample 1210, Loss: 2.1917\n",
            "Epoch 4, Sample 1211, Loss: 2.8918\n",
            "Epoch 4, Sample 1212, Loss: 1.9316\n",
            "Epoch 4, Sample 1213, Loss: 1.6950\n",
            "Epoch 4, Sample 1214, Loss: 2.0544\n",
            "Epoch 4, Sample 1215, Loss: 2.0675\n",
            "Epoch 4, Sample 1216, Loss: 2.1983\n",
            "Epoch 4, Sample 1217, Loss: 2.5553\n",
            "Epoch 4, Sample 1218, Loss: 2.6027\n",
            "Epoch 4, Sample 1219, Loss: 2.4973\n",
            "Epoch 4, Sample 1220, Loss: 2.8938\n",
            "Epoch 4, Sample 1221, Loss: 2.1796\n",
            "Epoch 4, Sample 1222, Loss: 3.2364\n",
            "Epoch 4, Sample 1223, Loss: 2.2654\n",
            "Epoch 4, Sample 1224, Loss: 2.0121\n",
            "Epoch 4, Sample 1225, Loss: 2.5566\n",
            "Epoch 4, Sample 1226, Loss: 2.7622\n",
            "Epoch 4, Sample 1227, Loss: 2.8960\n",
            "Epoch 4, Sample 1228, Loss: 2.3669\n",
            "Epoch 4, Sample 1229, Loss: 2.5296\n",
            "Epoch 4, Sample 1230, Loss: 2.9965\n",
            "Epoch 4, Sample 1231, Loss: 2.5745\n",
            "Epoch 4, Sample 1232, Loss: 2.7485\n",
            "Epoch 4, Sample 1233, Loss: 3.6984\n",
            "Epoch 4, Sample 1234, Loss: 2.2807\n",
            "Epoch 4, Sample 1235, Loss: 2.1093\n",
            "Epoch 4, Sample 1236, Loss: 2.7445\n",
            "Epoch 4, Sample 1237, Loss: 2.9005\n",
            "Epoch 4, Sample 1238, Loss: 2.7753\n",
            "Epoch 4, Sample 1239, Loss: 2.6791\n",
            "Epoch 4, Sample 1240, Loss: 2.9254\n",
            "Epoch 4, Sample 1241, Loss: 2.5018\n",
            "Epoch 4, Sample 1242, Loss: 3.6866\n",
            "Epoch 4, Sample 1243, Loss: 2.9683\n",
            "Epoch 4, Sample 1244, Loss: 3.1928\n",
            "Epoch 4, Sample 1245, Loss: 3.3527\n",
            "Epoch 4, Sample 1246, Loss: 2.6486\n",
            "Epoch 4, Sample 1247, Loss: 3.4575\n",
            "Epoch 4, Sample 1248, Loss: 3.5436\n",
            "Epoch 4, Sample 1249, Loss: 3.0092\n",
            "Epoch 4, Sample 1250, Loss: 2.9872\n",
            "Epoch 4, Sample 1251, Loss: 3.3987\n",
            "Epoch 4, Sample 1252, Loss: 3.3232\n",
            "Epoch 4, Sample 1253, Loss: 2.5298\n",
            "Epoch 4, Sample 1254, Loss: 2.7898\n",
            "Epoch 4, Sample 1255, Loss: 2.7645\n",
            "Epoch 4, Sample 1256, Loss: 2.7035\n",
            "Epoch 4, Sample 1257, Loss: 2.7055\n",
            "Epoch 4, Sample 1258, Loss: 1.8532\n",
            "Epoch 4, Sample 1259, Loss: 2.6177\n",
            "Epoch 4, Sample 1260, Loss: 3.3192\n",
            "Epoch 4, Sample 1261, Loss: 3.2627\n",
            "Epoch 4, Sample 1262, Loss: 2.8602\n",
            "Epoch 4, Sample 1263, Loss: 2.6476\n",
            "Epoch 4, Sample 1264, Loss: 2.5167\n",
            "Epoch 4, Sample 1265, Loss: 2.7775\n",
            "Epoch 4, Sample 1266, Loss: 3.0022\n",
            "Epoch 4, Sample 1267, Loss: 2.8041\n",
            "Epoch 4, Sample 1268, Loss: 2.7583\n",
            "Epoch 4, Sample 1269, Loss: 2.0128\n",
            "Epoch 4, Sample 1270, Loss: 2.7348\n",
            "Epoch 4, Sample 1271, Loss: 2.3189\n",
            "Epoch 4, Sample 1272, Loss: 2.9379\n",
            "Epoch 4, Sample 1273, Loss: 3.6970\n",
            "Epoch 4, Sample 1274, Loss: 3.4574\n",
            "Epoch 4, Sample 1275, Loss: 2.8636\n",
            "Epoch 4, Sample 1276, Loss: 2.7534\n",
            "Epoch 4, Sample 1277, Loss: 2.7031\n",
            "Epoch 4, Sample 1278, Loss: 2.8508\n",
            "Epoch 4, Sample 1279, Loss: 2.4062\n",
            "Epoch 4, Sample 1280, Loss: 2.5790\n",
            "Epoch 4, Sample 1281, Loss: 2.5506\n",
            "Epoch 4, Sample 1282, Loss: 2.5348\n",
            "Epoch 4, Sample 1283, Loss: 3.0932\n",
            "Epoch 4, Sample 1284, Loss: 2.8252\n",
            "Epoch 4, Sample 1285, Loss: 3.8460\n",
            "Epoch 4, Sample 1286, Loss: 2.3845\n",
            "Epoch 4, Sample 1287, Loss: 2.7102\n",
            "Epoch 4, Sample 1288, Loss: 2.6376\n",
            "Epoch 4, Sample 1289, Loss: 2.8482\n",
            "Epoch 4, Sample 1290, Loss: 2.3948\n",
            "Epoch 4, Sample 1291, Loss: 2.8695\n",
            "Epoch 4, Sample 1292, Loss: 2.6889\n",
            "Epoch 4, Sample 1293, Loss: 3.9450\n",
            "Epoch 4, Sample 1294, Loss: 3.5754\n",
            "Epoch 4, Sample 1295, Loss: 3.1967\n",
            "Epoch 4, Sample 1296, Loss: 2.7869\n",
            "Epoch 4, Sample 1297, Loss: 2.9176\n",
            "Epoch 4, Sample 1298, Loss: 3.4390\n",
            "Epoch 4, Sample 1299, Loss: 3.1850\n",
            "Epoch 4, Sample 1300, Loss: 3.0048\n",
            "Epoch 4, Sample 1301, Loss: 3.3862\n",
            "Epoch 4, Sample 1302, Loss: 2.8851\n",
            "Epoch 4, Sample 1303, Loss: 3.5999\n",
            "Epoch 4, Sample 1304, Loss: 2.5061\n",
            "Epoch 4, Sample 1305, Loss: 3.0186\n",
            "Epoch 4, Sample 1306, Loss: 2.4379\n",
            "Epoch 4, Sample 1307, Loss: 1.9496\n",
            "Epoch 4, Sample 1308, Loss: 2.5987\n",
            "Epoch 4, Sample 1309, Loss: 2.7492\n",
            "Epoch 4, Sample 1310, Loss: 1.9693\n",
            "Epoch 4, Sample 1311, Loss: 3.5596\n",
            "Epoch 4, Sample 1312, Loss: 3.3676\n",
            "Epoch 4, Sample 1313, Loss: 3.2196\n",
            "Epoch 4, Sample 1314, Loss: 2.9301\n",
            "Epoch 4, Sample 1315, Loss: 2.1302\n",
            "Epoch 4, Sample 1316, Loss: 2.2583\n",
            "Epoch 4, Sample 1317, Loss: 3.1288\n",
            "Epoch 4, Sample 1318, Loss: 2.9608\n",
            "Epoch 4, Sample 1319, Loss: 3.0037\n",
            "Epoch 4, Sample 1320, Loss: 2.8212\n",
            "Epoch 4, Sample 1321, Loss: 2.9369\n",
            "Epoch 4, Sample 1322, Loss: 3.1147\n",
            "Epoch 4, Sample 1323, Loss: 2.5291\n",
            "Epoch 4, Sample 1324, Loss: 2.9262\n",
            "Epoch 4, Sample 1325, Loss: 2.7760\n",
            "Epoch 4, Sample 1326, Loss: 3.0175\n",
            "Epoch 4, Sample 1327, Loss: 2.4678\n",
            "Epoch 4, Sample 1328, Loss: 2.7004\n",
            "Epoch 4, Sample 1329, Loss: 2.6149\n",
            "Epoch 4, Sample 1330, Loss: 2.3907\n",
            "Epoch 4, Sample 1331, Loss: 2.4986\n",
            "Epoch 4, Sample 1332, Loss: 2.2751\n",
            "Epoch 4, Sample 1333, Loss: 3.6489\n",
            "Epoch 4, Sample 1334, Loss: 3.0591\n",
            "Epoch 4, Sample 1335, Loss: 3.0886\n",
            "Epoch 4, Sample 1336, Loss: 2.8029\n",
            "Epoch 4, Sample 1337, Loss: 3.3480\n",
            "Epoch 4, Sample 1338, Loss: 2.9416\n",
            "Epoch 4, Sample 1339, Loss: 2.7727\n",
            "Epoch 4, Sample 1340, Loss: 2.6221\n",
            "Epoch 4, Sample 1341, Loss: 2.4485\n",
            "Epoch 4, Sample 1342, Loss: 2.6487\n",
            "Epoch 4, Sample 1343, Loss: 3.5244\n",
            "Epoch 4, Sample 1344, Loss: 3.7118\n",
            "Epoch 4, Sample 1345, Loss: 3.4281\n",
            "Epoch 4, Sample 1346, Loss: 2.4590\n",
            "Epoch 4, Sample 1347, Loss: 3.0329\n",
            "Epoch 4, Sample 1348, Loss: 2.3471\n",
            "Epoch 4, Sample 1349, Loss: 2.6230\n",
            "Epoch 4, Sample 1350, Loss: 2.4337\n",
            "Epoch 4, Sample 1351, Loss: 2.9478\n",
            "Epoch 4, Sample 1352, Loss: 2.6586\n",
            "Epoch 4, Sample 1353, Loss: 3.1102\n",
            "Epoch 4, Sample 1354, Loss: 3.0405\n",
            "Epoch 4, Sample 1355, Loss: 3.5309\n",
            "Epoch 4, Sample 1356, Loss: 2.5477\n",
            "Epoch 4, Sample 1357, Loss: 3.2787\n",
            "Epoch 4, Sample 1358, Loss: 3.6145\n",
            "Epoch 4, Sample 1359, Loss: 2.0773\n",
            "Epoch 4, Sample 1360, Loss: 2.4121\n",
            "Epoch 4, Sample 1361, Loss: 3.1211\n",
            "Epoch 4, Sample 1362, Loss: 2.9257\n",
            "Epoch 4, Sample 1363, Loss: 2.6148\n",
            "Epoch 4, Sample 1364, Loss: 2.9850\n",
            "Epoch 4, Sample 1365, Loss: 2.8050\n",
            "Epoch 4, Sample 1366, Loss: 2.7118\n",
            "Epoch 4, Sample 1367, Loss: 3.5973\n",
            "Epoch 4, Sample 1368, Loss: 2.8616\n",
            "Epoch 4, Sample 1369, Loss: 2.9907\n",
            "Epoch 4, Sample 1370, Loss: 2.4584\n",
            "Epoch 4, Sample 1371, Loss: 3.2260\n",
            "Epoch 4, Sample 1372, Loss: 2.6853\n",
            "Epoch 4, Sample 1373, Loss: 3.5785\n",
            "Epoch 4, Sample 1374, Loss: 2.9082\n",
            "Epoch 4, Sample 1375, Loss: 3.3070\n",
            "Epoch 4, Sample 1376, Loss: 3.3763\n",
            "Epoch 4, Sample 1377, Loss: 2.8585\n",
            "Epoch 4, Sample 1378, Loss: 3.7655\n",
            "Epoch 4, Sample 1379, Loss: 3.4217\n",
            "Epoch 4, Sample 1380, Loss: 2.0511\n",
            "Epoch 4, Sample 1381, Loss: 2.8896\n",
            "Epoch 4, Sample 1382, Loss: 3.4275\n",
            "Epoch 4, Sample 1383, Loss: 3.0066\n",
            "Epoch 4, Sample 1384, Loss: 3.1330\n",
            "Epoch 4, Sample 1385, Loss: 3.3666\n",
            "Epoch 4, Sample 1386, Loss: 3.3158\n",
            "Epoch 4, Sample 1387, Loss: 3.3900\n",
            "Epoch 4, Sample 1388, Loss: 2.9201\n",
            "Epoch 4, Sample 1389, Loss: 3.7712\n",
            "Epoch 4, Sample 1390, Loss: 2.9560\n",
            "Epoch 4, Sample 1391, Loss: 3.8325\n",
            "Epoch 4, Sample 1392, Loss: 2.7960\n",
            "Epoch 4, Sample 1393, Loss: 2.9384\n",
            "Epoch 4, Sample 1394, Loss: 2.8901\n",
            "Epoch 4, Sample 1395, Loss: 2.8361\n",
            "Epoch 4, Sample 1396, Loss: 2.7116\n",
            "Epoch 4, Sample 1397, Loss: 3.0726\n",
            "Epoch 4, Sample 1398, Loss: 2.8558\n",
            "Epoch 4, Sample 1399, Loss: 2.9313\n",
            "Epoch 4, Sample 1400, Loss: 2.6205\n",
            "Epoch 4, Sample 1401, Loss: 3.3275\n",
            "Epoch 4, Sample 1402, Loss: 2.8428\n",
            "Epoch 4, Sample 1403, Loss: 2.8550\n",
            "Epoch 4, Sample 1404, Loss: 3.2217\n",
            "Epoch 4, Sample 1405, Loss: 2.9087\n",
            "Epoch 4, Sample 1406, Loss: 2.9067\n",
            "Epoch 4, Sample 1407, Loss: 2.6880\n",
            "Epoch 4, Sample 1408, Loss: 2.6951\n",
            "Epoch 4, Sample 1409, Loss: 2.7138\n",
            "Epoch 4, Sample 1410, Loss: 3.1617\n",
            "Epoch 4, Sample 1411, Loss: 2.9430\n",
            "Epoch 4, Sample 1412, Loss: 3.0016\n",
            "Epoch 4, Sample 1413, Loss: 3.3458\n",
            "Epoch 4, Sample 1414, Loss: 2.8410\n",
            "Epoch 4, Sample 1415, Loss: 2.8988\n",
            "Epoch 4, Sample 1416, Loss: 2.5886\n",
            "Epoch 4, Sample 1417, Loss: 3.1486\n",
            "Epoch 4, Sample 1418, Loss: 3.0217\n",
            "Epoch 4, Sample 1419, Loss: 2.7133\n",
            "Epoch 4, Sample 1420, Loss: 3.6744\n",
            "Epoch 4, Sample 1421, Loss: 3.2205\n",
            "Epoch 4, Sample 1422, Loss: 3.2693\n",
            "Epoch 4, Sample 1423, Loss: 2.7542\n",
            "Epoch 4, Sample 1424, Loss: 2.5612\n",
            "Epoch 4, Sample 1425, Loss: 2.7972\n",
            "Epoch 4, Sample 1426, Loss: 3.4629\n",
            "Epoch 4, Sample 1427, Loss: 2.5839\n",
            "Epoch 4, Sample 1428, Loss: 3.1895\n",
            "Epoch 4, Sample 1429, Loss: 2.6968\n",
            "Epoch 4, Sample 1430, Loss: 2.7938\n",
            "Epoch 4, Sample 1431, Loss: 2.3376\n",
            "Epoch 4, Sample 1432, Loss: 3.5109\n",
            "Epoch 4, Sample 1433, Loss: 2.6932\n",
            "Epoch 4, Sample 1434, Loss: 2.7118\n",
            "Epoch 4, Sample 1435, Loss: 2.4069\n",
            "Epoch 4, Sample 1436, Loss: 2.2129\n",
            "Epoch 4, Sample 1437, Loss: 1.4174\n",
            "Epoch 4, Sample 1438, Loss: 1.9142\n",
            "Epoch 4, Sample 1439, Loss: 2.4494\n",
            "Epoch 4, Sample 1440, Loss: 2.9148\n",
            "Epoch 4, Sample 1441, Loss: 2.8383\n",
            "Epoch 4, Sample 1442, Loss: 2.6397\n",
            "Epoch 4, Sample 1443, Loss: 2.1932\n",
            "Epoch 4, Sample 1444, Loss: 2.1576\n",
            "Epoch 4, Sample 1445, Loss: 2.7043\n",
            "Epoch 4, Sample 1446, Loss: 3.6549\n",
            "Epoch 4, Sample 1447, Loss: 2.5517\n",
            "Epoch 4, Sample 1448, Loss: 2.4954\n",
            "Epoch 4, Sample 1449, Loss: 2.4694\n",
            "Epoch 4, Sample 1450, Loss: 2.7215\n",
            "Epoch 4, Sample 1451, Loss: 2.1481\n",
            "Epoch 4, Sample 1452, Loss: 2.5870\n",
            "Epoch 4, Sample 1453, Loss: 2.3606\n",
            "Epoch 4, Sample 1454, Loss: 2.0502\n",
            "Epoch 4, Sample 1455, Loss: 2.0703\n",
            "Epoch 4, Sample 1456, Loss: 2.5700\n",
            "Epoch 4, Sample 1457, Loss: 2.4829\n",
            "Epoch 4, Sample 1458, Loss: 2.6699\n",
            "Epoch 4, Sample 1459, Loss: 2.5453\n",
            "Epoch 4, Sample 1460, Loss: 2.4251\n",
            "Epoch 4, Sample 1461, Loss: 2.6050\n",
            "Epoch 4, Sample 1462, Loss: 2.4581\n",
            "Epoch 4, Sample 1463, Loss: 2.7372\n",
            "Epoch 4, Sample 1464, Loss: 2.5821\n",
            "Epoch 4, Sample 1465, Loss: 2.0152\n",
            "Epoch 4, Sample 1466, Loss: 2.5337\n",
            "Epoch 4, Sample 1467, Loss: 2.8346\n",
            "Epoch 4, Sample 1468, Loss: 2.8155\n",
            "Epoch 4, Sample 1469, Loss: 2.5207\n",
            "Epoch 4, Sample 1470, Loss: 3.1973\n",
            "Epoch 4, Sample 1471, Loss: 2.4611\n",
            "Epoch 4, Sample 1472, Loss: 2.0344\n",
            "Epoch 4, Sample 1473, Loss: 2.5966\n",
            "Epoch 4, Sample 1474, Loss: 2.4252\n",
            "Epoch 4, Sample 1475, Loss: 2.4321\n",
            "Epoch 4, Sample 1476, Loss: 3.7282\n",
            "Epoch 4, Sample 1477, Loss: 2.0205\n",
            "Epoch 4, Sample 1478, Loss: 2.0850\n",
            "Epoch 4, Sample 1479, Loss: 2.8284\n",
            "Epoch 4, Sample 1480, Loss: 2.5082\n",
            "Epoch 4, Sample 1481, Loss: 2.6226\n",
            "Epoch 4, Sample 1482, Loss: 2.6536\n",
            "Epoch 4, Sample 1483, Loss: 2.7202\n",
            "Epoch 4, Sample 1484, Loss: 2.3542\n",
            "Epoch 4, Sample 1485, Loss: 3.6057\n",
            "Epoch 4, Sample 1486, Loss: 1.9188\n",
            "Epoch 4, Sample 1487, Loss: 2.0898\n",
            "Epoch 4, Sample 1488, Loss: 2.6781\n",
            "Epoch 4, Sample 1489, Loss: 3.6549\n",
            "Epoch 4, Sample 1490, Loss: 2.3308\n",
            "Epoch 4, Sample 1491, Loss: 2.4788\n",
            "Epoch 4, Sample 1492, Loss: 2.4890\n",
            "Epoch 4, Sample 1493, Loss: 2.3802\n",
            "Epoch 4, Sample 1494, Loss: 2.4041\n",
            "Epoch 4, Sample 1495, Loss: 3.0791\n",
            "Epoch 4, Sample 1496, Loss: 2.1292\n",
            "Epoch 4, Sample 1497, Loss: 2.3095\n",
            "Epoch 4, Sample 1498, Loss: 2.5653\n",
            "Epoch 4, Sample 1499, Loss: 2.5309\n",
            "Epoch 4, Sample 1500, Loss: 2.8431\n",
            "Epoch 4, Sample 1501, Loss: 3.3896\n",
            "Epoch 4, Sample 1502, Loss: 2.3001\n",
            "Epoch 4, Sample 1503, Loss: 2.6492\n",
            "Epoch 4, Sample 1504, Loss: 2.3332\n",
            "Epoch 4, Sample 1505, Loss: 2.3096\n",
            "Epoch 4, Sample 1506, Loss: 2.7463\n",
            "Epoch 4, Sample 1507, Loss: 3.1417\n",
            "Epoch 4, Sample 1508, Loss: 2.8272\n",
            "Epoch 4, Sample 1509, Loss: 1.9665\n",
            "Epoch 4, Sample 1510, Loss: 2.4282\n",
            "Epoch 4, Sample 1511, Loss: 2.6224\n",
            "Epoch 4, Sample 1512, Loss: 2.5466\n",
            "Epoch 4, Sample 1513, Loss: 2.9828\n",
            "Epoch 4, Sample 1514, Loss: 2.8361\n",
            "Epoch 4, Sample 1515, Loss: 3.4411\n",
            "Epoch 4, Sample 1516, Loss: 1.9379\n",
            "Epoch 4, Sample 1517, Loss: 3.6034\n",
            "Epoch 4, Sample 1518, Loss: 2.7075\n",
            "Epoch 4, Sample 1519, Loss: 2.8180\n",
            "Epoch 4, Sample 1520, Loss: 2.2604\n",
            "Epoch 4, Sample 1521, Loss: 2.7725\n",
            "Epoch 4, Sample 1522, Loss: 2.0612\n",
            "Epoch 4, Sample 1523, Loss: 2.7133\n",
            "Epoch 4, Sample 1524, Loss: 1.6398\n",
            "Epoch 4, Sample 1525, Loss: 3.3661\n",
            "Epoch 4, Sample 1526, Loss: 2.4021\n",
            "Epoch 4, Sample 1527, Loss: 3.0406\n",
            "Epoch 4, Sample 1528, Loss: 2.5637\n",
            "Epoch 4, Sample 1529, Loss: 2.5274\n",
            "Epoch 4, Sample 1530, Loss: 2.1162\n",
            "Epoch 4, Sample 1531, Loss: 3.3409\n",
            "Epoch 4, Sample 1532, Loss: 3.0574\n",
            "Epoch 4, Sample 1533, Loss: 2.4707\n",
            "Epoch 4, Sample 1534, Loss: 3.4228\n",
            "Epoch 4, Sample 1535, Loss: 3.8042\n",
            "Epoch 4, Sample 1536, Loss: 3.6443\n",
            "Epoch 4, Sample 1537, Loss: 1.5957\n",
            "Epoch 4, Sample 1538, Loss: 3.2164\n",
            "Epoch 4, Sample 1539, Loss: 2.6153\n",
            "Epoch 4, Sample 1540, Loss: 1.7818\n",
            "Epoch 4, Sample 1541, Loss: 2.6395\n",
            "Epoch 4, Sample 1542, Loss: 2.5080\n",
            "Epoch 4, Sample 1543, Loss: 2.6785\n",
            "Epoch 4, Sample 1544, Loss: 3.0386\n",
            "Epoch 4, Sample 1545, Loss: 1.7920\n",
            "Epoch 4, Sample 1546, Loss: 2.8007\n",
            "Epoch 4, Sample 1547, Loss: 2.6282\n",
            "Epoch 4, Sample 1548, Loss: 2.4506\n",
            "Epoch 4, Sample 1549, Loss: 1.9419\n",
            "Epoch 4, Sample 1550, Loss: 2.7935\n",
            "Epoch 4, Sample 1551, Loss: 2.5190\n",
            "Epoch 4, Sample 1552, Loss: 2.5650\n",
            "Epoch 4, Sample 1553, Loss: 2.2280\n",
            "Epoch 4, Sample 1554, Loss: 3.0718\n",
            "Epoch 4, Sample 1555, Loss: 3.5790\n",
            "Epoch 4, Sample 1556, Loss: 1.7363\n",
            "Epoch 4, Sample 1557, Loss: 2.9498\n",
            "Epoch 4, Sample 1558, Loss: 2.6992\n",
            "Epoch 4, Sample 1559, Loss: 1.9505\n",
            "Epoch 4, Sample 1560, Loss: 2.7008\n",
            "Epoch 4, Sample 1561, Loss: 2.7063\n",
            "Epoch 4, Sample 1562, Loss: 2.7125\n",
            "Epoch 4, Sample 1563, Loss: 2.8636\n",
            "Epoch 4, Sample 1564, Loss: 1.8974\n",
            "Epoch 4, Sample 1565, Loss: 2.6453\n",
            "Epoch 4, Sample 1566, Loss: 3.8627\n",
            "Epoch 4, Sample 1567, Loss: 2.5257\n",
            "Epoch 4, Sample 1568, Loss: 2.6886\n",
            "Epoch 4, Sample 1569, Loss: 2.9350\n",
            "Epoch 4, Sample 1570, Loss: 3.5148\n",
            "Epoch 4, Sample 1571, Loss: 2.9706\n",
            "Epoch 4, Sample 1572, Loss: 3.5969\n",
            "Epoch 4, Sample 1573, Loss: 2.8673\n",
            "Epoch 4, Sample 1574, Loss: 2.9863\n",
            "Epoch 4, Sample 1575, Loss: 2.5154\n",
            "Epoch 4, Sample 1576, Loss: 3.0901\n",
            "Epoch 4, Sample 1577, Loss: 2.6612\n",
            "Epoch 4, Sample 1578, Loss: 2.6055\n",
            "Epoch 4, Sample 1579, Loss: 2.5292\n",
            "Epoch 4, Sample 1580, Loss: 2.0787\n",
            "Epoch 4, Sample 1581, Loss: 2.6689\n",
            "Epoch 4, Sample 1582, Loss: 2.6747\n",
            "Epoch 4, Sample 1583, Loss: 2.9244\n",
            "Epoch 4, Sample 1584, Loss: 1.7796\n",
            "Epoch 4, Sample 1585, Loss: 1.9812\n",
            "Epoch 4, Sample 1586, Loss: 2.2203\n",
            "Epoch 4, Sample 1587, Loss: 2.1905\n",
            "Epoch 4, Sample 1588, Loss: 3.0777\n",
            "Epoch 4, Sample 1589, Loss: 2.2622\n",
            "Epoch 4, Sample 1590, Loss: 2.3334\n",
            "Epoch 4, Sample 1591, Loss: 2.5866\n",
            "Epoch 4, Sample 1592, Loss: 2.3402\n",
            "Epoch 4, Sample 1593, Loss: 1.7414\n",
            "Epoch 4, Sample 1594, Loss: 2.6214\n",
            "Epoch 4, Sample 1595, Loss: 2.5928\n",
            "Epoch 4, Sample 1596, Loss: 2.2422\n",
            "Epoch 4, Sample 1597, Loss: 2.3214\n",
            "Epoch 4, Sample 1598, Loss: 3.3299\n",
            "Epoch 4, Sample 1599, Loss: 2.0599\n",
            "Epoch 4, Sample 1600, Loss: 2.7592\n",
            "Epoch 4, Sample 1601, Loss: 1.9059\n",
            "Epoch 4, Sample 1602, Loss: 2.8906\n",
            "Epoch 4, Sample 1603, Loss: 2.7914\n",
            "Epoch 4, Sample 1604, Loss: 3.0901\n",
            "Epoch 4, Sample 1605, Loss: 2.4158\n",
            "Epoch 4, Sample 1606, Loss: 2.9808\n",
            "Epoch 4, Sample 1607, Loss: 1.9653\n",
            "Epoch 4, Sample 1608, Loss: 2.4969\n",
            "Epoch 4, Sample 1609, Loss: 2.5550\n",
            "Epoch 4, Sample 1610, Loss: 3.4848\n",
            "Epoch 4, Sample 1611, Loss: 2.9103\n",
            "Epoch 4, Sample 1612, Loss: 3.0717\n",
            "Epoch 4, Sample 1613, Loss: 2.3921\n",
            "Epoch 4, Sample 1614, Loss: 2.1827\n",
            "Epoch 4, Sample 1615, Loss: 2.7451\n",
            "Epoch 4, Sample 1616, Loss: 2.8873\n",
            "Epoch 4, Sample 1617, Loss: 2.5921\n",
            "Epoch 4, Sample 1618, Loss: 3.3265\n",
            "Epoch 4, Sample 1619, Loss: 2.6776\n",
            "Epoch 4, Sample 1620, Loss: 3.0286\n",
            "Epoch 4, Sample 1621, Loss: 3.1189\n",
            "Epoch 4, Sample 1622, Loss: 2.3259\n",
            "Epoch 4, Sample 1623, Loss: 2.4883\n",
            "Epoch 4, Sample 1624, Loss: 2.5914\n",
            "Epoch 4, Sample 1625, Loss: 2.1788\n",
            "Epoch 4, Sample 1626, Loss: 3.5583\n",
            "Epoch 4, Sample 1627, Loss: 2.2193\n",
            "Epoch 4, Sample 1628, Loss: 2.4054\n",
            "Epoch 4, Sample 1629, Loss: 2.6866\n",
            "Epoch 4, Sample 1630, Loss: 2.2635\n",
            "Epoch 4, Sample 1631, Loss: 2.6756\n",
            "Epoch 4, Sample 1632, Loss: 2.3135\n",
            "Epoch 4, Sample 1633, Loss: 2.8651\n",
            "Epoch 4, Sample 1634, Loss: 1.9978\n",
            "Epoch 4, Sample 1635, Loss: 2.1673\n",
            "Epoch 4, Sample 1636, Loss: 2.2122\n",
            "Epoch 4, Sample 1637, Loss: 1.6044\n",
            "Epoch 4, Sample 1638, Loss: 2.1639\n",
            "Epoch 4, Sample 1639, Loss: 2.4916\n",
            "Epoch 4, Sample 1640, Loss: 1.4269\n",
            "Epoch 4, Sample 1641, Loss: 2.4544\n",
            "Epoch 4, Sample 1642, Loss: 1.9575\n",
            "Epoch 4, Sample 1643, Loss: 2.2746\n",
            "Epoch 4, Sample 1644, Loss: 2.3152\n",
            "Epoch 4, Sample 1645, Loss: 2.6343\n",
            "Epoch 4, Sample 1646, Loss: 2.5365\n",
            "Epoch 4, Sample 1647, Loss: 1.9696\n",
            "Epoch 4, Sample 1648, Loss: 2.9347\n",
            "Epoch 4, Sample 1649, Loss: 2.5465\n",
            "Epoch 4, Sample 1650, Loss: 2.3260\n",
            "Epoch 4, Sample 1651, Loss: 2.3444\n",
            "Epoch 4, Sample 1652, Loss: 2.0376\n",
            "Epoch 4, Sample 1653, Loss: 1.6417\n",
            "Epoch 4, Sample 1654, Loss: 3.0404\n",
            "Epoch 4, Sample 1655, Loss: 1.6819\n",
            "Epoch 4, Sample 1656, Loss: 1.8042\n",
            "Epoch 4, Sample 1657, Loss: 2.5412\n",
            "Epoch 4, Sample 1658, Loss: 2.1238\n",
            "Epoch 4, Sample 1659, Loss: 1.5379\n",
            "Epoch 4, Sample 1660, Loss: 2.8168\n",
            "Epoch 4, Sample 1661, Loss: 2.5379\n",
            "Epoch 4, Sample 1662, Loss: 2.6510\n",
            "Epoch 4, Sample 1663, Loss: 2.4773\n",
            "Epoch 4, Sample 1664, Loss: 3.1177\n",
            "Epoch 4, Sample 1665, Loss: 2.2575\n",
            "Epoch 4, Sample 1666, Loss: 2.7081\n",
            "Epoch 4, Sample 1667, Loss: 2.2957\n",
            "Epoch 4, Sample 1668, Loss: 2.6299\n",
            "Epoch 4, Sample 1669, Loss: 2.6054\n",
            "Epoch 4, Sample 1670, Loss: 2.2119\n",
            "Epoch 4, Sample 1671, Loss: 2.4668\n",
            "Epoch 4, Sample 1672, Loss: 2.2451\n",
            "Epoch 4, Sample 1673, Loss: 2.8474\n",
            "Epoch 4, Sample 1674, Loss: 2.9670\n",
            "Epoch 4, Sample 1675, Loss: 3.6765\n",
            "Epoch 4, Sample 1676, Loss: 2.1789\n",
            "Epoch 4, Sample 1677, Loss: 2.9823\n",
            "Epoch 4, Sample 1678, Loss: 2.7931\n",
            "Epoch 4, Sample 1679, Loss: 2.1744\n",
            "Epoch 4, Sample 1680, Loss: 3.2284\n",
            "Epoch 4, Sample 1681, Loss: 2.2138\n",
            "Epoch 4, Sample 1682, Loss: 1.9172\n",
            "Epoch 4, Sample 1683, Loss: 2.8259\n",
            "Epoch 4, Sample 1684, Loss: 2.8874\n",
            "Epoch 4, Sample 1685, Loss: 3.0371\n",
            "Epoch 4, Sample 1686, Loss: 3.2819\n",
            "Epoch 4, Sample 1687, Loss: 1.9489\n",
            "Epoch 4, Sample 1688, Loss: 2.7818\n",
            "Epoch 4, Sample 1689, Loss: 2.1049\n",
            "Epoch 4, Sample 1690, Loss: 2.0913\n",
            "Epoch 4, Sample 1691, Loss: 2.5922\n",
            "Epoch 4, Sample 1692, Loss: 3.0388\n",
            "Epoch 4, Sample 1693, Loss: 3.4141\n",
            "Epoch 4, Sample 1694, Loss: 2.3943\n",
            "Epoch 4, Sample 1695, Loss: 3.0967\n",
            "Epoch 4, Sample 1696, Loss: 1.8612\n",
            "Epoch 4, Sample 1697, Loss: 2.1780\n",
            "Epoch 4, Sample 1698, Loss: 1.4615\n",
            "Epoch 4, Sample 1699, Loss: 2.9845\n",
            "Epoch 4, Sample 1700, Loss: 2.2541\n",
            "Epoch 4, Sample 1701, Loss: 1.8221\n",
            "Epoch 4, Sample 1702, Loss: 2.4347\n",
            "Epoch 4, Sample 1703, Loss: 2.1547\n",
            "Epoch 4, Sample 1704, Loss: 2.5710\n",
            "Epoch 4, Sample 1705, Loss: 2.5213\n",
            "Epoch 4, Sample 1706, Loss: 1.7620\n",
            "Epoch 4, Sample 1707, Loss: 2.1722\n",
            "Epoch 4, Sample 1708, Loss: 1.7634\n",
            "Epoch 4, Sample 1709, Loss: 2.1865\n",
            "Epoch 4, Sample 1710, Loss: 2.2599\n",
            "Epoch 4, Sample 1711, Loss: 3.2345\n",
            "Epoch 4, Sample 1712, Loss: 2.3110\n",
            "Epoch 4, Sample 1713, Loss: 2.3979\n",
            "Epoch 4, Sample 1714, Loss: 2.1148\n",
            "Epoch 4, Sample 1715, Loss: 1.9796\n",
            "Epoch 4, Sample 1716, Loss: 1.8310\n",
            "Epoch 4, Sample 1717, Loss: 2.2411\n",
            "Epoch 4, Sample 1718, Loss: 2.6444\n",
            "Epoch 4, Sample 1719, Loss: 2.1571\n",
            "Epoch 4, Sample 1720, Loss: 2.2439\n",
            "Epoch 4, Sample 1721, Loss: 2.2060\n",
            "Epoch 4, Sample 1722, Loss: 2.7673\n",
            "Epoch 4, Sample 1723, Loss: 2.5400\n",
            "Epoch 4, Sample 1724, Loss: 3.0467\n",
            "Epoch 4, Sample 1725, Loss: 1.8812\n",
            "Epoch 4, Sample 1726, Loss: 2.4359\n",
            "Epoch 4, Sample 1727, Loss: 2.3982\n",
            "Epoch 4, Sample 1728, Loss: 2.6713\n",
            "Epoch 4, Sample 1729, Loss: 1.7229\n",
            "Epoch 4, Sample 1730, Loss: 2.5315\n",
            "Epoch 4, Sample 1731, Loss: 2.6893\n",
            "Epoch 4, Sample 1732, Loss: 2.9038\n",
            "Epoch 4, Sample 1733, Loss: 2.1473\n",
            "Epoch 4, Sample 1734, Loss: 1.8585\n",
            "Epoch 4, Sample 1735, Loss: 2.0026\n",
            "Epoch 4, Sample 1736, Loss: 2.2931\n",
            "Epoch 4, Sample 1737, Loss: 2.7130\n",
            "Epoch 4, Sample 1738, Loss: 2.6436\n",
            "Epoch 4, Sample 1739, Loss: 2.2283\n",
            "Epoch 4, Sample 1740, Loss: 2.8739\n",
            "Epoch 4, Sample 1741, Loss: 2.3511\n",
            "Epoch 4, Sample 1742, Loss: 2.2673\n",
            "Epoch 4, Sample 1743, Loss: 2.0213\n",
            "Epoch 4, Sample 1744, Loss: 2.4634\n",
            "Epoch 4, Sample 1745, Loss: 2.4427\n",
            "Epoch 4, Sample 1746, Loss: 2.6171\n",
            "Epoch 4, Sample 1747, Loss: 2.5792\n",
            "Epoch 4, Sample 1748, Loss: 2.2948\n",
            "Epoch 4, Sample 1749, Loss: 2.5168\n",
            "Epoch 4, Sample 1750, Loss: 2.1669\n",
            "Epoch 4, Sample 1751, Loss: 2.6309\n",
            "Epoch 4, Sample 1752, Loss: 2.1596\n",
            "Epoch 4, Sample 1753, Loss: 1.4476\n",
            "Epoch 4, Sample 1754, Loss: 2.9464\n",
            "Epoch 4, Sample 1755, Loss: 2.7791\n",
            "Epoch 4, Sample 1756, Loss: 2.2933\n",
            "Epoch 4, Sample 1757, Loss: 2.0840\n",
            "Epoch 4, Sample 1758, Loss: 2.1926\n",
            "Epoch 4, Sample 1759, Loss: 2.2503\n",
            "Epoch 4, Sample 1760, Loss: 1.8788\n",
            "Epoch 4, Sample 1761, Loss: 2.8111\n",
            "Epoch 4, Sample 1762, Loss: 2.0739\n",
            "Epoch 4, Sample 1763, Loss: 1.7593\n",
            "Epoch 4, Sample 1764, Loss: 2.2489\n",
            "Epoch 4, Sample 1765, Loss: 2.5277\n",
            "Epoch 4, Sample 1766, Loss: 2.2879\n",
            "Epoch 4, Sample 1767, Loss: 1.7990\n",
            "Epoch 4, Sample 1768, Loss: 2.1049\n",
            "Epoch 4, Sample 1769, Loss: 2.6592\n",
            "Epoch 4, Sample 1770, Loss: 2.7826\n",
            "Epoch 4, Sample 1771, Loss: 2.7622\n",
            "Epoch 4, Sample 1772, Loss: 3.0782\n",
            "Epoch 4, Sample 1773, Loss: 2.1867\n",
            "Epoch 4, Sample 1774, Loss: 2.8248\n",
            "Epoch 4, Sample 1775, Loss: 2.2065\n",
            "Epoch 4, Sample 1776, Loss: 2.0265\n",
            "Epoch 4, Sample 1777, Loss: 2.4805\n",
            "Epoch 4, Sample 1778, Loss: 2.1780\n",
            "Epoch 4, Sample 1779, Loss: 2.3206\n",
            "Epoch 4, Sample 1780, Loss: 1.4612\n",
            "Epoch 4, Sample 1781, Loss: 1.8522\n",
            "Epoch 4, Sample 1782, Loss: 2.2284\n",
            "Epoch 4, Sample 1783, Loss: 2.0157\n",
            "Epoch 4, Sample 1784, Loss: 2.3943\n",
            "Epoch 4, Sample 1785, Loss: 2.0939\n",
            "Epoch 4, Sample 1786, Loss: 2.5957\n",
            "Epoch 4, Sample 1787, Loss: 1.9136\n",
            "Epoch 4, Sample 1788, Loss: 2.8574\n",
            "Epoch 4, Sample 1789, Loss: 2.4163\n",
            "Epoch 4, Sample 1790, Loss: 2.7457\n",
            "Epoch 4, Sample 1791, Loss: 2.3623\n",
            "Epoch 4, Sample 1792, Loss: 2.2808\n",
            "Epoch 4, Sample 1793, Loss: 3.0707\n",
            "Epoch 4, Sample 1794, Loss: 3.2162\n",
            "Epoch 4, Sample 1795, Loss: 1.9547\n",
            "Epoch 4, Sample 1796, Loss: 2.3115\n",
            "Epoch 4, Sample 1797, Loss: 3.2735\n",
            "Epoch 4, Sample 1798, Loss: 2.4526\n",
            "Epoch 4, Sample 1799, Loss: 2.3919\n",
            "Epoch 4, Sample 1800, Loss: 2.3375\n",
            "Epoch 4, Sample 1801, Loss: 2.2707\n",
            "Epoch 4, Sample 1802, Loss: 2.3119\n",
            "Epoch 4, Sample 1803, Loss: 2.3726\n",
            "Epoch 4, Sample 1804, Loss: 2.1961\n",
            "Epoch 4, Sample 1805, Loss: 2.5397\n",
            "Epoch 4, Sample 1806, Loss: 2.0931\n",
            "Epoch 4, Sample 1807, Loss: 1.6139\n",
            "Epoch 4, Sample 1808, Loss: 2.5301\n",
            "Epoch 4, Sample 1809, Loss: 3.3477\n",
            "Epoch 4, Sample 1810, Loss: 2.4596\n",
            "Epoch 4, Sample 1811, Loss: 2.6896\n",
            "Epoch 4, Sample 1812, Loss: 2.2714\n",
            "Epoch 4, Sample 1813, Loss: 3.1717\n",
            "Epoch 4, Sample 1814, Loss: 2.3786\n",
            "Epoch 4, Sample 1815, Loss: 1.8818\n",
            "Epoch 4, Sample 1816, Loss: 2.3543\n",
            "Epoch 4, Sample 1817, Loss: 2.4112\n",
            "Epoch 4, Sample 1818, Loss: 2.5045\n",
            "Epoch 4, Sample 1819, Loss: 2.7559\n",
            "Epoch 4, Sample 1820, Loss: 2.4541\n",
            "Epoch 4, Sample 1821, Loss: 1.9108\n",
            "Epoch 4, Sample 1822, Loss: 3.0317\n",
            "Epoch 4, Sample 1823, Loss: 1.9531\n",
            "Epoch 4, Sample 1824, Loss: 2.1174\n",
            "Epoch 4, Sample 1825, Loss: 2.2550\n",
            "Epoch 4, Sample 1826, Loss: 2.7538\n",
            "Epoch 4, Sample 1827, Loss: 2.5606\n",
            "Epoch 4, Sample 1828, Loss: 2.7333\n",
            "Epoch 4, Sample 1829, Loss: 2.2142\n",
            "Epoch 4, Sample 1830, Loss: 2.2561\n",
            "Epoch 4, Sample 1831, Loss: 2.5356\n",
            "Epoch 4, Sample 1832, Loss: 2.1360\n",
            "Epoch 4, Sample 1833, Loss: 2.3777\n",
            "Epoch 4, Sample 1834, Loss: 2.2873\n",
            "Epoch 4, Sample 1835, Loss: 2.3743\n",
            "Epoch 5, Sample 1, Loss: 3.3271\n",
            "Epoch 5, Sample 2, Loss: 2.4778\n",
            "Epoch 5, Sample 3, Loss: 2.8042\n",
            "Epoch 5, Sample 4, Loss: 3.0016\n",
            "Epoch 5, Sample 5, Loss: 3.2689\n",
            "Epoch 5, Sample 6, Loss: 2.8223\n",
            "Epoch 5, Sample 7, Loss: 2.5425\n",
            "Epoch 5, Sample 8, Loss: 2.3717\n",
            "Epoch 5, Sample 9, Loss: 3.0532\n",
            "Epoch 5, Sample 10, Loss: 2.9093\n",
            "Epoch 5, Sample 11, Loss: 2.7725\n",
            "Epoch 5, Sample 12, Loss: 2.1532\n",
            "Epoch 5, Sample 13, Loss: 2.1682\n",
            "Epoch 5, Sample 14, Loss: 1.9370\n",
            "Epoch 5, Sample 15, Loss: 2.2694\n",
            "Epoch 5, Sample 16, Loss: 2.4861\n",
            "Epoch 5, Sample 17, Loss: 2.2793\n",
            "Epoch 5, Sample 18, Loss: 2.9380\n",
            "Epoch 5, Sample 19, Loss: 2.8185\n",
            "Epoch 5, Sample 20, Loss: 2.1824\n",
            "Epoch 5, Sample 21, Loss: 2.2958\n",
            "Epoch 5, Sample 22, Loss: 3.0644\n",
            "Epoch 5, Sample 23, Loss: 1.3006\n",
            "Epoch 5, Sample 24, Loss: 3.1202\n",
            "Epoch 5, Sample 25, Loss: 2.3100\n",
            "Epoch 5, Sample 26, Loss: 2.3461\n",
            "Epoch 5, Sample 27, Loss: 1.5132\n",
            "Epoch 5, Sample 28, Loss: 3.4865\n",
            "Epoch 5, Sample 29, Loss: 2.3103\n",
            "Epoch 5, Sample 30, Loss: 1.9007\n",
            "Epoch 5, Sample 31, Loss: 1.4092\n",
            "Epoch 5, Sample 32, Loss: 1.9252\n",
            "Epoch 5, Sample 33, Loss: 1.4966\n",
            "Epoch 5, Sample 34, Loss: 1.6478\n",
            "Epoch 5, Sample 35, Loss: 1.8609\n",
            "Epoch 5, Sample 36, Loss: 1.4360\n",
            "Epoch 5, Sample 37, Loss: 1.8446\n",
            "Epoch 5, Sample 38, Loss: 1.5616\n",
            "Epoch 5, Sample 39, Loss: 1.7844\n",
            "Epoch 5, Sample 40, Loss: 1.9834\n",
            "Epoch 5, Sample 41, Loss: 1.5029\n",
            "Epoch 5, Sample 42, Loss: 1.9215\n",
            "Epoch 5, Sample 43, Loss: 2.5901\n",
            "Epoch 5, Sample 44, Loss: 1.7671\n",
            "Epoch 5, Sample 45, Loss: 1.8871\n",
            "Epoch 5, Sample 46, Loss: 1.4494\n",
            "Epoch 5, Sample 47, Loss: 2.0415\n",
            "Epoch 5, Sample 48, Loss: 1.7284\n",
            "Epoch 5, Sample 49, Loss: 1.8036\n",
            "Epoch 5, Sample 50, Loss: 1.9703\n",
            "Epoch 5, Sample 51, Loss: 1.2838\n",
            "Epoch 5, Sample 52, Loss: 1.8330\n",
            "Epoch 5, Sample 53, Loss: 1.9376\n",
            "Epoch 5, Sample 54, Loss: 1.9009\n",
            "Epoch 5, Sample 55, Loss: 2.2331\n",
            "Epoch 5, Sample 56, Loss: 2.1201\n",
            "Epoch 5, Sample 57, Loss: 1.3083\n",
            "Epoch 5, Sample 58, Loss: 1.8961\n",
            "Epoch 5, Sample 59, Loss: 1.9356\n",
            "Epoch 5, Sample 60, Loss: 1.7050\n",
            "Epoch 5, Sample 61, Loss: 1.4882\n",
            "Epoch 5, Sample 62, Loss: 1.7773\n",
            "Epoch 5, Sample 63, Loss: 1.7811\n",
            "Epoch 5, Sample 64, Loss: 2.3395\n",
            "Epoch 5, Sample 65, Loss: 1.7248\n",
            "Epoch 5, Sample 66, Loss: 1.6243\n",
            "Epoch 5, Sample 67, Loss: 1.6969\n",
            "Epoch 5, Sample 68, Loss: 1.8199\n",
            "Epoch 5, Sample 69, Loss: 1.5966\n",
            "Epoch 5, Sample 70, Loss: 1.7208\n",
            "Epoch 5, Sample 71, Loss: 1.4363\n",
            "Epoch 5, Sample 72, Loss: 1.5290\n",
            "Epoch 5, Sample 73, Loss: 1.8119\n",
            "Epoch 5, Sample 74, Loss: 1.7195\n",
            "Epoch 5, Sample 75, Loss: 2.3220\n",
            "Epoch 5, Sample 76, Loss: 1.8028\n",
            "Epoch 5, Sample 77, Loss: 1.2385\n",
            "Epoch 5, Sample 78, Loss: 1.7263\n",
            "Epoch 5, Sample 79, Loss: 1.8519\n",
            "Epoch 5, Sample 80, Loss: 2.0754\n",
            "Epoch 5, Sample 81, Loss: 1.5259\n",
            "Epoch 5, Sample 82, Loss: 1.1861\n",
            "Epoch 5, Sample 83, Loss: 1.9155\n",
            "Epoch 5, Sample 84, Loss: 1.6880\n",
            "Epoch 5, Sample 85, Loss: 1.8311\n",
            "Epoch 5, Sample 86, Loss: 1.4503\n",
            "Epoch 5, Sample 87, Loss: 1.8315\n",
            "Epoch 5, Sample 88, Loss: 1.6643\n",
            "Epoch 5, Sample 89, Loss: 2.2592\n",
            "Epoch 5, Sample 90, Loss: 1.5489\n",
            "Epoch 5, Sample 91, Loss: 2.0284\n",
            "Epoch 5, Sample 92, Loss: 1.7354\n",
            "Epoch 5, Sample 93, Loss: 1.9380\n",
            "Epoch 5, Sample 94, Loss: 1.8208\n",
            "Epoch 5, Sample 95, Loss: 2.0243\n",
            "Epoch 5, Sample 96, Loss: 1.9299\n",
            "Epoch 5, Sample 97, Loss: 2.2220\n",
            "Epoch 5, Sample 98, Loss: 2.5917\n",
            "Epoch 5, Sample 99, Loss: 2.2149\n",
            "Epoch 5, Sample 100, Loss: 2.9770\n",
            "Epoch 5, Sample 101, Loss: 2.2440\n",
            "Epoch 5, Sample 102, Loss: 2.5787\n",
            "Epoch 5, Sample 103, Loss: 2.2434\n",
            "Epoch 5, Sample 104, Loss: 2.1130\n",
            "Epoch 5, Sample 105, Loss: 2.1826\n",
            "Epoch 5, Sample 106, Loss: 1.8079\n",
            "Epoch 5, Sample 107, Loss: 1.9089\n",
            "Epoch 5, Sample 108, Loss: 2.6212\n",
            "Epoch 5, Sample 109, Loss: 1.5199\n",
            "Epoch 5, Sample 110, Loss: 2.8840\n",
            "Epoch 5, Sample 111, Loss: 1.2609\n",
            "Epoch 5, Sample 112, Loss: 2.5031\n",
            "Epoch 5, Sample 113, Loss: 1.7929\n",
            "Epoch 5, Sample 114, Loss: 2.0612\n",
            "Epoch 5, Sample 115, Loss: 2.3640\n",
            "Epoch 5, Sample 116, Loss: 1.6603\n",
            "Epoch 5, Sample 117, Loss: 2.7084\n",
            "Epoch 5, Sample 118, Loss: 2.0333\n",
            "Epoch 5, Sample 119, Loss: 2.7287\n",
            "Epoch 5, Sample 120, Loss: 2.4874\n",
            "Epoch 5, Sample 121, Loss: 2.1412\n",
            "Epoch 5, Sample 122, Loss: 1.8406\n",
            "Epoch 5, Sample 123, Loss: 2.7861\n",
            "Epoch 5, Sample 124, Loss: 2.0354\n",
            "Epoch 5, Sample 125, Loss: 1.9494\n",
            "Epoch 5, Sample 126, Loss: 2.0095\n",
            "Epoch 5, Sample 127, Loss: 2.8853\n",
            "Epoch 5, Sample 128, Loss: 2.0530\n",
            "Epoch 5, Sample 129, Loss: 2.0804\n",
            "Epoch 5, Sample 130, Loss: 2.6220\n",
            "Epoch 5, Sample 131, Loss: 1.5577\n",
            "Epoch 5, Sample 132, Loss: 1.8658\n",
            "Epoch 5, Sample 133, Loss: 2.6169\n",
            "Epoch 5, Sample 134, Loss: 2.1102\n",
            "Epoch 5, Sample 135, Loss: 2.1723\n",
            "Epoch 5, Sample 136, Loss: 1.7609\n",
            "Epoch 5, Sample 137, Loss: 2.4191\n",
            "Epoch 5, Sample 138, Loss: 1.8946\n",
            "Epoch 5, Sample 139, Loss: 2.9623\n",
            "Epoch 5, Sample 140, Loss: 2.0086\n",
            "Epoch 5, Sample 141, Loss: 2.4292\n",
            "Epoch 5, Sample 142, Loss: 1.9690\n",
            "Epoch 5, Sample 143, Loss: 2.2925\n",
            "Epoch 5, Sample 144, Loss: 2.1754\n",
            "Epoch 5, Sample 145, Loss: 1.6579\n",
            "Epoch 5, Sample 146, Loss: 3.1369\n",
            "Epoch 5, Sample 147, Loss: 1.9076\n",
            "Epoch 5, Sample 148, Loss: 2.7382\n",
            "Epoch 5, Sample 149, Loss: 1.8612\n",
            "Epoch 5, Sample 150, Loss: 1.8705\n",
            "Epoch 5, Sample 151, Loss: 1.4407\n",
            "Epoch 5, Sample 152, Loss: 1.6492\n",
            "Epoch 5, Sample 153, Loss: 3.3907\n",
            "Epoch 5, Sample 154, Loss: 1.8578\n",
            "Epoch 5, Sample 155, Loss: 2.1808\n",
            "Epoch 5, Sample 156, Loss: 2.3399\n",
            "Epoch 5, Sample 157, Loss: 1.5066\n",
            "Epoch 5, Sample 158, Loss: 1.5810\n",
            "Epoch 5, Sample 159, Loss: 2.0539\n",
            "Epoch 5, Sample 160, Loss: 2.3440\n",
            "Epoch 5, Sample 161, Loss: 2.6586\n",
            "Epoch 5, Sample 162, Loss: 2.4632\n",
            "Epoch 5, Sample 163, Loss: 3.1911\n",
            "Epoch 5, Sample 164, Loss: 1.8163\n",
            "Epoch 5, Sample 165, Loss: 1.8551\n",
            "Epoch 5, Sample 166, Loss: 2.3120\n",
            "Epoch 5, Sample 167, Loss: 1.7016\n",
            "Epoch 5, Sample 168, Loss: 2.5869\n",
            "Epoch 5, Sample 169, Loss: 2.6471\n",
            "Epoch 5, Sample 170, Loss: 1.9016\n",
            "Epoch 5, Sample 171, Loss: 1.7920\n",
            "Epoch 5, Sample 172, Loss: 1.6035\n",
            "Epoch 5, Sample 173, Loss: 2.0784\n",
            "Epoch 5, Sample 174, Loss: 2.4111\n",
            "Epoch 5, Sample 175, Loss: 1.9954\n",
            "Epoch 5, Sample 176, Loss: 2.8565\n",
            "Epoch 5, Sample 177, Loss: 2.4323\n",
            "Epoch 5, Sample 178, Loss: 3.0077\n",
            "Epoch 5, Sample 179, Loss: 1.8617\n",
            "Epoch 5, Sample 180, Loss: 2.2831\n",
            "Epoch 5, Sample 181, Loss: 2.9953\n",
            "Epoch 5, Sample 182, Loss: 2.9164\n",
            "Epoch 5, Sample 183, Loss: 2.1614\n",
            "Epoch 5, Sample 184, Loss: 1.5446\n",
            "Epoch 5, Sample 185, Loss: 2.3616\n",
            "Epoch 5, Sample 186, Loss: 1.7884\n",
            "Epoch 5, Sample 187, Loss: 2.2869\n",
            "Epoch 5, Sample 188, Loss: 2.0886\n",
            "Epoch 5, Sample 189, Loss: 3.0901\n",
            "Epoch 5, Sample 190, Loss: 2.8836\n",
            "Epoch 5, Sample 191, Loss: 1.9704\n",
            "Epoch 5, Sample 192, Loss: 2.1634\n",
            "Epoch 5, Sample 193, Loss: 2.2422\n",
            "Epoch 5, Sample 194, Loss: 2.2904\n",
            "Epoch 5, Sample 195, Loss: 2.5474\n",
            "Epoch 5, Sample 196, Loss: 2.2471\n",
            "Epoch 5, Sample 197, Loss: 2.0293\n",
            "Epoch 5, Sample 198, Loss: 1.3744\n",
            "Epoch 5, Sample 199, Loss: 2.0912\n",
            "Epoch 5, Sample 200, Loss: 1.5425\n",
            "Epoch 5, Sample 201, Loss: 1.7713\n",
            "Epoch 5, Sample 202, Loss: 2.5874\n",
            "Epoch 5, Sample 203, Loss: 2.1901\n",
            "Epoch 5, Sample 204, Loss: 2.8516\n",
            "Epoch 5, Sample 205, Loss: 1.9035\n",
            "Epoch 5, Sample 206, Loss: 2.0122\n",
            "Epoch 5, Sample 207, Loss: 2.8445\n",
            "Epoch 5, Sample 208, Loss: 1.9056\n",
            "Epoch 5, Sample 209, Loss: 2.0397\n",
            "Epoch 5, Sample 210, Loss: 2.0405\n",
            "Epoch 5, Sample 211, Loss: 1.9353\n",
            "Epoch 5, Sample 212, Loss: 1.6210\n",
            "Epoch 5, Sample 213, Loss: 2.2183\n",
            "Epoch 5, Sample 214, Loss: 1.8576\n",
            "Epoch 5, Sample 215, Loss: 2.1438\n",
            "Epoch 5, Sample 216, Loss: 2.6606\n",
            "Epoch 5, Sample 217, Loss: 1.8749\n",
            "Epoch 5, Sample 218, Loss: 2.2799\n",
            "Epoch 5, Sample 219, Loss: 2.4327\n",
            "Epoch 5, Sample 220, Loss: 2.1881\n",
            "Epoch 5, Sample 221, Loss: 2.5974\n",
            "Epoch 5, Sample 222, Loss: 2.2588\n",
            "Epoch 5, Sample 223, Loss: 2.3951\n",
            "Epoch 5, Sample 224, Loss: 2.1970\n",
            "Epoch 5, Sample 225, Loss: 2.3061\n",
            "Epoch 5, Sample 226, Loss: 2.1508\n",
            "Epoch 5, Sample 227, Loss: 2.8721\n",
            "Epoch 5, Sample 228, Loss: 2.1172\n",
            "Epoch 5, Sample 229, Loss: 2.3745\n",
            "Epoch 5, Sample 230, Loss: 2.8900\n",
            "Epoch 5, Sample 231, Loss: 2.1113\n",
            "Epoch 5, Sample 232, Loss: 3.4488\n",
            "Epoch 5, Sample 233, Loss: 2.1290\n",
            "Epoch 5, Sample 234, Loss: 2.8139\n",
            "Epoch 5, Sample 235, Loss: 2.4509\n",
            "Epoch 5, Sample 236, Loss: 2.6050\n",
            "Epoch 5, Sample 237, Loss: 1.5973\n",
            "Epoch 5, Sample 238, Loss: 2.5540\n",
            "Epoch 5, Sample 239, Loss: 1.9255\n",
            "Epoch 5, Sample 240, Loss: 1.8690\n",
            "Epoch 5, Sample 241, Loss: 1.6942\n",
            "Epoch 5, Sample 242, Loss: 2.3500\n",
            "Epoch 5, Sample 243, Loss: 2.5564\n",
            "Epoch 5, Sample 244, Loss: 2.5731\n",
            "Epoch 5, Sample 245, Loss: 2.3085\n",
            "Epoch 5, Sample 246, Loss: 2.2642\n",
            "Epoch 5, Sample 247, Loss: 2.8943\n",
            "Epoch 5, Sample 248, Loss: 2.6128\n",
            "Epoch 5, Sample 249, Loss: 2.0587\n",
            "Epoch 5, Sample 250, Loss: 2.7977\n",
            "Epoch 5, Sample 251, Loss: 1.9926\n",
            "Epoch 5, Sample 252, Loss: 1.5776\n",
            "Epoch 5, Sample 253, Loss: 2.1016\n",
            "Epoch 5, Sample 254, Loss: 1.8300\n",
            "Epoch 5, Sample 255, Loss: 1.9777\n",
            "Epoch 5, Sample 256, Loss: 1.8044\n",
            "Epoch 5, Sample 257, Loss: 2.3544\n",
            "Epoch 5, Sample 258, Loss: 2.5191\n",
            "Epoch 5, Sample 259, Loss: 2.1459\n",
            "Epoch 5, Sample 260, Loss: 1.8941\n",
            "Epoch 5, Sample 261, Loss: 2.2156\n",
            "Epoch 5, Sample 262, Loss: 2.8385\n",
            "Epoch 5, Sample 263, Loss: 2.2245\n",
            "Epoch 5, Sample 264, Loss: 1.7354\n",
            "Epoch 5, Sample 265, Loss: 1.9868\n",
            "Epoch 5, Sample 266, Loss: 1.9077\n",
            "Epoch 5, Sample 267, Loss: 1.8899\n",
            "Epoch 5, Sample 268, Loss: 2.1548\n",
            "Epoch 5, Sample 269, Loss: 2.7296\n",
            "Epoch 5, Sample 270, Loss: 2.3503\n",
            "Epoch 5, Sample 271, Loss: 2.2027\n",
            "Epoch 5, Sample 272, Loss: 2.0963\n",
            "Epoch 5, Sample 273, Loss: 1.9296\n",
            "Epoch 5, Sample 274, Loss: 2.1238\n",
            "Epoch 5, Sample 275, Loss: 1.4977\n",
            "Epoch 5, Sample 276, Loss: 2.7643\n",
            "Epoch 5, Sample 277, Loss: 2.3836\n",
            "Epoch 5, Sample 278, Loss: 1.4911\n",
            "Epoch 5, Sample 279, Loss: 1.7930\n",
            "Epoch 5, Sample 280, Loss: 2.3244\n",
            "Epoch 5, Sample 281, Loss: 2.0622\n",
            "Epoch 5, Sample 282, Loss: 2.6325\n",
            "Epoch 5, Sample 283, Loss: 1.2920\n",
            "Epoch 5, Sample 284, Loss: 1.9906\n",
            "Epoch 5, Sample 285, Loss: 1.9587\n",
            "Epoch 5, Sample 286, Loss: 2.2585\n",
            "Epoch 5, Sample 287, Loss: 2.3130\n",
            "Epoch 5, Sample 288, Loss: 1.7977\n",
            "Epoch 5, Sample 289, Loss: 1.9667\n",
            "Epoch 5, Sample 290, Loss: 2.1292\n",
            "Epoch 5, Sample 291, Loss: 3.1500\n",
            "Epoch 5, Sample 292, Loss: 1.5910\n",
            "Epoch 5, Sample 293, Loss: 1.9321\n",
            "Epoch 5, Sample 294, Loss: 2.3730\n",
            "Epoch 5, Sample 295, Loss: 1.9661\n",
            "Epoch 5, Sample 296, Loss: 1.9922\n",
            "Epoch 5, Sample 297, Loss: 2.3884\n",
            "Epoch 5, Sample 298, Loss: 2.1806\n",
            "Epoch 5, Sample 299, Loss: 2.5949\n",
            "Epoch 5, Sample 300, Loss: 2.1655\n",
            "Epoch 5, Sample 301, Loss: 2.6763\n",
            "Epoch 5, Sample 302, Loss: 2.0375\n",
            "Epoch 5, Sample 303, Loss: 2.7693\n",
            "Epoch 5, Sample 304, Loss: 1.6062\n",
            "Epoch 5, Sample 305, Loss: 1.4342\n",
            "Epoch 5, Sample 306, Loss: 1.3784\n",
            "Epoch 5, Sample 307, Loss: 3.6146\n",
            "Epoch 5, Sample 308, Loss: 2.0782\n",
            "Epoch 5, Sample 309, Loss: 1.9224\n",
            "Epoch 5, Sample 310, Loss: 2.1147\n",
            "Epoch 5, Sample 311, Loss: 2.2461\n",
            "Epoch 5, Sample 312, Loss: 2.1864\n",
            "Epoch 5, Sample 313, Loss: 1.7543\n",
            "Epoch 5, Sample 314, Loss: 1.6240\n",
            "Epoch 5, Sample 315, Loss: 2.5912\n",
            "Epoch 5, Sample 316, Loss: 2.8173\n",
            "Epoch 5, Sample 317, Loss: 2.3420\n",
            "Epoch 5, Sample 318, Loss: 1.8569\n",
            "Epoch 5, Sample 319, Loss: 2.5837\n",
            "Epoch 5, Sample 320, Loss: 1.8782\n",
            "Epoch 5, Sample 321, Loss: 1.8077\n",
            "Epoch 5, Sample 322, Loss: 1.9347\n",
            "Epoch 5, Sample 323, Loss: 1.7499\n",
            "Epoch 5, Sample 324, Loss: 2.2792\n",
            "Epoch 5, Sample 325, Loss: 2.0471\n",
            "Epoch 5, Sample 326, Loss: 2.2680\n",
            "Epoch 5, Sample 327, Loss: 2.2503\n",
            "Epoch 5, Sample 328, Loss: 3.2972\n",
            "Epoch 5, Sample 329, Loss: 2.1319\n",
            "Epoch 5, Sample 330, Loss: 2.2853\n",
            "Epoch 5, Sample 331, Loss: 2.1976\n",
            "Epoch 5, Sample 332, Loss: 1.7929\n",
            "Epoch 5, Sample 333, Loss: 2.9473\n",
            "Epoch 5, Sample 334, Loss: 3.6774\n",
            "Epoch 5, Sample 335, Loss: 2.7442\n",
            "Epoch 5, Sample 336, Loss: 1.8432\n",
            "Epoch 5, Sample 337, Loss: 1.7199\n",
            "Epoch 5, Sample 338, Loss: 1.6660\n",
            "Epoch 5, Sample 339, Loss: 2.2063\n",
            "Epoch 5, Sample 340, Loss: 3.2784\n",
            "Epoch 5, Sample 341, Loss: 1.9652\n",
            "Epoch 5, Sample 342, Loss: 2.0013\n",
            "Epoch 5, Sample 343, Loss: 1.5883\n",
            "Epoch 5, Sample 344, Loss: 2.0488\n",
            "Epoch 5, Sample 345, Loss: 2.6773\n",
            "Epoch 5, Sample 346, Loss: 2.5744\n",
            "Epoch 5, Sample 347, Loss: 2.9215\n",
            "Epoch 5, Sample 348, Loss: 1.7549\n",
            "Epoch 5, Sample 349, Loss: 2.4409\n",
            "Epoch 5, Sample 350, Loss: 2.2872\n",
            "Epoch 5, Sample 351, Loss: 2.3702\n",
            "Epoch 5, Sample 352, Loss: 2.5569\n",
            "Epoch 5, Sample 353, Loss: 2.8837\n",
            "Epoch 5, Sample 354, Loss: 3.0088\n",
            "Epoch 5, Sample 355, Loss: 2.2794\n",
            "Epoch 5, Sample 356, Loss: 3.4473\n",
            "Epoch 5, Sample 357, Loss: 1.6691\n",
            "Epoch 5, Sample 358, Loss: 2.3922\n",
            "Epoch 5, Sample 359, Loss: 2.1144\n",
            "Epoch 5, Sample 360, Loss: 2.4778\n",
            "Epoch 5, Sample 361, Loss: 1.9680\n",
            "Epoch 5, Sample 362, Loss: 2.6760\n",
            "Epoch 5, Sample 363, Loss: 2.4814\n",
            "Epoch 5, Sample 364, Loss: 1.7097\n",
            "Epoch 5, Sample 365, Loss: 3.0220\n",
            "Epoch 5, Sample 366, Loss: 2.3244\n",
            "Epoch 5, Sample 367, Loss: 1.3723\n",
            "Epoch 5, Sample 368, Loss: 2.2990\n",
            "Epoch 5, Sample 369, Loss: 2.0473\n",
            "Epoch 5, Sample 370, Loss: 1.5499\n",
            "Epoch 5, Sample 371, Loss: 1.7232\n",
            "Epoch 5, Sample 372, Loss: 2.8480\n",
            "Epoch 5, Sample 373, Loss: 2.3622\n",
            "Epoch 5, Sample 374, Loss: 2.9979\n",
            "Epoch 5, Sample 375, Loss: 1.8773\n",
            "Epoch 5, Sample 376, Loss: 2.4974\n",
            "Epoch 5, Sample 377, Loss: 2.2667\n",
            "Epoch 5, Sample 378, Loss: 2.2968\n",
            "Epoch 5, Sample 379, Loss: 1.8729\n",
            "Epoch 5, Sample 380, Loss: 1.5022\n",
            "Epoch 5, Sample 381, Loss: 1.8367\n",
            "Epoch 5, Sample 382, Loss: 2.3005\n",
            "Epoch 5, Sample 383, Loss: 1.8902\n",
            "Epoch 5, Sample 384, Loss: 1.6103\n",
            "Epoch 5, Sample 385, Loss: 1.9214\n",
            "Epoch 5, Sample 386, Loss: 1.8591\n",
            "Epoch 5, Sample 387, Loss: 1.8959\n",
            "Epoch 5, Sample 388, Loss: 2.4408\n",
            "Epoch 5, Sample 389, Loss: 1.6026\n",
            "Epoch 5, Sample 390, Loss: 3.0792\n",
            "Epoch 5, Sample 391, Loss: 2.0419\n",
            "Epoch 5, Sample 392, Loss: 1.9717\n",
            "Epoch 5, Sample 393, Loss: 2.2478\n",
            "Epoch 5, Sample 394, Loss: 2.8317\n",
            "Epoch 5, Sample 395, Loss: 2.4071\n",
            "Epoch 5, Sample 396, Loss: 2.8426\n",
            "Epoch 5, Sample 397, Loss: 1.8030\n",
            "Epoch 5, Sample 398, Loss: 2.3483\n",
            "Epoch 5, Sample 399, Loss: 2.4380\n",
            "Epoch 5, Sample 400, Loss: 1.7052\n",
            "Epoch 5, Sample 401, Loss: 2.3126\n",
            "Epoch 5, Sample 402, Loss: 2.5807\n",
            "Epoch 5, Sample 403, Loss: 2.2246\n",
            "Epoch 5, Sample 404, Loss: 3.0077\n",
            "Epoch 5, Sample 405, Loss: 2.3921\n",
            "Epoch 5, Sample 406, Loss: 1.7086\n",
            "Epoch 5, Sample 407, Loss: 1.7454\n",
            "Epoch 5, Sample 408, Loss: 2.6568\n",
            "Epoch 5, Sample 409, Loss: 1.9131\n",
            "Epoch 5, Sample 410, Loss: 1.8273\n",
            "Epoch 5, Sample 411, Loss: 1.5304\n",
            "Epoch 5, Sample 412, Loss: 1.6528\n",
            "Epoch 5, Sample 413, Loss: 1.4687\n",
            "Epoch 5, Sample 414, Loss: 2.6357\n",
            "Epoch 5, Sample 415, Loss: 2.0493\n",
            "Epoch 5, Sample 416, Loss: 2.1012\n",
            "Epoch 5, Sample 417, Loss: 1.5905\n",
            "Epoch 5, Sample 418, Loss: 1.6252\n",
            "Epoch 5, Sample 419, Loss: 2.5012\n",
            "Epoch 5, Sample 420, Loss: 2.5523\n",
            "Epoch 5, Sample 421, Loss: 1.3024\n",
            "Epoch 5, Sample 422, Loss: 2.7167\n",
            "Epoch 5, Sample 423, Loss: 2.1186\n",
            "Epoch 5, Sample 424, Loss: 2.3799\n",
            "Epoch 5, Sample 425, Loss: 1.5383\n",
            "Epoch 5, Sample 426, Loss: 2.0371\n",
            "Epoch 5, Sample 427, Loss: 2.5283\n",
            "Epoch 5, Sample 428, Loss: 2.2651\n",
            "Epoch 5, Sample 429, Loss: 2.6416\n",
            "Epoch 5, Sample 430, Loss: 1.3652\n",
            "Epoch 5, Sample 431, Loss: 1.7833\n",
            "Epoch 5, Sample 432, Loss: 1.6753\n",
            "Epoch 5, Sample 433, Loss: 2.3521\n",
            "Epoch 5, Sample 434, Loss: 1.6793\n",
            "Epoch 5, Sample 435, Loss: 2.2515\n",
            "Epoch 5, Sample 436, Loss: 1.8734\n",
            "Epoch 5, Sample 437, Loss: 2.7507\n",
            "Epoch 5, Sample 438, Loss: 1.7335\n",
            "Epoch 5, Sample 439, Loss: 2.5144\n",
            "Epoch 5, Sample 440, Loss: 1.6088\n",
            "Epoch 5, Sample 441, Loss: 2.7321\n",
            "Epoch 5, Sample 442, Loss: 2.0056\n",
            "Epoch 5, Sample 443, Loss: 2.2191\n",
            "Epoch 5, Sample 444, Loss: 2.3380\n",
            "Epoch 5, Sample 445, Loss: 2.2199\n",
            "Epoch 5, Sample 446, Loss: 2.0630\n",
            "Epoch 5, Sample 447, Loss: 2.0124\n",
            "Epoch 5, Sample 448, Loss: 1.6125\n",
            "Epoch 5, Sample 449, Loss: 2.3123\n",
            "Epoch 5, Sample 450, Loss: 2.3394\n",
            "Epoch 5, Sample 451, Loss: 2.0119\n",
            "Epoch 5, Sample 452, Loss: 2.5548\n",
            "Epoch 5, Sample 453, Loss: 2.0485\n",
            "Epoch 5, Sample 454, Loss: 2.2917\n",
            "Epoch 5, Sample 455, Loss: 2.2307\n",
            "Epoch 5, Sample 456, Loss: 1.9988\n",
            "Epoch 5, Sample 457, Loss: 1.7472\n",
            "Epoch 5, Sample 458, Loss: 2.3693\n",
            "Epoch 5, Sample 459, Loss: 1.7889\n",
            "Epoch 5, Sample 460, Loss: 2.8379\n",
            "Epoch 5, Sample 461, Loss: 2.1713\n",
            "Epoch 5, Sample 462, Loss: 1.3850\n",
            "Epoch 5, Sample 463, Loss: 1.7976\n",
            "Epoch 5, Sample 464, Loss: 2.2497\n",
            "Epoch 5, Sample 465, Loss: 1.9523\n",
            "Epoch 5, Sample 466, Loss: 2.2365\n",
            "Epoch 5, Sample 467, Loss: 2.9050\n",
            "Epoch 5, Sample 468, Loss: 1.6988\n",
            "Epoch 5, Sample 469, Loss: 1.6504\n",
            "Epoch 5, Sample 470, Loss: 2.4295\n",
            "Epoch 5, Sample 471, Loss: 2.1168\n",
            "Epoch 5, Sample 472, Loss: 2.1414\n",
            "Epoch 5, Sample 473, Loss: 2.3867\n",
            "Epoch 5, Sample 474, Loss: 2.3892\n",
            "Epoch 5, Sample 475, Loss: 1.9487\n",
            "Epoch 5, Sample 476, Loss: 1.9716\n",
            "Epoch 5, Sample 477, Loss: 1.5992\n",
            "Epoch 5, Sample 478, Loss: 1.8976\n",
            "Epoch 5, Sample 479, Loss: 1.3525\n",
            "Epoch 5, Sample 480, Loss: 1.6746\n",
            "Epoch 5, Sample 481, Loss: 2.2793\n",
            "Epoch 5, Sample 482, Loss: 2.5124\n",
            "Epoch 5, Sample 483, Loss: 2.4819\n",
            "Epoch 5, Sample 484, Loss: 2.2966\n",
            "Epoch 5, Sample 485, Loss: 2.1419\n",
            "Epoch 5, Sample 486, Loss: 2.4740\n",
            "Epoch 5, Sample 487, Loss: 1.1357\n",
            "Epoch 5, Sample 488, Loss: 2.5547\n",
            "Epoch 5, Sample 489, Loss: 1.7075\n",
            "Epoch 5, Sample 490, Loss: 2.5181\n",
            "Epoch 5, Sample 491, Loss: 2.3062\n",
            "Epoch 5, Sample 492, Loss: 2.8263\n",
            "Epoch 5, Sample 493, Loss: 1.8349\n",
            "Epoch 5, Sample 494, Loss: 2.3844\n",
            "Epoch 5, Sample 495, Loss: 2.5502\n",
            "Epoch 5, Sample 496, Loss: 2.5218\n",
            "Epoch 5, Sample 497, Loss: 1.4921\n",
            "Epoch 5, Sample 498, Loss: 2.6157\n",
            "Epoch 5, Sample 499, Loss: 2.6169\n",
            "Epoch 5, Sample 500, Loss: 2.7038\n",
            "Epoch 5, Sample 501, Loss: 2.0417\n",
            "Epoch 5, Sample 502, Loss: 2.7938\n",
            "Epoch 5, Sample 503, Loss: 1.9994\n",
            "Epoch 5, Sample 504, Loss: 3.2176\n",
            "Epoch 5, Sample 505, Loss: 2.4741\n",
            "Epoch 5, Sample 506, Loss: 2.2369\n",
            "Epoch 5, Sample 507, Loss: 1.9631\n",
            "Epoch 5, Sample 508, Loss: 2.5078\n",
            "Epoch 5, Sample 509, Loss: 1.2677\n",
            "Epoch 5, Sample 510, Loss: 2.2689\n",
            "Epoch 5, Sample 511, Loss: 1.9970\n",
            "Epoch 5, Sample 512, Loss: 2.1126\n",
            "Epoch 5, Sample 513, Loss: 1.3258\n",
            "Epoch 5, Sample 514, Loss: 2.0742\n",
            "Epoch 5, Sample 515, Loss: 1.5035\n",
            "Epoch 5, Sample 516, Loss: 2.0953\n",
            "Epoch 5, Sample 517, Loss: 2.2336\n",
            "Epoch 5, Sample 518, Loss: 1.6082\n",
            "Epoch 5, Sample 519, Loss: 1.9855\n",
            "Epoch 5, Sample 520, Loss: 1.8776\n",
            "Epoch 5, Sample 521, Loss: 1.8961\n",
            "Epoch 5, Sample 522, Loss: 2.5201\n",
            "Epoch 5, Sample 523, Loss: 1.8982\n",
            "Epoch 5, Sample 524, Loss: 2.4207\n",
            "Epoch 5, Sample 525, Loss: 2.5097\n",
            "Epoch 5, Sample 526, Loss: 1.9909\n",
            "Epoch 5, Sample 527, Loss: 1.6797\n",
            "Epoch 5, Sample 528, Loss: 1.8244\n",
            "Epoch 5, Sample 529, Loss: 2.7963\n",
            "Epoch 5, Sample 530, Loss: 3.0798\n",
            "Epoch 5, Sample 531, Loss: 2.3390\n",
            "Epoch 5, Sample 532, Loss: 2.5465\n",
            "Epoch 5, Sample 533, Loss: 1.6607\n",
            "Epoch 5, Sample 534, Loss: 1.6047\n",
            "Epoch 5, Sample 535, Loss: 1.8260\n",
            "Epoch 5, Sample 536, Loss: 1.8558\n",
            "Epoch 5, Sample 537, Loss: 3.0049\n",
            "Epoch 5, Sample 538, Loss: 1.8312\n",
            "Epoch 5, Sample 539, Loss: 1.9803\n",
            "Epoch 5, Sample 540, Loss: 2.5570\n",
            "Epoch 5, Sample 541, Loss: 1.8261\n",
            "Epoch 5, Sample 542, Loss: 1.9969\n",
            "Epoch 5, Sample 543, Loss: 2.7062\n",
            "Epoch 5, Sample 544, Loss: 1.6327\n",
            "Epoch 5, Sample 545, Loss: 2.5843\n",
            "Epoch 5, Sample 546, Loss: 2.3019\n",
            "Epoch 5, Sample 547, Loss: 1.6699\n",
            "Epoch 5, Sample 548, Loss: 1.2641\n",
            "Epoch 5, Sample 549, Loss: 2.5305\n",
            "Epoch 5, Sample 550, Loss: 2.1387\n",
            "Epoch 5, Sample 551, Loss: 1.7921\n",
            "Epoch 5, Sample 552, Loss: 2.1263\n",
            "Epoch 5, Sample 553, Loss: 2.1767\n",
            "Epoch 5, Sample 554, Loss: 2.4442\n",
            "Epoch 5, Sample 555, Loss: 1.9858\n",
            "Epoch 5, Sample 556, Loss: 2.3054\n",
            "Epoch 5, Sample 557, Loss: 2.8127\n",
            "Epoch 5, Sample 558, Loss: 2.8742\n",
            "Epoch 5, Sample 559, Loss: 2.1326\n",
            "Epoch 5, Sample 560, Loss: 2.7563\n",
            "Epoch 5, Sample 561, Loss: 2.8233\n",
            "Epoch 5, Sample 562, Loss: 2.4193\n",
            "Epoch 5, Sample 563, Loss: 1.8357\n",
            "Epoch 5, Sample 564, Loss: 2.0473\n",
            "Epoch 5, Sample 565, Loss: 2.2732\n",
            "Epoch 5, Sample 566, Loss: 2.2113\n",
            "Epoch 5, Sample 567, Loss: 1.9422\n",
            "Epoch 5, Sample 568, Loss: 2.3140\n",
            "Epoch 5, Sample 569, Loss: 2.4156\n",
            "Epoch 5, Sample 570, Loss: 2.6090\n",
            "Epoch 5, Sample 571, Loss: 2.3956\n",
            "Epoch 5, Sample 572, Loss: 2.1093\n",
            "Epoch 5, Sample 573, Loss: 1.9632\n",
            "Epoch 5, Sample 574, Loss: 2.3723\n",
            "Epoch 5, Sample 575, Loss: 3.1097\n",
            "Epoch 5, Sample 576, Loss: 2.4146\n",
            "Epoch 5, Sample 577, Loss: 1.9716\n",
            "Epoch 5, Sample 578, Loss: 2.2946\n",
            "Epoch 5, Sample 579, Loss: 2.6114\n",
            "Epoch 5, Sample 580, Loss: 3.3401\n",
            "Epoch 5, Sample 581, Loss: 1.4881\n",
            "Epoch 5, Sample 582, Loss: 2.5241\n",
            "Epoch 5, Sample 583, Loss: 2.7566\n",
            "Epoch 5, Sample 584, Loss: 2.0794\n",
            "Epoch 5, Sample 585, Loss: 2.3560\n",
            "Epoch 5, Sample 586, Loss: 3.0996\n",
            "Epoch 5, Sample 587, Loss: 2.2689\n",
            "Epoch 5, Sample 588, Loss: 3.1939\n",
            "Epoch 5, Sample 589, Loss: 1.9481\n",
            "Epoch 5, Sample 590, Loss: 2.5063\n",
            "Epoch 5, Sample 591, Loss: 2.0660\n",
            "Epoch 5, Sample 592, Loss: 2.9463\n",
            "Epoch 5, Sample 593, Loss: 1.4863\n",
            "Epoch 5, Sample 594, Loss: 2.5252\n",
            "Epoch 5, Sample 595, Loss: 1.5914\n",
            "Epoch 5, Sample 596, Loss: 2.1495\n",
            "Epoch 5, Sample 597, Loss: 2.6101\n",
            "Epoch 5, Sample 598, Loss: 2.1425\n",
            "Epoch 5, Sample 599, Loss: 1.9160\n",
            "Epoch 5, Sample 600, Loss: 2.8503\n",
            "Epoch 5, Sample 601, Loss: 2.2515\n",
            "Epoch 5, Sample 602, Loss: 2.6521\n",
            "Epoch 5, Sample 603, Loss: 1.9888\n",
            "Epoch 5, Sample 604, Loss: 2.5053\n",
            "Epoch 5, Sample 605, Loss: 2.4287\n",
            "Epoch 5, Sample 606, Loss: 1.8820\n",
            "Epoch 5, Sample 607, Loss: 2.9152\n",
            "Epoch 5, Sample 608, Loss: 2.0787\n",
            "Epoch 5, Sample 609, Loss: 1.9472\n",
            "Epoch 5, Sample 610, Loss: 2.1042\n",
            "Epoch 5, Sample 611, Loss: 2.4301\n",
            "Epoch 5, Sample 612, Loss: 2.3896\n",
            "Epoch 5, Sample 613, Loss: 3.2123\n",
            "Epoch 5, Sample 614, Loss: 2.9924\n",
            "Epoch 5, Sample 615, Loss: 1.5170\n",
            "Epoch 5, Sample 616, Loss: 2.3136\n",
            "Epoch 5, Sample 617, Loss: 2.6241\n",
            "Epoch 5, Sample 618, Loss: 1.9989\n",
            "Epoch 5, Sample 619, Loss: 1.8562\n",
            "Epoch 5, Sample 620, Loss: 2.2631\n",
            "Epoch 5, Sample 621, Loss: 1.9050\n",
            "Epoch 5, Sample 622, Loss: 1.8344\n",
            "Epoch 5, Sample 623, Loss: 3.0295\n",
            "Epoch 5, Sample 624, Loss: 1.4156\n",
            "Epoch 5, Sample 625, Loss: 2.4106\n",
            "Epoch 5, Sample 626, Loss: 1.8776\n",
            "Epoch 5, Sample 627, Loss: 2.3856\n",
            "Epoch 5, Sample 628, Loss: 2.6299\n",
            "Epoch 5, Sample 629, Loss: 2.6719\n",
            "Epoch 5, Sample 630, Loss: 2.6028\n",
            "Epoch 5, Sample 631, Loss: 1.4322\n",
            "Epoch 5, Sample 632, Loss: 1.8860\n",
            "Epoch 5, Sample 633, Loss: 1.5538\n",
            "Epoch 5, Sample 634, Loss: 1.6772\n",
            "Epoch 5, Sample 635, Loss: 1.9323\n",
            "Epoch 5, Sample 636, Loss: 2.6989\n",
            "Epoch 5, Sample 637, Loss: 1.7025\n",
            "Epoch 5, Sample 638, Loss: 1.5931\n",
            "Epoch 5, Sample 639, Loss: 2.3453\n",
            "Epoch 5, Sample 640, Loss: 1.9270\n",
            "Epoch 5, Sample 641, Loss: 1.3367\n",
            "Epoch 5, Sample 642, Loss: 1.7200\n",
            "Epoch 5, Sample 643, Loss: 2.1943\n",
            "Epoch 5, Sample 644, Loss: 1.8038\n",
            "Epoch 5, Sample 645, Loss: 1.7097\n",
            "Epoch 5, Sample 646, Loss: 2.6652\n",
            "Epoch 5, Sample 647, Loss: 2.2790\n",
            "Epoch 5, Sample 648, Loss: 2.6473\n",
            "Epoch 5, Sample 649, Loss: 2.3323\n",
            "Epoch 5, Sample 650, Loss: 1.8091\n",
            "Epoch 5, Sample 651, Loss: 2.6079\n",
            "Epoch 5, Sample 652, Loss: 1.5849\n",
            "Epoch 5, Sample 653, Loss: 1.8401\n",
            "Epoch 5, Sample 654, Loss: 1.9902\n",
            "Epoch 5, Sample 655, Loss: 2.0301\n",
            "Epoch 5, Sample 656, Loss: 2.4533\n",
            "Epoch 5, Sample 657, Loss: 2.0940\n",
            "Epoch 5, Sample 658, Loss: 2.2034\n",
            "Epoch 5, Sample 659, Loss: 1.5127\n",
            "Epoch 5, Sample 660, Loss: 1.9745\n",
            "Epoch 5, Sample 661, Loss: 1.8747\n",
            "Epoch 5, Sample 662, Loss: 2.0312\n",
            "Epoch 5, Sample 663, Loss: 2.0412\n",
            "Epoch 5, Sample 664, Loss: 1.5120\n",
            "Epoch 5, Sample 665, Loss: 1.8181\n",
            "Epoch 5, Sample 666, Loss: 1.6005\n",
            "Epoch 5, Sample 667, Loss: 3.3414\n",
            "Epoch 5, Sample 668, Loss: 2.5880\n",
            "Epoch 5, Sample 669, Loss: 1.8563\n",
            "Epoch 5, Sample 670, Loss: 2.1108\n",
            "Epoch 5, Sample 671, Loss: 1.7494\n",
            "Epoch 5, Sample 672, Loss: 1.7770\n",
            "Epoch 5, Sample 673, Loss: 2.1565\n",
            "Epoch 5, Sample 674, Loss: 2.4402\n",
            "Epoch 5, Sample 675, Loss: 2.0862\n",
            "Epoch 5, Sample 676, Loss: 2.2814\n",
            "Epoch 5, Sample 677, Loss: 2.4252\n",
            "Epoch 5, Sample 678, Loss: 1.9772\n",
            "Epoch 5, Sample 679, Loss: 1.9413\n",
            "Epoch 5, Sample 680, Loss: 2.4023\n",
            "Epoch 5, Sample 681, Loss: 1.5848\n",
            "Epoch 5, Sample 682, Loss: 1.9274\n",
            "Epoch 5, Sample 683, Loss: 1.8576\n",
            "Epoch 5, Sample 684, Loss: 1.9957\n",
            "Epoch 5, Sample 685, Loss: 1.6221\n",
            "Epoch 5, Sample 686, Loss: 1.6830\n",
            "Epoch 5, Sample 687, Loss: 2.4027\n",
            "Epoch 5, Sample 688, Loss: 1.9418\n",
            "Epoch 5, Sample 689, Loss: 1.8302\n",
            "Epoch 5, Sample 690, Loss: 1.7779\n",
            "Epoch 5, Sample 691, Loss: 2.2130\n",
            "Epoch 5, Sample 692, Loss: 2.0370\n",
            "Epoch 5, Sample 693, Loss: 1.4451\n",
            "Epoch 5, Sample 694, Loss: 2.7366\n",
            "Epoch 5, Sample 695, Loss: 2.2141\n",
            "Epoch 5, Sample 696, Loss: 2.0786\n",
            "Epoch 5, Sample 697, Loss: 1.8731\n",
            "Epoch 5, Sample 698, Loss: 1.8994\n",
            "Epoch 5, Sample 699, Loss: 3.6215\n",
            "Epoch 5, Sample 700, Loss: 2.4647\n",
            "Epoch 5, Sample 701, Loss: 1.7454\n",
            "Epoch 5, Sample 702, Loss: 1.8612\n",
            "Epoch 5, Sample 703, Loss: 2.1592\n",
            "Epoch 5, Sample 704, Loss: 1.9718\n",
            "Epoch 5, Sample 705, Loss: 2.3771\n",
            "Epoch 5, Sample 706, Loss: 3.1205\n",
            "Epoch 5, Sample 707, Loss: 2.6384\n",
            "Epoch 5, Sample 708, Loss: 2.7725\n",
            "Epoch 5, Sample 709, Loss: 2.5704\n",
            "Epoch 5, Sample 710, Loss: 2.5702\n",
            "Epoch 5, Sample 711, Loss: 1.5857\n",
            "Epoch 5, Sample 712, Loss: 2.0202\n",
            "Epoch 5, Sample 713, Loss: 3.0802\n",
            "Epoch 5, Sample 714, Loss: 2.3770\n",
            "Epoch 5, Sample 715, Loss: 1.8798\n",
            "Epoch 5, Sample 716, Loss: 2.2775\n",
            "Epoch 5, Sample 717, Loss: 2.1009\n",
            "Epoch 5, Sample 718, Loss: 2.4554\n",
            "Epoch 5, Sample 719, Loss: 2.2158\n",
            "Epoch 5, Sample 720, Loss: 2.5737\n",
            "Epoch 5, Sample 721, Loss: 2.1322\n",
            "Epoch 5, Sample 722, Loss: 1.6059\n",
            "Epoch 5, Sample 723, Loss: 2.6103\n",
            "Epoch 5, Sample 724, Loss: 2.7297\n",
            "Epoch 5, Sample 725, Loss: 2.0826\n",
            "Epoch 5, Sample 726, Loss: 2.1479\n",
            "Epoch 5, Sample 727, Loss: 2.7718\n",
            "Epoch 5, Sample 728, Loss: 2.7538\n",
            "Epoch 5, Sample 729, Loss: 2.9379\n",
            "Epoch 5, Sample 730, Loss: 2.5137\n",
            "Epoch 5, Sample 731, Loss: 2.0678\n",
            "Epoch 5, Sample 732, Loss: 2.9538\n",
            "Epoch 5, Sample 733, Loss: 1.3111\n",
            "Epoch 5, Sample 734, Loss: 2.6291\n",
            "Epoch 5, Sample 735, Loss: 2.5758\n",
            "Epoch 5, Sample 736, Loss: 2.2735\n",
            "Epoch 5, Sample 737, Loss: 1.6117\n",
            "Epoch 5, Sample 738, Loss: 1.9156\n",
            "Epoch 5, Sample 739, Loss: 2.2101\n",
            "Epoch 5, Sample 740, Loss: 2.1637\n",
            "Epoch 5, Sample 741, Loss: 2.1063\n",
            "Epoch 5, Sample 742, Loss: 2.1034\n",
            "Epoch 5, Sample 743, Loss: 2.9814\n",
            "Epoch 5, Sample 744, Loss: 2.6646\n",
            "Epoch 5, Sample 745, Loss: 2.9317\n",
            "Epoch 5, Sample 746, Loss: 2.2841\n",
            "Epoch 5, Sample 747, Loss: 2.9151\n",
            "Epoch 5, Sample 748, Loss: 2.2296\n",
            "Epoch 5, Sample 749, Loss: 1.6801\n",
            "Epoch 5, Sample 750, Loss: 2.5616\n",
            "Epoch 5, Sample 751, Loss: 1.4889\n",
            "Epoch 5, Sample 752, Loss: 1.8928\n",
            "Epoch 5, Sample 753, Loss: 2.7215\n",
            "Epoch 5, Sample 754, Loss: 2.7315\n",
            "Epoch 5, Sample 755, Loss: 2.4951\n",
            "Epoch 5, Sample 756, Loss: 2.4744\n",
            "Epoch 5, Sample 757, Loss: 3.2359\n",
            "Epoch 5, Sample 758, Loss: 2.8027\n",
            "Epoch 5, Sample 759, Loss: 2.6165\n",
            "Epoch 5, Sample 760, Loss: 2.4107\n",
            "Epoch 5, Sample 761, Loss: 2.1232\n",
            "Epoch 5, Sample 762, Loss: 3.2276\n",
            "Epoch 5, Sample 763, Loss: 2.1797\n",
            "Epoch 5, Sample 764, Loss: 2.8697\n",
            "Epoch 5, Sample 765, Loss: 2.3499\n",
            "Epoch 5, Sample 766, Loss: 2.7684\n",
            "Epoch 5, Sample 767, Loss: 2.4665\n",
            "Epoch 5, Sample 768, Loss: 2.3502\n",
            "Epoch 5, Sample 769, Loss: 2.3082\n",
            "Epoch 5, Sample 770, Loss: 2.8487\n",
            "Epoch 5, Sample 771, Loss: 2.2302\n",
            "Epoch 5, Sample 772, Loss: 2.4742\n",
            "Epoch 5, Sample 773, Loss: 1.9058\n",
            "Epoch 5, Sample 774, Loss: 2.3445\n",
            "Epoch 5, Sample 775, Loss: 2.2896\n",
            "Epoch 5, Sample 776, Loss: 2.0528\n",
            "Epoch 5, Sample 777, Loss: 2.0055\n",
            "Epoch 5, Sample 778, Loss: 2.4914\n",
            "Epoch 5, Sample 779, Loss: 2.1323\n",
            "Epoch 5, Sample 780, Loss: 2.5638\n",
            "Epoch 5, Sample 781, Loss: 2.1275\n",
            "Epoch 5, Sample 782, Loss: 2.1942\n",
            "Epoch 5, Sample 783, Loss: 2.5964\n",
            "Epoch 5, Sample 784, Loss: 1.2965\n",
            "Epoch 5, Sample 785, Loss: 2.0964\n",
            "Epoch 5, Sample 786, Loss: 2.1107\n",
            "Epoch 5, Sample 787, Loss: 2.0015\n",
            "Epoch 5, Sample 788, Loss: 2.4745\n",
            "Epoch 5, Sample 789, Loss: 2.7463\n",
            "Epoch 5, Sample 790, Loss: 2.2555\n",
            "Epoch 5, Sample 791, Loss: 2.9182\n",
            "Epoch 5, Sample 792, Loss: 2.3811\n",
            "Epoch 5, Sample 793, Loss: 1.7327\n",
            "Epoch 5, Sample 794, Loss: 2.6006\n",
            "Epoch 5, Sample 795, Loss: 2.6099\n",
            "Epoch 5, Sample 796, Loss: 2.1278\n",
            "Epoch 5, Sample 797, Loss: 2.7499\n",
            "Epoch 5, Sample 798, Loss: 3.1080\n",
            "Epoch 5, Sample 799, Loss: 3.8038\n",
            "Epoch 5, Sample 800, Loss: 2.7839\n",
            "Epoch 5, Sample 801, Loss: 2.7610\n",
            "Epoch 5, Sample 802, Loss: 1.8413\n",
            "Epoch 5, Sample 803, Loss: 2.1842\n",
            "Epoch 5, Sample 804, Loss: 1.9569\n",
            "Epoch 5, Sample 805, Loss: 2.8349\n",
            "Epoch 5, Sample 806, Loss: 2.5940\n",
            "Epoch 5, Sample 807, Loss: 1.9428\n",
            "Epoch 5, Sample 808, Loss: 3.2978\n",
            "Epoch 5, Sample 809, Loss: 2.3218\n",
            "Epoch 5, Sample 810, Loss: 2.6192\n",
            "Epoch 5, Sample 811, Loss: 2.2131\n",
            "Epoch 5, Sample 812, Loss: 2.1322\n",
            "Epoch 5, Sample 813, Loss: 2.6724\n",
            "Epoch 5, Sample 814, Loss: 2.4336\n",
            "Epoch 5, Sample 815, Loss: 2.6248\n",
            "Epoch 5, Sample 816, Loss: 2.0347\n",
            "Epoch 5, Sample 817, Loss: 2.6589\n",
            "Epoch 5, Sample 818, Loss: 2.4289\n",
            "Epoch 5, Sample 819, Loss: 2.1617\n",
            "Epoch 5, Sample 820, Loss: 2.1666\n",
            "Epoch 5, Sample 821, Loss: 3.2132\n",
            "Epoch 5, Sample 822, Loss: 2.4632\n",
            "Epoch 5, Sample 823, Loss: 1.3840\n",
            "Epoch 5, Sample 824, Loss: 2.9068\n",
            "Epoch 5, Sample 825, Loss: 2.2293\n",
            "Epoch 5, Sample 826, Loss: 2.8210\n",
            "Epoch 5, Sample 827, Loss: 2.2133\n",
            "Epoch 5, Sample 828, Loss: 2.5665\n",
            "Epoch 5, Sample 829, Loss: 1.7429\n",
            "Epoch 5, Sample 830, Loss: 3.2327\n",
            "Epoch 5, Sample 831, Loss: 2.6336\n",
            "Epoch 5, Sample 832, Loss: 1.7599\n",
            "Epoch 5, Sample 833, Loss: 2.5747\n",
            "Epoch 5, Sample 834, Loss: 2.7283\n",
            "Epoch 5, Sample 835, Loss: 2.7451\n",
            "Epoch 5, Sample 836, Loss: 2.4606\n",
            "Epoch 5, Sample 837, Loss: 2.2112\n",
            "Epoch 5, Sample 838, Loss: 2.6952\n",
            "Epoch 5, Sample 839, Loss: 2.3124\n",
            "Epoch 5, Sample 840, Loss: 2.6593\n",
            "Epoch 5, Sample 841, Loss: 2.1174\n",
            "Epoch 5, Sample 842, Loss: 2.5261\n",
            "Epoch 5, Sample 843, Loss: 2.3392\n",
            "Epoch 5, Sample 844, Loss: 1.9286\n",
            "Epoch 5, Sample 845, Loss: 2.5401\n",
            "Epoch 5, Sample 846, Loss: 2.2760\n",
            "Epoch 5, Sample 847, Loss: 2.1163\n",
            "Epoch 5, Sample 848, Loss: 2.9969\n",
            "Epoch 5, Sample 849, Loss: 2.9697\n",
            "Epoch 5, Sample 850, Loss: 2.7275\n",
            "Epoch 5, Sample 851, Loss: 1.7627\n",
            "Epoch 5, Sample 852, Loss: 2.0008\n",
            "Epoch 5, Sample 853, Loss: 2.1052\n",
            "Epoch 5, Sample 854, Loss: 3.0611\n",
            "Epoch 5, Sample 855, Loss: 2.2061\n",
            "Epoch 5, Sample 856, Loss: 1.8695\n",
            "Epoch 5, Sample 857, Loss: 3.2424\n",
            "Epoch 5, Sample 858, Loss: 1.6945\n",
            "Epoch 5, Sample 859, Loss: 2.2232\n",
            "Epoch 5, Sample 860, Loss: 2.1587\n",
            "Epoch 5, Sample 861, Loss: 2.2784\n",
            "Epoch 5, Sample 862, Loss: 2.6435\n",
            "Epoch 5, Sample 863, Loss: 1.9915\n",
            "Epoch 5, Sample 864, Loss: 2.6950\n",
            "Epoch 5, Sample 865, Loss: 2.6990\n",
            "Epoch 5, Sample 866, Loss: 2.0470\n",
            "Epoch 5, Sample 867, Loss: 2.8071\n",
            "Epoch 5, Sample 868, Loss: 2.9132\n",
            "Epoch 5, Sample 869, Loss: 2.6677\n",
            "Epoch 5, Sample 870, Loss: 2.4390\n",
            "Epoch 5, Sample 871, Loss: 2.7640\n",
            "Epoch 5, Sample 872, Loss: 2.8243\n",
            "Epoch 5, Sample 873, Loss: 1.4569\n",
            "Epoch 5, Sample 874, Loss: 1.4750\n",
            "Epoch 5, Sample 875, Loss: 2.0883\n",
            "Epoch 5, Sample 876, Loss: 2.1204\n",
            "Epoch 5, Sample 877, Loss: 1.9555\n",
            "Epoch 5, Sample 878, Loss: 2.9528\n",
            "Epoch 5, Sample 879, Loss: 2.3024\n",
            "Epoch 5, Sample 880, Loss: 1.8436\n",
            "Epoch 5, Sample 881, Loss: 1.7259\n",
            "Epoch 5, Sample 882, Loss: 2.2885\n",
            "Epoch 5, Sample 883, Loss: 2.7170\n",
            "Epoch 5, Sample 884, Loss: 2.2893\n",
            "Epoch 5, Sample 885, Loss: 1.9836\n",
            "Epoch 5, Sample 886, Loss: 2.1988\n",
            "Epoch 5, Sample 887, Loss: 3.5390\n",
            "Epoch 5, Sample 888, Loss: 2.2757\n",
            "Epoch 5, Sample 889, Loss: 2.3002\n",
            "Epoch 5, Sample 890, Loss: 2.8661\n",
            "Epoch 5, Sample 891, Loss: 2.1765\n",
            "Epoch 5, Sample 892, Loss: 2.9151\n",
            "Epoch 5, Sample 893, Loss: 2.9597\n",
            "Epoch 5, Sample 894, Loss: 2.6865\n",
            "Epoch 5, Sample 895, Loss: 1.5662\n",
            "Epoch 5, Sample 896, Loss: 2.2609\n",
            "Epoch 5, Sample 897, Loss: 2.2323\n",
            "Epoch 5, Sample 898, Loss: 1.8618\n",
            "Epoch 5, Sample 899, Loss: 2.1319\n",
            "Epoch 5, Sample 900, Loss: 2.1231\n",
            "Epoch 5, Sample 901, Loss: 2.4132\n",
            "Epoch 5, Sample 902, Loss: 2.7123\n",
            "Epoch 5, Sample 903, Loss: 2.7350\n",
            "Epoch 5, Sample 904, Loss: 2.0737\n",
            "Epoch 5, Sample 905, Loss: 1.7195\n",
            "Epoch 5, Sample 906, Loss: 2.0577\n",
            "Epoch 5, Sample 907, Loss: 2.3888\n",
            "Epoch 5, Sample 908, Loss: 2.4785\n",
            "Epoch 5, Sample 909, Loss: 1.8023\n",
            "Epoch 5, Sample 910, Loss: 3.0163\n",
            "Epoch 5, Sample 911, Loss: 2.7851\n",
            "Epoch 5, Sample 912, Loss: 1.8853\n",
            "Epoch 5, Sample 913, Loss: 2.1301\n",
            "Epoch 5, Sample 914, Loss: 2.7383\n",
            "Epoch 5, Sample 915, Loss: 3.0548\n",
            "Epoch 5, Sample 916, Loss: 2.5510\n",
            "Epoch 5, Sample 917, Loss: 2.5026\n",
            "Epoch 5, Sample 918, Loss: 1.9772\n",
            "Epoch 5, Sample 919, Loss: 2.3970\n",
            "Epoch 5, Sample 920, Loss: 2.5223\n",
            "Epoch 5, Sample 921, Loss: 1.9754\n",
            "Epoch 5, Sample 922, Loss: 2.3671\n",
            "Epoch 5, Sample 923, Loss: 1.8712\n",
            "Epoch 5, Sample 924, Loss: 2.3912\n",
            "Epoch 5, Sample 925, Loss: 2.4919\n",
            "Epoch 5, Sample 926, Loss: 2.8506\n",
            "Epoch 5, Sample 927, Loss: 2.2987\n",
            "Epoch 5, Sample 928, Loss: 1.9469\n",
            "Epoch 5, Sample 929, Loss: 2.2095\n",
            "Epoch 5, Sample 930, Loss: 2.5666\n",
            "Epoch 5, Sample 931, Loss: 2.4070\n",
            "Epoch 5, Sample 932, Loss: 1.5938\n",
            "Epoch 5, Sample 933, Loss: 1.9772\n",
            "Epoch 5, Sample 934, Loss: 2.0335\n",
            "Epoch 5, Sample 935, Loss: 2.3767\n",
            "Epoch 5, Sample 936, Loss: 2.6728\n",
            "Epoch 5, Sample 937, Loss: 2.3903\n",
            "Epoch 5, Sample 938, Loss: 2.0678\n",
            "Epoch 5, Sample 939, Loss: 2.2086\n",
            "Epoch 5, Sample 940, Loss: 2.1448\n",
            "Epoch 5, Sample 941, Loss: 2.0577\n",
            "Epoch 5, Sample 942, Loss: 1.7140\n",
            "Epoch 5, Sample 943, Loss: 1.7072\n",
            "Epoch 5, Sample 944, Loss: 2.3274\n",
            "Epoch 5, Sample 945, Loss: 2.0423\n",
            "Epoch 5, Sample 946, Loss: 1.9950\n",
            "Epoch 5, Sample 947, Loss: 1.9120\n",
            "Epoch 5, Sample 948, Loss: 2.9742\n",
            "Epoch 5, Sample 949, Loss: 2.7411\n",
            "Epoch 5, Sample 950, Loss: 2.2390\n",
            "Epoch 5, Sample 951, Loss: 2.2749\n",
            "Epoch 5, Sample 952, Loss: 2.6492\n",
            "Epoch 5, Sample 953, Loss: 2.8026\n",
            "Epoch 5, Sample 954, Loss: 2.6082\n",
            "Epoch 5, Sample 955, Loss: 1.9931\n",
            "Epoch 5, Sample 956, Loss: 2.7409\n",
            "Epoch 5, Sample 957, Loss: 2.5015\n",
            "Epoch 5, Sample 958, Loss: 2.2021\n",
            "Epoch 5, Sample 959, Loss: 2.5490\n",
            "Epoch 5, Sample 960, Loss: 1.9695\n",
            "Epoch 5, Sample 961, Loss: 2.9023\n",
            "Epoch 5, Sample 962, Loss: 2.4236\n",
            "Epoch 5, Sample 963, Loss: 2.3937\n",
            "Epoch 5, Sample 964, Loss: 1.8539\n",
            "Epoch 5, Sample 965, Loss: 1.8040\n",
            "Epoch 5, Sample 966, Loss: 2.6753\n",
            "Epoch 5, Sample 967, Loss: 2.2199\n",
            "Epoch 5, Sample 968, Loss: 2.3003\n",
            "Epoch 5, Sample 969, Loss: 2.2928\n",
            "Epoch 5, Sample 970, Loss: 2.5166\n",
            "Epoch 5, Sample 971, Loss: 2.1605\n",
            "Epoch 5, Sample 972, Loss: 2.4643\n",
            "Epoch 5, Sample 973, Loss: 2.5534\n",
            "Epoch 5, Sample 974, Loss: 2.3466\n",
            "Epoch 5, Sample 975, Loss: 2.4060\n",
            "Epoch 5, Sample 976, Loss: 1.5758\n",
            "Epoch 5, Sample 977, Loss: 2.2592\n",
            "Epoch 5, Sample 978, Loss: 1.6637\n",
            "Epoch 5, Sample 979, Loss: 2.2386\n",
            "Epoch 5, Sample 980, Loss: 2.4685\n",
            "Epoch 5, Sample 981, Loss: 1.9322\n",
            "Epoch 5, Sample 982, Loss: 2.2276\n",
            "Epoch 5, Sample 983, Loss: 2.6188\n",
            "Epoch 5, Sample 984, Loss: 2.4236\n",
            "Epoch 5, Sample 985, Loss: 2.0253\n",
            "Epoch 5, Sample 986, Loss: 2.1807\n",
            "Epoch 5, Sample 987, Loss: 2.4694\n",
            "Epoch 5, Sample 988, Loss: 2.4174\n",
            "Epoch 5, Sample 989, Loss: 2.3904\n",
            "Epoch 5, Sample 990, Loss: 2.1299\n",
            "Epoch 5, Sample 991, Loss: 2.1632\n",
            "Epoch 5, Sample 992, Loss: 2.7661\n",
            "Epoch 5, Sample 993, Loss: 1.9527\n",
            "Epoch 5, Sample 994, Loss: 3.2018\n",
            "Epoch 5, Sample 995, Loss: 1.8611\n",
            "Epoch 5, Sample 996, Loss: 2.5051\n",
            "Epoch 5, Sample 997, Loss: 2.2480\n",
            "Epoch 5, Sample 998, Loss: 2.5825\n",
            "Epoch 5, Sample 999, Loss: 2.2726\n",
            "Epoch 5, Sample 1000, Loss: 2.1438\n",
            "Epoch 5, Sample 1001, Loss: 2.9389\n",
            "Epoch 5, Sample 1002, Loss: 3.1439\n",
            "Epoch 5, Sample 1003, Loss: 2.8369\n",
            "Epoch 5, Sample 1004, Loss: 2.4989\n",
            "Epoch 5, Sample 1005, Loss: 2.4410\n",
            "Epoch 5, Sample 1006, Loss: 3.0135\n",
            "Epoch 5, Sample 1007, Loss: 2.9272\n",
            "Epoch 5, Sample 1008, Loss: 2.4098\n",
            "Epoch 5, Sample 1009, Loss: 2.3475\n",
            "Epoch 5, Sample 1010, Loss: 1.8609\n",
            "Epoch 5, Sample 1011, Loss: 2.2725\n",
            "Epoch 5, Sample 1012, Loss: 2.9294\n",
            "Epoch 5, Sample 1013, Loss: 1.6774\n",
            "Epoch 5, Sample 1014, Loss: 2.5419\n",
            "Epoch 5, Sample 1015, Loss: 2.9609\n",
            "Epoch 5, Sample 1016, Loss: 2.2232\n",
            "Epoch 5, Sample 1017, Loss: 2.8413\n",
            "Epoch 5, Sample 1018, Loss: 2.6446\n",
            "Epoch 5, Sample 1019, Loss: 2.6002\n",
            "Epoch 5, Sample 1020, Loss: 2.1194\n",
            "Epoch 5, Sample 1021, Loss: 2.0924\n",
            "Epoch 5, Sample 1022, Loss: 2.3566\n",
            "Epoch 5, Sample 1023, Loss: 2.0135\n",
            "Epoch 5, Sample 1024, Loss: 1.8407\n",
            "Epoch 5, Sample 1025, Loss: 2.7408\n",
            "Epoch 5, Sample 1026, Loss: 2.0555\n",
            "Epoch 5, Sample 1027, Loss: 2.3811\n",
            "Epoch 5, Sample 1028, Loss: 2.1126\n",
            "Epoch 5, Sample 1029, Loss: 1.7179\n",
            "Epoch 5, Sample 1030, Loss: 1.6852\n",
            "Epoch 5, Sample 1031, Loss: 2.2558\n",
            "Epoch 5, Sample 1032, Loss: 2.1326\n",
            "Epoch 5, Sample 1033, Loss: 2.1185\n",
            "Epoch 5, Sample 1034, Loss: 2.4660\n",
            "Epoch 5, Sample 1035, Loss: 1.8359\n",
            "Epoch 5, Sample 1036, Loss: 1.7453\n",
            "Epoch 5, Sample 1037, Loss: 2.4538\n",
            "Epoch 5, Sample 1038, Loss: 1.4845\n",
            "Epoch 5, Sample 1039, Loss: 1.9344\n",
            "Epoch 5, Sample 1040, Loss: 1.9533\n",
            "Epoch 5, Sample 1041, Loss: 1.7800\n",
            "Epoch 5, Sample 1042, Loss: 1.5024\n",
            "Epoch 5, Sample 1043, Loss: 1.9043\n",
            "Epoch 5, Sample 1044, Loss: 1.5890\n",
            "Epoch 5, Sample 1045, Loss: 1.9880\n",
            "Epoch 5, Sample 1046, Loss: 2.0534\n",
            "Epoch 5, Sample 1047, Loss: 2.4463\n",
            "Epoch 5, Sample 1048, Loss: 1.8818\n",
            "Epoch 5, Sample 1049, Loss: 2.1000\n",
            "Epoch 5, Sample 1050, Loss: 1.2006\n",
            "Epoch 5, Sample 1051, Loss: 1.6632\n",
            "Epoch 5, Sample 1052, Loss: 2.2734\n",
            "Epoch 5, Sample 1053, Loss: 1.9598\n",
            "Epoch 5, Sample 1054, Loss: 2.0275\n",
            "Epoch 5, Sample 1055, Loss: 1.9887\n",
            "Epoch 5, Sample 1056, Loss: 2.7353\n",
            "Epoch 5, Sample 1057, Loss: 3.2658\n",
            "Epoch 5, Sample 1058, Loss: 2.6231\n",
            "Epoch 5, Sample 1059, Loss: 2.4852\n",
            "Epoch 5, Sample 1060, Loss: 1.9176\n",
            "Epoch 5, Sample 1061, Loss: 2.3528\n",
            "Epoch 5, Sample 1062, Loss: 2.3005\n",
            "Epoch 5, Sample 1063, Loss: 2.1662\n",
            "Epoch 5, Sample 1064, Loss: 2.1834\n",
            "Epoch 5, Sample 1065, Loss: 1.6041\n",
            "Epoch 5, Sample 1066, Loss: 1.2592\n",
            "Epoch 5, Sample 1067, Loss: 1.5931\n",
            "Epoch 5, Sample 1068, Loss: 1.8561\n",
            "Epoch 5, Sample 1069, Loss: 1.3646\n",
            "Epoch 5, Sample 1070, Loss: 2.1507\n",
            "Epoch 5, Sample 1071, Loss: 1.6077\n",
            "Epoch 5, Sample 1072, Loss: 2.6374\n",
            "Epoch 5, Sample 1073, Loss: 1.6423\n",
            "Epoch 5, Sample 1074, Loss: 2.2044\n",
            "Epoch 5, Sample 1075, Loss: 1.7225\n",
            "Epoch 5, Sample 1076, Loss: 3.0170\n",
            "Epoch 5, Sample 1077, Loss: 2.9552\n",
            "Epoch 5, Sample 1078, Loss: 1.7949\n",
            "Epoch 5, Sample 1079, Loss: 2.5921\n",
            "Epoch 5, Sample 1080, Loss: 2.2395\n",
            "Epoch 5, Sample 1081, Loss: 1.9871\n",
            "Epoch 5, Sample 1082, Loss: 3.7129\n",
            "Epoch 5, Sample 1083, Loss: 2.1220\n",
            "Epoch 5, Sample 1084, Loss: 1.3356\n",
            "Epoch 5, Sample 1085, Loss: 1.5045\n",
            "Epoch 5, Sample 1086, Loss: 2.3675\n",
            "Epoch 5, Sample 1087, Loss: 3.6277\n",
            "Epoch 5, Sample 1088, Loss: 2.0873\n",
            "Epoch 5, Sample 1089, Loss: 1.8292\n",
            "Epoch 5, Sample 1090, Loss: 1.7929\n",
            "Epoch 5, Sample 1091, Loss: 1.9749\n",
            "Epoch 5, Sample 1092, Loss: 2.5941\n",
            "Epoch 5, Sample 1093, Loss: 2.3293\n",
            "Epoch 5, Sample 1094, Loss: 2.1566\n",
            "Epoch 5, Sample 1095, Loss: 2.0778\n",
            "Epoch 5, Sample 1096, Loss: 2.9447\n",
            "Epoch 5, Sample 1097, Loss: 2.3635\n",
            "Epoch 5, Sample 1098, Loss: 1.8286\n",
            "Epoch 5, Sample 1099, Loss: 2.1308\n",
            "Epoch 5, Sample 1100, Loss: 2.4561\n",
            "Epoch 5, Sample 1101, Loss: 1.5966\n",
            "Epoch 5, Sample 1102, Loss: 2.0548\n",
            "Epoch 5, Sample 1103, Loss: 1.6434\n",
            "Epoch 5, Sample 1104, Loss: 2.2484\n",
            "Epoch 5, Sample 1105, Loss: 1.7797\n",
            "Epoch 5, Sample 1106, Loss: 2.0540\n",
            "Epoch 5, Sample 1107, Loss: 2.7030\n",
            "Epoch 5, Sample 1108, Loss: 2.6604\n",
            "Epoch 5, Sample 1109, Loss: 1.5691\n",
            "Epoch 5, Sample 1110, Loss: 1.9697\n",
            "Epoch 5, Sample 1111, Loss: 1.9753\n",
            "Epoch 5, Sample 1112, Loss: 1.4468\n",
            "Epoch 5, Sample 1113, Loss: 1.7624\n",
            "Epoch 5, Sample 1114, Loss: 1.6186\n",
            "Epoch 5, Sample 1115, Loss: 3.1476\n",
            "Epoch 5, Sample 1116, Loss: 3.3404\n",
            "Epoch 5, Sample 1117, Loss: 1.9438\n",
            "Epoch 5, Sample 1118, Loss: 1.5319\n",
            "Epoch 5, Sample 1119, Loss: 2.0462\n",
            "Epoch 5, Sample 1120, Loss: 2.1884\n",
            "Epoch 5, Sample 1121, Loss: 2.3003\n",
            "Epoch 5, Sample 1122, Loss: 2.2251\n",
            "Epoch 5, Sample 1123, Loss: 1.8073\n",
            "Epoch 5, Sample 1124, Loss: 1.5530\n",
            "Epoch 5, Sample 1125, Loss: 2.3525\n",
            "Epoch 5, Sample 1126, Loss: 1.5901\n",
            "Epoch 5, Sample 1127, Loss: 1.8503\n",
            "Epoch 5, Sample 1128, Loss: 1.4716\n",
            "Epoch 5, Sample 1129, Loss: 2.8821\n",
            "Epoch 5, Sample 1130, Loss: 1.9547\n",
            "Epoch 5, Sample 1131, Loss: 2.2339\n",
            "Epoch 5, Sample 1132, Loss: 3.4532\n",
            "Epoch 5, Sample 1133, Loss: 2.0678\n",
            "Epoch 5, Sample 1134, Loss: 2.6965\n",
            "Epoch 5, Sample 1135, Loss: 2.5064\n",
            "Epoch 5, Sample 1136, Loss: 3.0774\n",
            "Epoch 5, Sample 1137, Loss: 2.8352\n",
            "Epoch 5, Sample 1138, Loss: 2.5671\n",
            "Epoch 5, Sample 1139, Loss: 2.2226\n",
            "Epoch 5, Sample 1140, Loss: 2.1814\n",
            "Epoch 5, Sample 1141, Loss: 2.4680\n",
            "Epoch 5, Sample 1142, Loss: 2.5849\n",
            "Epoch 5, Sample 1143, Loss: 2.4617\n",
            "Epoch 5, Sample 1144, Loss: 1.7799\n",
            "Epoch 5, Sample 1145, Loss: 1.7756\n",
            "Epoch 5, Sample 1146, Loss: 1.8956\n",
            "Epoch 5, Sample 1147, Loss: 3.0586\n",
            "Epoch 5, Sample 1148, Loss: 2.1385\n",
            "Epoch 5, Sample 1149, Loss: 1.8611\n",
            "Epoch 5, Sample 1150, Loss: 1.9811\n",
            "Epoch 5, Sample 1151, Loss: 1.9138\n",
            "Epoch 5, Sample 1152, Loss: 1.7271\n",
            "Epoch 5, Sample 1153, Loss: 2.1984\n",
            "Epoch 5, Sample 1154, Loss: 2.2862\n",
            "Epoch 5, Sample 1155, Loss: 1.6586\n",
            "Epoch 5, Sample 1156, Loss: 2.1478\n",
            "Epoch 5, Sample 1157, Loss: 1.6002\n",
            "Epoch 5, Sample 1158, Loss: 2.1098\n",
            "Epoch 5, Sample 1159, Loss: 2.3777\n",
            "Epoch 5, Sample 1160, Loss: 2.4665\n",
            "Epoch 5, Sample 1161, Loss: 1.7886\n",
            "Epoch 5, Sample 1162, Loss: 2.5670\n",
            "Epoch 5, Sample 1163, Loss: 2.5055\n",
            "Epoch 5, Sample 1164, Loss: 2.5750\n",
            "Epoch 5, Sample 1165, Loss: 2.2241\n",
            "Epoch 5, Sample 1166, Loss: 2.2727\n",
            "Epoch 5, Sample 1167, Loss: 1.7933\n",
            "Epoch 5, Sample 1168, Loss: 2.7911\n",
            "Epoch 5, Sample 1169, Loss: 1.9760\n",
            "Epoch 5, Sample 1170, Loss: 2.3516\n",
            "Epoch 5, Sample 1171, Loss: 2.1683\n",
            "Epoch 5, Sample 1172, Loss: 1.8611\n",
            "Epoch 5, Sample 1173, Loss: 1.2299\n",
            "Epoch 5, Sample 1174, Loss: 3.2854\n",
            "Epoch 5, Sample 1175, Loss: 2.3511\n",
            "Epoch 5, Sample 1176, Loss: 2.3319\n",
            "Epoch 5, Sample 1177, Loss: 2.3031\n",
            "Epoch 5, Sample 1178, Loss: 1.7760\n",
            "Epoch 5, Sample 1179, Loss: 2.6277\n",
            "Epoch 5, Sample 1180, Loss: 2.5717\n",
            "Epoch 5, Sample 1181, Loss: 2.5506\n",
            "Epoch 5, Sample 1182, Loss: 1.8179\n",
            "Epoch 5, Sample 1183, Loss: 1.8732\n",
            "Epoch 5, Sample 1184, Loss: 2.0907\n",
            "Epoch 5, Sample 1185, Loss: 2.0154\n",
            "Epoch 5, Sample 1186, Loss: 1.9483\n",
            "Epoch 5, Sample 1187, Loss: 1.6746\n",
            "Epoch 5, Sample 1188, Loss: 2.5249\n",
            "Epoch 5, Sample 1189, Loss: 2.1160\n",
            "Epoch 5, Sample 1190, Loss: 2.2041\n",
            "Epoch 5, Sample 1191, Loss: 2.1841\n",
            "Epoch 5, Sample 1192, Loss: 2.0119\n",
            "Epoch 5, Sample 1193, Loss: 1.5585\n",
            "Epoch 5, Sample 1194, Loss: 2.3428\n",
            "Epoch 5, Sample 1195, Loss: 2.2434\n",
            "Epoch 5, Sample 1196, Loss: 1.8383\n",
            "Epoch 5, Sample 1197, Loss: 2.0391\n",
            "Epoch 5, Sample 1198, Loss: 2.4044\n",
            "Epoch 5, Sample 1199, Loss: 2.2118\n",
            "Epoch 5, Sample 1200, Loss: 1.8454\n",
            "Epoch 5, Sample 1201, Loss: 2.2553\n",
            "Epoch 5, Sample 1202, Loss: 2.0351\n",
            "Epoch 5, Sample 1203, Loss: 2.1440\n",
            "Epoch 5, Sample 1204, Loss: 2.0475\n",
            "Epoch 5, Sample 1205, Loss: 2.0356\n",
            "Epoch 5, Sample 1206, Loss: 2.4727\n",
            "Epoch 5, Sample 1207, Loss: 2.4272\n",
            "Epoch 5, Sample 1208, Loss: 2.8508\n",
            "Epoch 5, Sample 1209, Loss: 1.5864\n",
            "Epoch 5, Sample 1210, Loss: 1.7368\n",
            "Epoch 5, Sample 1211, Loss: 2.4193\n",
            "Epoch 5, Sample 1212, Loss: 1.8056\n",
            "Epoch 5, Sample 1213, Loss: 1.8333\n",
            "Epoch 5, Sample 1214, Loss: 2.0476\n",
            "Epoch 5, Sample 1215, Loss: 2.1818\n",
            "Epoch 5, Sample 1216, Loss: 2.1335\n",
            "Epoch 5, Sample 1217, Loss: 2.5544\n",
            "Epoch 5, Sample 1218, Loss: 2.2211\n",
            "Epoch 5, Sample 1219, Loss: 2.4452\n",
            "Epoch 5, Sample 1220, Loss: 2.2035\n",
            "Epoch 5, Sample 1221, Loss: 1.9136\n",
            "Epoch 5, Sample 1222, Loss: 3.1545\n",
            "Epoch 5, Sample 1223, Loss: 1.8134\n",
            "Epoch 5, Sample 1224, Loss: 2.1616\n",
            "Epoch 5, Sample 1225, Loss: 2.2854\n",
            "Epoch 5, Sample 1226, Loss: 2.7377\n",
            "Epoch 5, Sample 1227, Loss: 3.2778\n",
            "Epoch 5, Sample 1228, Loss: 2.0369\n",
            "Epoch 5, Sample 1229, Loss: 2.2152\n",
            "Epoch 5, Sample 1230, Loss: 2.9198\n",
            "Epoch 5, Sample 1231, Loss: 2.3819\n",
            "Epoch 5, Sample 1232, Loss: 2.6130\n",
            "Epoch 5, Sample 1233, Loss: 3.1280\n",
            "Epoch 5, Sample 1234, Loss: 2.2467\n",
            "Epoch 5, Sample 1235, Loss: 2.2497\n",
            "Epoch 5, Sample 1236, Loss: 2.3995\n",
            "Epoch 5, Sample 1237, Loss: 2.6935\n",
            "Epoch 5, Sample 1238, Loss: 2.2778\n",
            "Epoch 5, Sample 1239, Loss: 2.7383\n",
            "Epoch 5, Sample 1240, Loss: 3.2237\n",
            "Epoch 5, Sample 1241, Loss: 2.2798\n",
            "Epoch 5, Sample 1242, Loss: 3.1346\n",
            "Epoch 5, Sample 1243, Loss: 2.6149\n",
            "Epoch 5, Sample 1244, Loss: 2.9804\n",
            "Epoch 5, Sample 1245, Loss: 3.2746\n",
            "Epoch 5, Sample 1246, Loss: 2.3215\n",
            "Epoch 5, Sample 1247, Loss: 3.2605\n",
            "Epoch 5, Sample 1248, Loss: 3.3589\n",
            "Epoch 5, Sample 1249, Loss: 3.0066\n",
            "Epoch 5, Sample 1250, Loss: 2.7379\n",
            "Epoch 5, Sample 1251, Loss: 3.0357\n",
            "Epoch 5, Sample 1252, Loss: 3.3678\n",
            "Epoch 5, Sample 1253, Loss: 2.6791\n",
            "Epoch 5, Sample 1254, Loss: 2.3531\n",
            "Epoch 5, Sample 1255, Loss: 2.7876\n",
            "Epoch 5, Sample 1256, Loss: 2.5297\n",
            "Epoch 5, Sample 1257, Loss: 2.7044\n",
            "Epoch 5, Sample 1258, Loss: 1.7563\n",
            "Epoch 5, Sample 1259, Loss: 2.6762\n",
            "Epoch 5, Sample 1260, Loss: 3.0730\n",
            "Epoch 5, Sample 1261, Loss: 3.0616\n",
            "Epoch 5, Sample 1262, Loss: 2.5475\n",
            "Epoch 5, Sample 1263, Loss: 2.2991\n",
            "Epoch 5, Sample 1264, Loss: 2.0779\n",
            "Epoch 5, Sample 1265, Loss: 2.7779\n",
            "Epoch 5, Sample 1266, Loss: 2.7914\n",
            "Epoch 5, Sample 1267, Loss: 2.6862\n",
            "Epoch 5, Sample 1268, Loss: 2.7623\n",
            "Epoch 5, Sample 1269, Loss: 1.8663\n",
            "Epoch 5, Sample 1270, Loss: 2.7603\n",
            "Epoch 5, Sample 1271, Loss: 1.9740\n",
            "Epoch 5, Sample 1272, Loss: 3.1861\n",
            "Epoch 5, Sample 1273, Loss: 3.2619\n",
            "Epoch 5, Sample 1274, Loss: 3.3163\n",
            "Epoch 5, Sample 1275, Loss: 2.9446\n",
            "Epoch 5, Sample 1276, Loss: 2.6992\n",
            "Epoch 5, Sample 1277, Loss: 2.4309\n",
            "Epoch 5, Sample 1278, Loss: 2.6837\n",
            "Epoch 5, Sample 1279, Loss: 2.4497\n",
            "Epoch 5, Sample 1280, Loss: 2.5380\n",
            "Epoch 5, Sample 1281, Loss: 2.4248\n",
            "Epoch 5, Sample 1282, Loss: 2.5800\n",
            "Epoch 5, Sample 1283, Loss: 3.1667\n",
            "Epoch 5, Sample 1284, Loss: 2.8263\n",
            "Epoch 5, Sample 1285, Loss: 3.5590\n",
            "Epoch 5, Sample 1286, Loss: 2.3334\n",
            "Epoch 5, Sample 1287, Loss: 2.6381\n",
            "Epoch 5, Sample 1288, Loss: 2.4926\n",
            "Epoch 5, Sample 1289, Loss: 2.7873\n",
            "Epoch 5, Sample 1290, Loss: 2.4586\n",
            "Epoch 5, Sample 1291, Loss: 2.7617\n",
            "Epoch 5, Sample 1292, Loss: 2.5115\n",
            "Epoch 5, Sample 1293, Loss: 3.6025\n",
            "Epoch 5, Sample 1294, Loss: 3.2344\n",
            "Epoch 5, Sample 1295, Loss: 3.0093\n",
            "Epoch 5, Sample 1296, Loss: 2.5468\n",
            "Epoch 5, Sample 1297, Loss: 2.5522\n",
            "Epoch 5, Sample 1298, Loss: 2.7754\n",
            "Epoch 5, Sample 1299, Loss: 2.9582\n",
            "Epoch 5, Sample 1300, Loss: 3.1231\n",
            "Epoch 5, Sample 1301, Loss: 3.0587\n",
            "Epoch 5, Sample 1302, Loss: 2.5862\n",
            "Epoch 5, Sample 1303, Loss: 3.0651\n",
            "Epoch 5, Sample 1304, Loss: 2.3768\n",
            "Epoch 5, Sample 1305, Loss: 2.8970\n",
            "Epoch 5, Sample 1306, Loss: 2.4149\n",
            "Epoch 5, Sample 1307, Loss: 2.2033\n",
            "Epoch 5, Sample 1308, Loss: 2.2112\n",
            "Epoch 5, Sample 1309, Loss: 2.7883\n",
            "Epoch 5, Sample 1310, Loss: 1.9938\n",
            "Epoch 5, Sample 1311, Loss: 2.8605\n",
            "Epoch 5, Sample 1312, Loss: 3.0117\n",
            "Epoch 5, Sample 1313, Loss: 2.8184\n",
            "Epoch 5, Sample 1314, Loss: 2.6087\n",
            "Epoch 5, Sample 1315, Loss: 2.2838\n",
            "Epoch 5, Sample 1316, Loss: 2.2409\n",
            "Epoch 5, Sample 1317, Loss: 3.1563\n",
            "Epoch 5, Sample 1318, Loss: 3.0460\n",
            "Epoch 5, Sample 1319, Loss: 2.7291\n",
            "Epoch 5, Sample 1320, Loss: 2.6107\n",
            "Epoch 5, Sample 1321, Loss: 2.8744\n",
            "Epoch 5, Sample 1322, Loss: 2.7428\n",
            "Epoch 5, Sample 1323, Loss: 2.4192\n",
            "Epoch 5, Sample 1324, Loss: 2.6645\n",
            "Epoch 5, Sample 1325, Loss: 2.8905\n",
            "Epoch 5, Sample 1326, Loss: 2.7961\n",
            "Epoch 5, Sample 1327, Loss: 2.2369\n",
            "Epoch 5, Sample 1328, Loss: 2.7078\n",
            "Epoch 5, Sample 1329, Loss: 2.5580\n",
            "Epoch 5, Sample 1330, Loss: 2.5002\n",
            "Epoch 5, Sample 1331, Loss: 2.3583\n",
            "Epoch 5, Sample 1332, Loss: 2.1762\n",
            "Epoch 5, Sample 1333, Loss: 3.5868\n",
            "Epoch 5, Sample 1334, Loss: 3.0788\n",
            "Epoch 5, Sample 1335, Loss: 2.6861\n",
            "Epoch 5, Sample 1336, Loss: 2.0987\n",
            "Epoch 5, Sample 1337, Loss: 3.3270\n",
            "Epoch 5, Sample 1338, Loss: 2.5465\n",
            "Epoch 5, Sample 1339, Loss: 2.8245\n",
            "Epoch 5, Sample 1340, Loss: 2.6993\n",
            "Epoch 5, Sample 1341, Loss: 2.5677\n",
            "Epoch 5, Sample 1342, Loss: 2.8229\n",
            "Epoch 5, Sample 1343, Loss: 3.2195\n",
            "Epoch 5, Sample 1344, Loss: 3.5558\n",
            "Epoch 5, Sample 1345, Loss: 3.3254\n",
            "Epoch 5, Sample 1346, Loss: 2.5589\n",
            "Epoch 5, Sample 1347, Loss: 2.8987\n",
            "Epoch 5, Sample 1348, Loss: 2.0607\n",
            "Epoch 5, Sample 1349, Loss: 2.5147\n",
            "Epoch 5, Sample 1350, Loss: 2.1930\n",
            "Epoch 5, Sample 1351, Loss: 2.5739\n",
            "Epoch 5, Sample 1352, Loss: 2.3697\n",
            "Epoch 5, Sample 1353, Loss: 2.8948\n",
            "Epoch 5, Sample 1354, Loss: 2.8485\n",
            "Epoch 5, Sample 1355, Loss: 3.2018\n",
            "Epoch 5, Sample 1356, Loss: 2.3550\n",
            "Epoch 5, Sample 1357, Loss: 3.1563\n",
            "Epoch 5, Sample 1358, Loss: 3.5753\n",
            "Epoch 5, Sample 1359, Loss: 2.0599\n",
            "Epoch 5, Sample 1360, Loss: 2.1212\n",
            "Epoch 5, Sample 1361, Loss: 2.7361\n",
            "Epoch 5, Sample 1362, Loss: 2.6741\n",
            "Epoch 5, Sample 1363, Loss: 2.1511\n",
            "Epoch 5, Sample 1364, Loss: 2.8693\n",
            "Epoch 5, Sample 1365, Loss: 2.9373\n",
            "Epoch 5, Sample 1366, Loss: 2.5745\n",
            "Epoch 5, Sample 1367, Loss: 3.4090\n",
            "Epoch 5, Sample 1368, Loss: 2.6895\n",
            "Epoch 5, Sample 1369, Loss: 3.0439\n",
            "Epoch 5, Sample 1370, Loss: 2.4119\n",
            "Epoch 5, Sample 1371, Loss: 3.0051\n",
            "Epoch 5, Sample 1372, Loss: 2.8642\n",
            "Epoch 5, Sample 1373, Loss: 3.3536\n",
            "Epoch 5, Sample 1374, Loss: 2.5730\n",
            "Epoch 5, Sample 1375, Loss: 3.0668\n",
            "Epoch 5, Sample 1376, Loss: 3.1662\n",
            "Epoch 5, Sample 1377, Loss: 2.9120\n",
            "Epoch 5, Sample 1378, Loss: 3.3775\n",
            "Epoch 5, Sample 1379, Loss: 3.2642\n",
            "Epoch 5, Sample 1380, Loss: 2.1637\n",
            "Epoch 5, Sample 1381, Loss: 3.0194\n",
            "Epoch 5, Sample 1382, Loss: 3.6204\n",
            "Epoch 5, Sample 1383, Loss: 2.8498\n",
            "Epoch 5, Sample 1384, Loss: 2.9254\n",
            "Epoch 5, Sample 1385, Loss: 3.1740\n",
            "Epoch 5, Sample 1386, Loss: 2.9728\n",
            "Epoch 5, Sample 1387, Loss: 3.1442\n",
            "Epoch 5, Sample 1388, Loss: 2.5002\n",
            "Epoch 5, Sample 1389, Loss: 3.6156\n",
            "Epoch 5, Sample 1390, Loss: 2.8752\n",
            "Epoch 5, Sample 1391, Loss: 3.5658\n",
            "Epoch 5, Sample 1392, Loss: 2.8710\n",
            "Epoch 5, Sample 1393, Loss: 2.7566\n",
            "Epoch 5, Sample 1394, Loss: 2.6438\n",
            "Epoch 5, Sample 1395, Loss: 2.6914\n",
            "Epoch 5, Sample 1396, Loss: 2.5695\n",
            "Epoch 5, Sample 1397, Loss: 2.8635\n",
            "Epoch 5, Sample 1398, Loss: 2.7284\n",
            "Epoch 5, Sample 1399, Loss: 2.9373\n",
            "Epoch 5, Sample 1400, Loss: 2.4558\n",
            "Epoch 5, Sample 1401, Loss: 3.2339\n",
            "Epoch 5, Sample 1402, Loss: 2.9584\n",
            "Epoch 5, Sample 1403, Loss: 2.7120\n",
            "Epoch 5, Sample 1404, Loss: 2.9703\n",
            "Epoch 5, Sample 1405, Loss: 3.1370\n",
            "Epoch 5, Sample 1406, Loss: 3.0742\n",
            "Epoch 5, Sample 1407, Loss: 2.5531\n",
            "Epoch 5, Sample 1408, Loss: 2.4253\n",
            "Epoch 5, Sample 1409, Loss: 2.6322\n",
            "Epoch 5, Sample 1410, Loss: 2.8002\n",
            "Epoch 5, Sample 1411, Loss: 2.7722\n",
            "Epoch 5, Sample 1412, Loss: 2.9164\n",
            "Epoch 5, Sample 1413, Loss: 3.0772\n",
            "Epoch 5, Sample 1414, Loss: 2.4289\n",
            "Epoch 5, Sample 1415, Loss: 2.8898\n",
            "Epoch 5, Sample 1416, Loss: 2.2959\n",
            "Epoch 5, Sample 1417, Loss: 2.9036\n",
            "Epoch 5, Sample 1418, Loss: 3.0660\n",
            "Epoch 5, Sample 1419, Loss: 2.8475\n",
            "Epoch 5, Sample 1420, Loss: 3.6192\n",
            "Epoch 5, Sample 1421, Loss: 2.8934\n",
            "Epoch 5, Sample 1422, Loss: 3.2642\n",
            "Epoch 5, Sample 1423, Loss: 2.7984\n",
            "Epoch 5, Sample 1424, Loss: 2.5444\n",
            "Epoch 5, Sample 1425, Loss: 2.9046\n",
            "Epoch 5, Sample 1426, Loss: 3.4489\n",
            "Epoch 5, Sample 1427, Loss: 2.5010\n",
            "Epoch 5, Sample 1428, Loss: 2.8056\n",
            "Epoch 5, Sample 1429, Loss: 2.7163\n",
            "Epoch 5, Sample 1430, Loss: 2.5750\n",
            "Epoch 5, Sample 1431, Loss: 2.3519\n",
            "Epoch 5, Sample 1432, Loss: 3.1798\n",
            "Epoch 5, Sample 1433, Loss: 2.5091\n",
            "Epoch 5, Sample 1434, Loss: 2.4456\n",
            "Epoch 5, Sample 1435, Loss: 2.3910\n",
            "Epoch 5, Sample 1436, Loss: 2.1418\n",
            "Epoch 5, Sample 1437, Loss: 1.4311\n",
            "Epoch 5, Sample 1438, Loss: 1.9654\n",
            "Epoch 5, Sample 1439, Loss: 2.4519\n",
            "Epoch 5, Sample 1440, Loss: 2.5602\n",
            "Epoch 5, Sample 1441, Loss: 2.8275\n",
            "Epoch 5, Sample 1442, Loss: 2.5891\n",
            "Epoch 5, Sample 1443, Loss: 2.2189\n",
            "Epoch 5, Sample 1444, Loss: 1.8921\n",
            "Epoch 5, Sample 1445, Loss: 2.8312\n",
            "Epoch 5, Sample 1446, Loss: 3.1968\n",
            "Epoch 5, Sample 1447, Loss: 2.5230\n",
            "Epoch 5, Sample 1448, Loss: 2.2057\n",
            "Epoch 5, Sample 1449, Loss: 2.3702\n",
            "Epoch 5, Sample 1450, Loss: 2.4861\n",
            "Epoch 5, Sample 1451, Loss: 1.6788\n",
            "Epoch 5, Sample 1452, Loss: 2.5062\n",
            "Epoch 5, Sample 1453, Loss: 2.4571\n",
            "Epoch 5, Sample 1454, Loss: 2.0045\n",
            "Epoch 5, Sample 1455, Loss: 1.6342\n",
            "Epoch 5, Sample 1456, Loss: 2.4590\n",
            "Epoch 5, Sample 1457, Loss: 2.1661\n",
            "Epoch 5, Sample 1458, Loss: 2.2603\n",
            "Epoch 5, Sample 1459, Loss: 2.3081\n",
            "Epoch 5, Sample 1460, Loss: 2.1879\n",
            "Epoch 5, Sample 1461, Loss: 2.6481\n",
            "Epoch 5, Sample 1462, Loss: 2.3639\n",
            "Epoch 5, Sample 1463, Loss: 1.9989\n",
            "Epoch 5, Sample 1464, Loss: 2.3625\n",
            "Epoch 5, Sample 1465, Loss: 1.9889\n",
            "Epoch 5, Sample 1466, Loss: 2.5679\n",
            "Epoch 5, Sample 1467, Loss: 2.2747\n",
            "Epoch 5, Sample 1468, Loss: 2.6481\n",
            "Epoch 5, Sample 1469, Loss: 2.5864\n",
            "Epoch 5, Sample 1470, Loss: 2.9560\n",
            "Epoch 5, Sample 1471, Loss: 2.3564\n",
            "Epoch 5, Sample 1472, Loss: 1.9613\n",
            "Epoch 5, Sample 1473, Loss: 2.3712\n",
            "Epoch 5, Sample 1474, Loss: 2.4934\n",
            "Epoch 5, Sample 1475, Loss: 2.4757\n",
            "Epoch 5, Sample 1476, Loss: 3.5509\n",
            "Epoch 5, Sample 1477, Loss: 2.0869\n",
            "Epoch 5, Sample 1478, Loss: 1.9084\n",
            "Epoch 5, Sample 1479, Loss: 2.5696\n",
            "Epoch 5, Sample 1480, Loss: 2.4813\n",
            "Epoch 5, Sample 1481, Loss: 2.5262\n",
            "Epoch 5, Sample 1482, Loss: 2.6827\n",
            "Epoch 5, Sample 1483, Loss: 2.4591\n",
            "Epoch 5, Sample 1484, Loss: 2.1736\n",
            "Epoch 5, Sample 1485, Loss: 3.3771\n",
            "Epoch 5, Sample 1486, Loss: 1.9053\n",
            "Epoch 5, Sample 1487, Loss: 1.8279\n",
            "Epoch 5, Sample 1488, Loss: 2.5334\n",
            "Epoch 5, Sample 1489, Loss: 3.5755\n",
            "Epoch 5, Sample 1490, Loss: 2.4032\n",
            "Epoch 5, Sample 1491, Loss: 2.3058\n",
            "Epoch 5, Sample 1492, Loss: 2.4667\n",
            "Epoch 5, Sample 1493, Loss: 2.5468\n",
            "Epoch 5, Sample 1494, Loss: 2.6607\n",
            "Epoch 5, Sample 1495, Loss: 3.1439\n",
            "Epoch 5, Sample 1496, Loss: 2.2208\n",
            "Epoch 5, Sample 1497, Loss: 2.2904\n",
            "Epoch 5, Sample 1498, Loss: 2.4605\n",
            "Epoch 5, Sample 1499, Loss: 2.3074\n",
            "Epoch 5, Sample 1500, Loss: 2.6602\n",
            "Epoch 5, Sample 1501, Loss: 3.3045\n",
            "Epoch 5, Sample 1502, Loss: 2.2708\n",
            "Epoch 5, Sample 1503, Loss: 2.5369\n",
            "Epoch 5, Sample 1504, Loss: 2.1372\n",
            "Epoch 5, Sample 1505, Loss: 2.2075\n",
            "Epoch 5, Sample 1506, Loss: 2.6087\n",
            "Epoch 5, Sample 1507, Loss: 2.6498\n",
            "Epoch 5, Sample 1508, Loss: 2.9689\n",
            "Epoch 5, Sample 1509, Loss: 1.8228\n",
            "Epoch 5, Sample 1510, Loss: 2.3301\n",
            "Epoch 5, Sample 1511, Loss: 2.1393\n",
            "Epoch 5, Sample 1512, Loss: 2.1229\n",
            "Epoch 5, Sample 1513, Loss: 3.1965\n",
            "Epoch 5, Sample 1514, Loss: 2.5579\n",
            "Epoch 5, Sample 1515, Loss: 3.2852\n",
            "Epoch 5, Sample 1516, Loss: 1.7287\n",
            "Epoch 5, Sample 1517, Loss: 3.3982\n",
            "Epoch 5, Sample 1518, Loss: 2.6468\n",
            "Epoch 5, Sample 1519, Loss: 3.0569\n",
            "Epoch 5, Sample 1520, Loss: 2.2341\n",
            "Epoch 5, Sample 1521, Loss: 2.5782\n",
            "Epoch 5, Sample 1522, Loss: 1.9944\n",
            "Epoch 5, Sample 1523, Loss: 2.5784\n",
            "Epoch 5, Sample 1524, Loss: 1.7275\n",
            "Epoch 5, Sample 1525, Loss: 3.0955\n",
            "Epoch 5, Sample 1526, Loss: 2.5385\n",
            "Epoch 5, Sample 1527, Loss: 3.1949\n",
            "Epoch 5, Sample 1528, Loss: 2.4168\n",
            "Epoch 5, Sample 1529, Loss: 2.5285\n",
            "Epoch 5, Sample 1530, Loss: 1.8969\n",
            "Epoch 5, Sample 1531, Loss: 2.7584\n",
            "Epoch 5, Sample 1532, Loss: 3.0973\n",
            "Epoch 5, Sample 1533, Loss: 2.3670\n",
            "Epoch 5, Sample 1534, Loss: 3.1893\n",
            "Epoch 5, Sample 1535, Loss: 3.5655\n",
            "Epoch 5, Sample 1536, Loss: 3.1534\n",
            "Epoch 5, Sample 1537, Loss: 1.4469\n",
            "Epoch 5, Sample 1538, Loss: 2.8452\n",
            "Epoch 5, Sample 1539, Loss: 2.2036\n",
            "Epoch 5, Sample 1540, Loss: 1.8538\n",
            "Epoch 5, Sample 1541, Loss: 2.3740\n",
            "Epoch 5, Sample 1542, Loss: 2.3921\n",
            "Epoch 5, Sample 1543, Loss: 2.5566\n",
            "Epoch 5, Sample 1544, Loss: 2.7002\n",
            "Epoch 5, Sample 1545, Loss: 1.7197\n",
            "Epoch 5, Sample 1546, Loss: 2.7705\n",
            "Epoch 5, Sample 1547, Loss: 2.5216\n",
            "Epoch 5, Sample 1548, Loss: 2.4059\n",
            "Epoch 5, Sample 1549, Loss: 1.8362\n",
            "Epoch 5, Sample 1550, Loss: 2.7445\n",
            "Epoch 5, Sample 1551, Loss: 2.1713\n",
            "Epoch 5, Sample 1552, Loss: 2.4294\n",
            "Epoch 5, Sample 1553, Loss: 2.3008\n",
            "Epoch 5, Sample 1554, Loss: 2.9727\n",
            "Epoch 5, Sample 1555, Loss: 2.8824\n",
            "Epoch 5, Sample 1556, Loss: 1.7071\n",
            "Epoch 5, Sample 1557, Loss: 2.6500\n",
            "Epoch 5, Sample 1558, Loss: 2.5363\n",
            "Epoch 5, Sample 1559, Loss: 1.7644\n",
            "Epoch 5, Sample 1560, Loss: 2.1691\n",
            "Epoch 5, Sample 1561, Loss: 2.3530\n",
            "Epoch 5, Sample 1562, Loss: 2.5842\n",
            "Epoch 5, Sample 1563, Loss: 2.5988\n",
            "Epoch 5, Sample 1564, Loss: 2.1195\n",
            "Epoch 5, Sample 1565, Loss: 2.7707\n",
            "Epoch 5, Sample 1566, Loss: 3.7004\n",
            "Epoch 5, Sample 1567, Loss: 2.3355\n",
            "Epoch 5, Sample 1568, Loss: 2.8115\n",
            "Epoch 5, Sample 1569, Loss: 2.5977\n",
            "Epoch 5, Sample 1570, Loss: 3.5846\n",
            "Epoch 5, Sample 1571, Loss: 2.6121\n",
            "Epoch 5, Sample 1572, Loss: 3.2738\n",
            "Epoch 5, Sample 1573, Loss: 2.9400\n",
            "Epoch 5, Sample 1574, Loss: 2.4574\n",
            "Epoch 5, Sample 1575, Loss: 2.4965\n",
            "Epoch 5, Sample 1576, Loss: 2.7573\n",
            "Epoch 5, Sample 1577, Loss: 2.3404\n",
            "Epoch 5, Sample 1578, Loss: 2.6361\n",
            "Epoch 5, Sample 1579, Loss: 2.5745\n",
            "Epoch 5, Sample 1580, Loss: 2.1491\n",
            "Epoch 5, Sample 1581, Loss: 2.3837\n",
            "Epoch 5, Sample 1582, Loss: 2.5247\n",
            "Epoch 5, Sample 1583, Loss: 2.3049\n",
            "Epoch 5, Sample 1584, Loss: 1.6740\n",
            "Epoch 5, Sample 1585, Loss: 2.0392\n",
            "Epoch 5, Sample 1586, Loss: 2.1421\n",
            "Epoch 5, Sample 1587, Loss: 2.0209\n",
            "Epoch 5, Sample 1588, Loss: 2.9528\n",
            "Epoch 5, Sample 1589, Loss: 2.1187\n",
            "Epoch 5, Sample 1590, Loss: 2.3407\n",
            "Epoch 5, Sample 1591, Loss: 2.3139\n",
            "Epoch 5, Sample 1592, Loss: 2.4565\n",
            "Epoch 5, Sample 1593, Loss: 1.7092\n",
            "Epoch 5, Sample 1594, Loss: 2.3459\n",
            "Epoch 5, Sample 1595, Loss: 2.6228\n",
            "Epoch 5, Sample 1596, Loss: 2.0551\n",
            "Epoch 5, Sample 1597, Loss: 2.3023\n",
            "Epoch 5, Sample 1598, Loss: 2.7689\n",
            "Epoch 5, Sample 1599, Loss: 2.1440\n",
            "Epoch 5, Sample 1600, Loss: 2.6801\n",
            "Epoch 5, Sample 1601, Loss: 1.8852\n",
            "Epoch 5, Sample 1602, Loss: 2.7094\n",
            "Epoch 5, Sample 1603, Loss: 2.5042\n",
            "Epoch 5, Sample 1604, Loss: 2.9204\n",
            "Epoch 5, Sample 1605, Loss: 2.4048\n",
            "Epoch 5, Sample 1606, Loss: 2.7588\n",
            "Epoch 5, Sample 1607, Loss: 1.9829\n",
            "Epoch 5, Sample 1608, Loss: 2.2695\n",
            "Epoch 5, Sample 1609, Loss: 2.6112\n",
            "Epoch 5, Sample 1610, Loss: 3.0931\n",
            "Epoch 5, Sample 1611, Loss: 2.5284\n",
            "Epoch 5, Sample 1612, Loss: 2.9540\n",
            "Epoch 5, Sample 1613, Loss: 2.3433\n",
            "Epoch 5, Sample 1614, Loss: 2.1122\n",
            "Epoch 5, Sample 1615, Loss: 2.4468\n",
            "Epoch 5, Sample 1616, Loss: 2.6019\n",
            "Epoch 5, Sample 1617, Loss: 2.7060\n",
            "Epoch 5, Sample 1618, Loss: 2.9317\n",
            "Epoch 5, Sample 1619, Loss: 2.2769\n",
            "Epoch 5, Sample 1620, Loss: 2.7311\n",
            "Epoch 5, Sample 1621, Loss: 3.0153\n",
            "Epoch 5, Sample 1622, Loss: 2.0308\n",
            "Epoch 5, Sample 1623, Loss: 2.4411\n",
            "Epoch 5, Sample 1624, Loss: 2.2851\n",
            "Epoch 5, Sample 1625, Loss: 2.2242\n",
            "Epoch 5, Sample 1626, Loss: 3.5024\n",
            "Epoch 5, Sample 1627, Loss: 2.1167\n",
            "Epoch 5, Sample 1628, Loss: 2.0957\n",
            "Epoch 5, Sample 1629, Loss: 2.3870\n",
            "Epoch 5, Sample 1630, Loss: 2.3612\n",
            "Epoch 5, Sample 1631, Loss: 2.7965\n",
            "Epoch 5, Sample 1632, Loss: 2.0854\n",
            "Epoch 5, Sample 1633, Loss: 2.7610\n",
            "Epoch 5, Sample 1634, Loss: 1.5213\n",
            "Epoch 5, Sample 1635, Loss: 2.5321\n",
            "Epoch 5, Sample 1636, Loss: 2.0325\n",
            "Epoch 5, Sample 1637, Loss: 1.4519\n",
            "Epoch 5, Sample 1638, Loss: 1.8993\n",
            "Epoch 5, Sample 1639, Loss: 2.3232\n",
            "Epoch 5, Sample 1640, Loss: 1.7772\n",
            "Epoch 5, Sample 1641, Loss: 2.2334\n",
            "Epoch 5, Sample 1642, Loss: 1.8219\n",
            "Epoch 5, Sample 1643, Loss: 1.9709\n",
            "Epoch 5, Sample 1644, Loss: 2.3167\n",
            "Epoch 5, Sample 1645, Loss: 2.5344\n",
            "Epoch 5, Sample 1646, Loss: 2.4215\n",
            "Epoch 5, Sample 1647, Loss: 2.0139\n",
            "Epoch 5, Sample 1648, Loss: 2.7037\n",
            "Epoch 5, Sample 1649, Loss: 2.5277\n",
            "Epoch 5, Sample 1650, Loss: 2.2172\n",
            "Epoch 5, Sample 1651, Loss: 2.6456\n",
            "Epoch 5, Sample 1652, Loss: 1.8799\n",
            "Epoch 5, Sample 1653, Loss: 1.7559\n",
            "Epoch 5, Sample 1654, Loss: 2.6895\n",
            "Epoch 5, Sample 1655, Loss: 1.7048\n",
            "Epoch 5, Sample 1656, Loss: 1.7630\n",
            "Epoch 5, Sample 1657, Loss: 2.5376\n",
            "Epoch 5, Sample 1658, Loss: 2.0186\n",
            "Epoch 5, Sample 1659, Loss: 1.2610\n",
            "Epoch 5, Sample 1660, Loss: 2.8336\n",
            "Epoch 5, Sample 1661, Loss: 2.8301\n",
            "Epoch 5, Sample 1662, Loss: 2.2087\n",
            "Epoch 5, Sample 1663, Loss: 2.3567\n",
            "Epoch 5, Sample 1664, Loss: 3.0878\n",
            "Epoch 5, Sample 1665, Loss: 2.3807\n",
            "Epoch 5, Sample 1666, Loss: 2.5659\n",
            "Epoch 5, Sample 1667, Loss: 2.3313\n",
            "Epoch 5, Sample 1668, Loss: 2.2071\n",
            "Epoch 5, Sample 1669, Loss: 2.4738\n",
            "Epoch 5, Sample 1670, Loss: 2.2440\n",
            "Epoch 5, Sample 1671, Loss: 2.2934\n",
            "Epoch 5, Sample 1672, Loss: 1.9963\n",
            "Epoch 5, Sample 1673, Loss: 2.9001\n",
            "Epoch 5, Sample 1674, Loss: 2.7638\n",
            "Epoch 5, Sample 1675, Loss: 3.6036\n",
            "Epoch 5, Sample 1676, Loss: 2.1304\n",
            "Epoch 5, Sample 1677, Loss: 2.6780\n",
            "Epoch 5, Sample 1678, Loss: 2.8897\n",
            "Epoch 5, Sample 1679, Loss: 2.1817\n",
            "Epoch 5, Sample 1680, Loss: 2.6056\n",
            "Epoch 5, Sample 1681, Loss: 2.1826\n",
            "Epoch 5, Sample 1682, Loss: 1.9571\n",
            "Epoch 5, Sample 1683, Loss: 2.8211\n",
            "Epoch 5, Sample 1684, Loss: 2.7810\n",
            "Epoch 5, Sample 1685, Loss: 2.7815\n",
            "Epoch 5, Sample 1686, Loss: 2.4042\n",
            "Epoch 5, Sample 1687, Loss: 2.0768\n",
            "Epoch 5, Sample 1688, Loss: 2.7173\n",
            "Epoch 5, Sample 1689, Loss: 2.0653\n",
            "Epoch 5, Sample 1690, Loss: 2.5687\n",
            "Epoch 5, Sample 1691, Loss: 2.8396\n",
            "Epoch 5, Sample 1692, Loss: 2.7412\n",
            "Epoch 5, Sample 1693, Loss: 3.5115\n",
            "Epoch 5, Sample 1694, Loss: 2.4602\n",
            "Epoch 5, Sample 1695, Loss: 2.6176\n",
            "Epoch 5, Sample 1696, Loss: 1.8055\n",
            "Epoch 5, Sample 1697, Loss: 2.2116\n",
            "Epoch 5, Sample 1698, Loss: 1.2604\n",
            "Epoch 5, Sample 1699, Loss: 2.7429\n",
            "Epoch 5, Sample 1700, Loss: 2.2053\n",
            "Epoch 5, Sample 1701, Loss: 1.9908\n",
            "Epoch 5, Sample 1702, Loss: 2.1865\n",
            "Epoch 5, Sample 1703, Loss: 1.7447\n",
            "Epoch 5, Sample 1704, Loss: 2.5776\n",
            "Epoch 5, Sample 1705, Loss: 2.5688\n",
            "Epoch 5, Sample 1706, Loss: 1.6364\n",
            "Epoch 5, Sample 1707, Loss: 1.9945\n",
            "Epoch 5, Sample 1708, Loss: 1.9646\n",
            "Epoch 5, Sample 1709, Loss: 2.1758\n",
            "Epoch 5, Sample 1710, Loss: 2.3555\n",
            "Epoch 5, Sample 1711, Loss: 2.7067\n",
            "Epoch 5, Sample 1712, Loss: 1.8938\n",
            "Epoch 5, Sample 1713, Loss: 2.5933\n",
            "Epoch 5, Sample 1714, Loss: 1.9221\n",
            "Epoch 5, Sample 1715, Loss: 2.0598\n",
            "Epoch 5, Sample 1716, Loss: 1.7248\n",
            "Epoch 5, Sample 1717, Loss: 2.2100\n",
            "Epoch 5, Sample 1718, Loss: 2.5369\n",
            "Epoch 5, Sample 1719, Loss: 2.0577\n",
            "Epoch 5, Sample 1720, Loss: 2.2329\n",
            "Epoch 5, Sample 1721, Loss: 2.2855\n",
            "Epoch 5, Sample 1722, Loss: 2.6955\n",
            "Epoch 5, Sample 1723, Loss: 2.3827\n",
            "Epoch 5, Sample 1724, Loss: 2.8445\n",
            "Epoch 5, Sample 1725, Loss: 1.6748\n",
            "Epoch 5, Sample 1726, Loss: 2.2740\n",
            "Epoch 5, Sample 1727, Loss: 2.2341\n",
            "Epoch 5, Sample 1728, Loss: 2.6604\n",
            "Epoch 5, Sample 1729, Loss: 1.7942\n",
            "Epoch 5, Sample 1730, Loss: 2.2360\n",
            "Epoch 5, Sample 1731, Loss: 2.4832\n",
            "Epoch 5, Sample 1732, Loss: 2.9524\n",
            "Epoch 5, Sample 1733, Loss: 2.1911\n",
            "Epoch 5, Sample 1734, Loss: 1.8863\n",
            "Epoch 5, Sample 1735, Loss: 1.9902\n",
            "Epoch 5, Sample 1736, Loss: 2.0988\n",
            "Epoch 5, Sample 1737, Loss: 2.2782\n",
            "Epoch 5, Sample 1738, Loss: 2.4146\n",
            "Epoch 5, Sample 1739, Loss: 1.9758\n",
            "Epoch 5, Sample 1740, Loss: 2.5742\n",
            "Epoch 5, Sample 1741, Loss: 2.0095\n",
            "Epoch 5, Sample 1742, Loss: 2.3291\n",
            "Epoch 5, Sample 1743, Loss: 1.9753\n",
            "Epoch 5, Sample 1744, Loss: 2.3404\n",
            "Epoch 5, Sample 1745, Loss: 2.1682\n",
            "Epoch 5, Sample 1746, Loss: 2.3661\n",
            "Epoch 5, Sample 1747, Loss: 2.6370\n",
            "Epoch 5, Sample 1748, Loss: 2.0482\n",
            "Epoch 5, Sample 1749, Loss: 2.3796\n",
            "Epoch 5, Sample 1750, Loss: 2.3176\n",
            "Epoch 5, Sample 1751, Loss: 2.3062\n",
            "Epoch 5, Sample 1752, Loss: 2.1452\n",
            "Epoch 5, Sample 1753, Loss: 1.4772\n",
            "Epoch 5, Sample 1754, Loss: 2.5364\n",
            "Epoch 5, Sample 1755, Loss: 2.9660\n",
            "Epoch 5, Sample 1756, Loss: 1.8543\n",
            "Epoch 5, Sample 1757, Loss: 2.4318\n",
            "Epoch 5, Sample 1758, Loss: 2.0866\n",
            "Epoch 5, Sample 1759, Loss: 2.2398\n",
            "Epoch 5, Sample 1760, Loss: 1.8874\n",
            "Epoch 5, Sample 1761, Loss: 2.2792\n",
            "Epoch 5, Sample 1762, Loss: 2.0639\n",
            "Epoch 5, Sample 1763, Loss: 1.6424\n",
            "Epoch 5, Sample 1764, Loss: 2.0036\n",
            "Epoch 5, Sample 1765, Loss: 2.3783\n",
            "Epoch 5, Sample 1766, Loss: 2.0219\n",
            "Epoch 5, Sample 1767, Loss: 1.7692\n",
            "Epoch 5, Sample 1768, Loss: 1.7146\n",
            "Epoch 5, Sample 1769, Loss: 2.5957\n",
            "Epoch 5, Sample 1770, Loss: 2.8484\n",
            "Epoch 5, Sample 1771, Loss: 2.9232\n",
            "Epoch 5, Sample 1772, Loss: 2.9563\n",
            "Epoch 5, Sample 1773, Loss: 1.9032\n",
            "Epoch 5, Sample 1774, Loss: 2.5392\n",
            "Epoch 5, Sample 1775, Loss: 2.1033\n",
            "Epoch 5, Sample 1776, Loss: 1.8079\n",
            "Epoch 5, Sample 1777, Loss: 2.3996\n",
            "Epoch 5, Sample 1778, Loss: 2.0617\n",
            "Epoch 5, Sample 1779, Loss: 2.1385\n",
            "Epoch 5, Sample 1780, Loss: 1.1798\n",
            "Epoch 5, Sample 1781, Loss: 1.7293\n",
            "Epoch 5, Sample 1782, Loss: 2.2410\n",
            "Epoch 5, Sample 1783, Loss: 2.1152\n",
            "Epoch 5, Sample 1784, Loss: 2.3215\n",
            "Epoch 5, Sample 1785, Loss: 2.0219\n",
            "Epoch 5, Sample 1786, Loss: 2.6778\n",
            "Epoch 5, Sample 1787, Loss: 1.8142\n",
            "Epoch 5, Sample 1788, Loss: 2.4797\n",
            "Epoch 5, Sample 1789, Loss: 2.1292\n",
            "Epoch 5, Sample 1790, Loss: 2.4395\n",
            "Epoch 5, Sample 1791, Loss: 2.2989\n",
            "Epoch 5, Sample 1792, Loss: 2.0415\n",
            "Epoch 5, Sample 1793, Loss: 2.6660\n",
            "Epoch 5, Sample 1794, Loss: 3.1027\n",
            "Epoch 5, Sample 1795, Loss: 1.8673\n",
            "Epoch 5, Sample 1796, Loss: 2.3144\n",
            "Epoch 5, Sample 1797, Loss: 3.4773\n",
            "Epoch 5, Sample 1798, Loss: 2.6866\n",
            "Epoch 5, Sample 1799, Loss: 2.1279\n",
            "Epoch 5, Sample 1800, Loss: 2.3878\n",
            "Epoch 5, Sample 1801, Loss: 2.0697\n",
            "Epoch 5, Sample 1802, Loss: 2.2644\n",
            "Epoch 5, Sample 1803, Loss: 1.9033\n",
            "Epoch 5, Sample 1804, Loss: 2.3333\n",
            "Epoch 5, Sample 1805, Loss: 2.3339\n",
            "Epoch 5, Sample 1806, Loss: 2.0634\n",
            "Epoch 5, Sample 1807, Loss: 1.8503\n",
            "Epoch 5, Sample 1808, Loss: 2.4241\n",
            "Epoch 5, Sample 1809, Loss: 3.0060\n",
            "Epoch 5, Sample 1810, Loss: 2.2924\n",
            "Epoch 5, Sample 1811, Loss: 2.2721\n",
            "Epoch 5, Sample 1812, Loss: 2.0146\n",
            "Epoch 5, Sample 1813, Loss: 2.8267\n",
            "Epoch 5, Sample 1814, Loss: 2.2437\n",
            "Epoch 5, Sample 1815, Loss: 1.9281\n",
            "Epoch 5, Sample 1816, Loss: 2.2416\n",
            "Epoch 5, Sample 1817, Loss: 2.3231\n",
            "Epoch 5, Sample 1818, Loss: 2.2774\n",
            "Epoch 5, Sample 1819, Loss: 2.7577\n",
            "Epoch 5, Sample 1820, Loss: 2.3002\n",
            "Epoch 5, Sample 1821, Loss: 1.8801\n",
            "Epoch 5, Sample 1822, Loss: 2.5458\n",
            "Epoch 5, Sample 1823, Loss: 1.9629\n",
            "Epoch 5, Sample 1824, Loss: 1.9371\n",
            "Epoch 5, Sample 1825, Loss: 2.1303\n",
            "Epoch 5, Sample 1826, Loss: 2.6092\n",
            "Epoch 5, Sample 1827, Loss: 2.2394\n",
            "Epoch 5, Sample 1828, Loss: 2.4473\n",
            "Epoch 5, Sample 1829, Loss: 2.0427\n",
            "Epoch 5, Sample 1830, Loss: 2.1821\n",
            "Epoch 5, Sample 1831, Loss: 2.3703\n",
            "Epoch 5, Sample 1832, Loss: 2.1267\n",
            "Epoch 5, Sample 1833, Loss: 2.4203\n",
            "Epoch 5, Sample 1834, Loss: 2.2790\n",
            "Epoch 5, Sample 1835, Loss: 2.3424\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/LinkedIn Chatbot/chatbot/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/LinkedIn Chatbot/chatbot/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/LinkedIn Chatbot/chatbot/spiece.model',\n",
              " '/content/drive/MyDrive/LinkedIn Chatbot/chatbot/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "from transformers import T5Tokenizer , T5ForConditionalGeneration\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from torch.optim import AdamW\n",
        "import torch\n",
        "\n",
        "model_name = \"/content/drive/MyDrive/LinkedIn Chatbot/flan-t5-small\"\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "df=pd.read_csv(\"/content/drive/MyDrive/LinkedIn Chatbot/linkedIn.csv\")\n",
        "df = df.rename(columns={\"Prompt\": \"prompt\", \"Response\": \"response\"})\n",
        "df = df[[\"prompt\", \"response\"]]\n",
        "df.columns = df.columns.str.strip().str.lower()\n",
        "dataset=Dataset.from_pandas(df)\n",
        "print(dataset.column_names)\n",
        "\n",
        "input_tensors = []\n",
        "df.dropna(subset=[\"prompt\", \"response\"], inplace=True)\n",
        "df[\"prompt\"] = df[\"prompt\"].astype(str)\n",
        "df[\"response\"] = df[\"response\"].astype(str)\n",
        "\n",
        "\n",
        "for i, row in df.iterrows():\n",
        "    input_encoding = tokenizer(\n",
        "        text=row[\"prompt\"],\n",
        "        max_length=128,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    target_encoding = tokenizer(\n",
        "        text=row[\"response\"],\n",
        "        max_length=128,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    labels = target_encoding[\"input_ids\"]\n",
        "    labels[labels == tokenizer.pad_token_id] = -100\n",
        "    input_tensors.append({\n",
        "        \"input_ids\": input_encoding[\"input_ids\"].squeeze(0),\n",
        "        \"attention_mask\": input_encoding[\"attention_mask\"].squeeze(0),\n",
        "        \"labels\": labels.squeeze(0)\n",
        "    })\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "model.train()\n",
        "\n",
        "for epoch in range(5):\n",
        "    for i, tokens in enumerate(input_tensors):\n",
        "        input_ids = tokens[\"input_ids\"].unsqueeze(0).to(model.device)\n",
        "        attention_mask = tokens[\"attention_mask\"].unsqueeze(0).to(model.device)\n",
        "        labels = tokens[\"labels\"].unsqueeze(0).to(model.device)\n",
        "        output = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = output.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        print(f\"Epoch {epoch+1}, Sample {i+1}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "model.save_pretrained(\"/content/drive/MyDrive/LinkedIn Chatbot/chatbot\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/LinkedIn Chatbot/chatbot\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/LinkedIn Chatbot/chatbot\"\n",
        "tokenizer = T5Tokenizer.from_pretrained('/content/drive/MyDrive/LinkedIn Chatbot/chatbot')\n",
        "model = T5ForConditionalGeneration.from_pretrained('/content/drive/MyDrive/LinkedIn Chatbot/chatbot')\n",
        "\n",
        "def generate_response(question, max_length=50):\n",
        "    input_text = f\"prompt: {prompt}\"\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
        "    outputs = model.generate(**inputs, temperature=1.0, top_p=0.9, max_length=100,num_beams=4,do_sample=True)\n",
        "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return answer\n",
        "\n",
        "while True:\n",
        "   prompt=input(\"Enter your prompt: \")\n",
        "   if prompt==\"end\" or prompt==\"End\":\n",
        "      break\n",
        "   else:\n",
        "      print(generate_response(prompt))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "003h__CsS4ib",
        "outputId": "e2c107f4-a351-4381-f09a-26fe9ef46915"
      },
      "execution_count": 31,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your promptwrite a linkedIn post for achieving a certificate\n",
            "Finished a certificate in [Topic] and earned a certificate in [Topic]! #CertifiedCertified #CertifiedCertified\n",
            "Enter your promptend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y transformers\n",
        "!pip install transformers --upgrade --force-reinstall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SmGp1sZ3ziw0",
        "outputId": "55bf7af6-b98b-421f-e92d-ec42a7126eec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: transformers 4.53.2\n",
            "Uninstalling transformers-4.53.2:\n",
            "  Successfully uninstalled transformers-4.53.2\n",
            "Collecting transformers\n",
            "  Using cached transformers-4.53.2-py3-none-any.whl.metadata (40 kB)\n",
            "Collecting filelock (from transformers)\n",
            "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
            "  Downloading huggingface_hub-0.33.4-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting numpy>=1.17 (from transformers)\n",
            "  Downloading numpy-2.3.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging>=20.0 (from transformers)\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting pyyaml>=5.1 (from transformers)\n",
            "  Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting regex!=2019.12.17 (from transformers)\n",
            "  Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests (from transformers)\n",
            "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
            "  Downloading tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting safetensors>=0.4.3 (from transformers)\n",
            "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting tqdm>=4.27 (from transformers)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.30.0->transformers)\n",
            "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0,>=0.30.0->transformers)\n",
            "  Downloading typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub<1.0,>=0.30.0->transformers)\n",
            "  Downloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
            "Collecting charset_normalizer<4,>=2 (from requests->transformers)\n",
            "  Downloading charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->transformers)\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
            "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
            "  Downloading certifi-2025.7.9-py3-none-any.whl.metadata (2.4 kB)\n",
            "Using cached transformers-4.53.2-py3-none-any.whl (10.8 MB)\n",
            "Downloading huggingface_hub-0.33.4-py3-none-any.whl (515 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.3/515.3 kB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.3.1-cp311-cp311-manylinux_2_28_x86_64.whl (16.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m116.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.0/763.0 kB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.7/792.7 kB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m111.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Downloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.8/64.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading certifi-2025.7.9-py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.2/159.2 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.3/147.3 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m111.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.8/129.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: urllib3, typing-extensions, tqdm, safetensors, regex, pyyaml, packaging, numpy, idna, hf-xet, fsspec, filelock, charset_normalizer, certifi, requests, huggingface-hub, tokenizers, transformers\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.4.0\n",
            "    Uninstalling urllib3-2.4.0:\n",
            "      Successfully uninstalled urllib3-2.4.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.14.1\n",
            "    Uninstalling typing_extensions-4.14.1:\n",
            "      Successfully uninstalled typing_extensions-4.14.1\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: safetensors\n",
            "    Found existing installation: safetensors 0.5.3\n",
            "    Uninstalling safetensors-0.5.3:\n",
            "      Successfully uninstalled safetensors-0.5.3\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2024.11.6\n",
            "    Uninstalling regex-2024.11.6:\n",
            "      Successfully uninstalled regex-2024.11.6\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: hf-xet\n",
            "    Found existing installation: hf-xet 1.1.5\n",
            "    Uninstalling hf-xet-1.1.5:\n",
            "      Successfully uninstalled hf-xet-1.1.5\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.18.0\n",
            "    Uninstalling filelock-3.18.0:\n",
            "      Successfully uninstalled filelock-3.18.0\n",
            "  Attempting uninstall: charset_normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.2\n",
            "    Uninstalling charset-normalizer-3.4.2:\n",
            "      Successfully uninstalled charset-normalizer-3.4.2\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.7.9\n",
            "    Uninstalling certifi-2025.7.9:\n",
            "      Successfully uninstalled certifi-2025.7.9\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.33.2\n",
            "    Uninstalling huggingface-hub-0.33.2:\n",
            "      Successfully uninstalled huggingface-hub-0.33.2\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.2\n",
            "    Uninstalling tokenizers-0.21.2:\n",
            "      Successfully uninstalled tokenizers-0.21.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.1 which is incompatible.\n",
            "cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.1 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "langchain-core 0.3.68 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.1 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.3.1 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed certifi-2025.7.9 charset_normalizer-3.4.2 filelock-3.18.0 fsspec-2025.5.1 hf-xet-1.1.5 huggingface-hub-0.33.4 idna-3.10 numpy-2.3.1 packaging-25.0 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.4 safetensors-0.5.3 tokenizers-0.21.2 tqdm-4.67.1 transformers-4.53.2 typing-extensions-4.14.1 urllib3-2.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "filelock",
                  "fsspec",
                  "huggingface_hub",
                  "idna",
                  "numpy",
                  "packaging",
                  "regex",
                  "requests",
                  "safetensors",
                  "tokenizers",
                  "tqdm",
                  "transformers",
                  "urllib3"
                ]
              },
              "id": "01fe81591b5041e4a3be10a80f4d3a38"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}